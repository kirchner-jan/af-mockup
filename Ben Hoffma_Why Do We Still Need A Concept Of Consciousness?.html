<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Why Do We Still Need A Concept Of Consciousness?      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Ben Hoffma</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Link post</p><br><p><strong>I. Consciousness Is More Than Just The Brain</strong></p><br><p>Our understanding of the world is largely based on sensory experience, but it's not just sight or sound or touch that is used to build understanding; we do a large amount of thinking by processing sensory information. And our experience of our own thinking, of <em>consciousness</em>, plays a role in making sense of the world, and thereby helps to constrain our understanding. This is related to the idea of information as "useful compression." Information is not a binary thing; there is more than one possible way that a signal could be used to encode something. If two signals are the same, it's because they share a _conservation of information, _one way of thinking about it is that they can be computed from the other. </p><br><p>A common argument in favor of multiple realizability of mental properties is that consciousness is an important mental property, a basic part of our thought, and we would expect other kinds of minds to exhibit similar properties: if qualia exist, we shouldn't be too surprised if future computers would also implement qualia[1]. It's less clear whether we currently understand the mechanisms behind conscious experience that are likely to be in future computers, and if we do we should hope that future computers will use mechanisms other than ours for consciousness, for example by understanding qualia fundamentally as information in the brain.</p><br><p>But it might be the case that consciousness _is _something we should expect in future computers, even if we don't understand what it is. In this sense qualia are very puzzling, for they don't fit well on many of our models of information processing in the brain. Some suggest that we're confused about the role of consciousness in thought\xe2\x80\x94consciousness might not actually exist\xe2\x80\x94and we should try to make sense of it by identifying alternative theories in the philosophy literature. But why do we still need a concept of consciousness in the first place? </p><br><p>A major reason is that, even if we're wrong, the assumption that consciousness exists can serve useful purposes. We can still build a rough picture of ourselves in our heads, and this image of ourselves does allow us to predict what we're going to do ("I'm going to do this", "I'm going to feel that", "wow I think I'm in the flow right now") and perhaps even predict what to do next ("that's funny, I seem to have forgotten what just happened").</p><br><p>We also use the fact that we think we're conscious to try to achieve our goals. We tend to _expect _various future results, and we _tend to _try to achieve those future results. We try not to get in our own way by _doing _anything. We want to experience our thoughts as being controlled by ourselves, not by our surroundings[2].</p><br><p>So we can use the information encoded in the fact that we're aware of our conscious experience as a way of shaping our future conscious experience. It seems reasonable to think that we might even be able to achieve a goal via conscious thinking where this is otherwise unattainable, perhaps e.g. by distracting ourselves from some unpleasant experience.</p><br><p>There is also some evidence that people can change their thoughts via training by making conscious choices. A similar type of training is used in some forms of psychotherapy[3]. And if we are talking about future AIs that are able to exert real-time control over themselves, some amount of training and guidance by humans will probably be necessary when those AIs first come online. On the other hand, a future AI that is trying to influence the world may have an advantage because we can already see what thoughts we're going to think and change our mind before we're actually affected by them.</p><br><p>One reason to still give consciousness a non-trivial role beyond the brain might be that there is no way to fully describe the mechanisms that create perceptions or beliefs (that's not to say we can't <em>detect _these mechanisms, but they're not what people are usually discussing when they talk about beliefs; we can think of beliefs as a _model</em> instead, created in our brains after perceptions from the past are experienced as sensory information). If consciousness serves a major computational function, one that is related to perception and thought, a theory that didn't acknowledge the existence of consciousness might lack the important parts of a full theory of the functions of the brain\xe2\x80\x94we may well end up talking about qualia just because we don't know what happens inside. Thus there could be scientific value (e.g. predictive or explanatory) to talking about consciousness, even if the concept of consciousness turns out to not actually describe a real physical entity.</p><br><p><strong>II. Qualia Aren't Magical Stuff, But Aren't Physical</strong></p><br><p>I've talked in favor of a functional role for consciousness because I think that this allows us to imagine some mechanisms (if qualia were a thing) for how this process might work. My hope is that the arguments in this post show that there's reason to still give a non-totally-ridiculous role to consciousness, though I think that this role should probably be reduced to the brain.</p><br><p>I think the way we talk about consciousness is a bit confused, because of the phenomenon of introspective illusion, or the illusion of experience. Here's an example: let's say Bob believes that he is going to stub his toe even though nothing seems to be happening. Now let's say that Alice comes into Bob's living room. When Bob's back is turned, Alice gives Bob a pill that makes Bob think he's stubbed his toe. His toe really isn't stubbed (and he would notice the pain if it were). Bob has a strong belief (or maybe he is conscious of some kind of <em>representation</em> of a belief) of stubbing his toe even though his toe isn't stubbed. </p><br><p>Alice tricks Bob in this sense because the belief is a reliable indicator of the thing it represents, and it's hard to disentangle the belief from the thing it represents. The belief _feels _like stubbing the toe, so it _feels _to Bob like stubbing his toe. And we can try to describe qualia as something non-physical to try to avoid talking about them in this way: we could say that a belief is represented in an external object like computers, but in humans the belief is represented by a kind of information signal in the brain. We could try to talk about this as if there is a signal in the brain, but I can't do this without making a series of dubious changes to what we're trying to say. </p><br><p>We can say it feels like Bob believes stubbing his toe, but that doesn't capture the important details of what's going on. I can have a representation of stubbing my toe, and not stubbing my toe. That I think I might stub my toe doesn't mean I do stub my toe.</p><br><p>If we say that qualia are information for the brain and are non-physical, we open the door to all sorts of strange possibilities and paradoxes. It makes predictions that include many strange things, such as the zombie (I-zombies), that have been suggested have trouble explaining other properties of qualia. And this also allows for the idea of a conscious robot that has the same kind of qualia I would if I had those conscious qualia. I'm not denying that qualia are in some sense non-physical, but I think much more is going on than just describing information that is encoded in a brain.</p><br><p>[1] Note that this may be in disagreement with the theory of mind implicit in the intentional stance. It seems that according to intentionalists, qualia are like any other representation or prediction by our brains, encoded as information in the physical substrate of the brain and then used by a human to think and act in the world. But note that this definition does allow for qualia to be encoded in other types of systems. For example a computer running a simulation of a human that is trying to predict the thoughts and feelings of its simulated self would have the same kinds of qualia as a real human. And my qualia might happen to be encoded by the physical substrate of my brain, but my qualia might not have their origins in anything about the physical substrate of that mind, it might only have an indirect connection. This would correspond to qualia existing entirely within one mind. This seems a bit odd, but is not at all unproblematic.</p><br><p>[2] Again I think most people would not try to _truly _do these things, rather we can view them as trying to _try _to succeed at these actions: as a deliberate attempt to make future events conform to expectations.</p><br><p>[3] Also, more controversially, see also Zen and the Art of Motorcycle Maintenance.</p>      </span>    </div>  </div></body></html>