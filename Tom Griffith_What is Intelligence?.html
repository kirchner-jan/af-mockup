<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        What is Intelligence?      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Tom Griffith</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>The Problem</li>
</ul><br><ul>
<li>Possible Solutions</li>
</ul><br><ul>
<li>The Need for a New Definition of Intelligence</li>
</ul><br><ul>
<li>Criteria for a Definition of Intelligence</li>
</ul><br><p><strong><em>Crossposted from the EA Global Hub (where I am the Director of Research for the New Ideas in Philosophy of AI)</em></strong></p><br><p>___TL;DR: Intelligence in humans appears to be a mix of a number of different cognitive mechanisms, and the current definitions of intelligence fail to reflect this. We propose a new definition that combines knowledge about how the brain works with a functional approach to intelligence. This definition also considers other capabilities, including motivations and emotions._</p><br><p><em>This post has been a long time coming. I started out with the following explanation in the comments of a previous post but it seemed to be of lower quality, so I thought I would add it to the main post.</em></p><br><p><strong><em>Introduction</em></strong></p><br><p>When thinking about the future of AI, we often do so by asking questions of the form "If we achieve a certain level of intelligence, what will it be like?". This is an important question, but the answers are far from obvious. As a starting point, I propose we consider a number of historical attempts to define and measure intelligence and contrast those with our current understanding of the brain, to see what has changed over time.</p><br><p>The Problem</p><br><p>Intelligence in humans appears to involve many different cognitive mechanisms (Gazzaniga 2009: p. 34). It is almost certainly a combination of learning abilities such as intelligence, memory and procedural skills such as creativity, coordination and communication. All these skills have a common link; in order for them to be learned, the learner must be able to construct mental representations of the things being learned. </p><br><p>In essence, we can think of humans as having the innate ability to construct new mental representations, an innate ability which is limited by the size of our brains. The size and shape of our brains varies significantly between different individuals\xe2\x80\x94with each person's brain having roughly a billion neurons, at least one of which must be randomly mutated. The average IQ test score for humans varies between 70-100, and the average human can only think about 15-20 complex thoughts at any time. So it is hard to say exactly what counts as human intelligence by today's human standards, but it would seem to be in the ballpark of a score in the 90s on the current IQ test. Even if we measure on the individual level, it is hard to give exact scores as humans will be able to fake their own scores in many different ways.</p><br><p>For this reason, if we define intelligence as the ability to do well on tests of general ability, then it may be hard to define who or what the tests should measure. A computer program that does well on these tests, for example, would be intelligent. But in fact we know the tests should be measuring human general intelligence (or, more specifically, intelligence of the sort that allows one human to successfully pursue their goals in the world (Gazzanigan 1997: p. 44)).</p><br><p>If we ignore this distinction and define intelligence as an intuitive concept, then it is hard to define exactly what counts as what would be intelligent anyway. But let's ignore that for a moment and suppose for the moment we are using our intuitive definitions.</p><br><p>The most intuitive definition of intelligence is the one which relies on the concept of a chess board. We have two options: either we say chess intelligence does not exist because the concept of chess intelligence appears to be purely a result of humans having a large brain that was specifically developed for the purposes of making chess board moves (Fodor et al 1982) or more broadly, humans have something like an innate "intelligence" built in. If we accept that chess intelligence exists naturally, then to test the theory we can take individuals (in all ages and all cultures), ask them to play chess and see whether their performance is above some threshold. If so, we have an intelligence test in the rough sense of the word, even if the threshold is not the same for everyone and people seem to score differently based on whether they are asked for the reasoning behind their board positions, or the probability of different chess positions.</p><br><p>This test is, clearly enough, somewhat limited as it relies on humans' ability to understand what a chess board is. An orangutan would not be able to play chess if we asked it to. And not even a chimpanzee. </p><br><p>So what do modern human beings have in common with the great apes? In the last 10,000 years or so, we have developed a particular way of thinking about how the world works. This is what I will call "rationality". To the extent humans use a particular way of constructing knowledge about the world, then this should be at least partially responsible for human intelligence. </p><br><p>Why should we believe that rationality is the component of intelligence that most relevant for thinking about AI? Two reasons: firstly, the brain itself is made up of neurons and the neural structure of the brain contains all the information about how the brain is functioning in everyday terms. If two individuals have very different cognitive algorithms, then we should expect one of them to have a different brain structure compared to the other. Secondly, there are reasons to believe that reasoning and learning ability are separable. In everyday language, there are people who are very good at learning and teaching, but who are still stumped when they try to reason about why a particular piece of knowledge they have learned is true. For example, we would expect to find people with learning difficulties who have no difficulty with reasoning. Even though both types of difficulty seem related, it stands to reason that perhaps certain characteristics of a person can only be observed by looking inside their head. On the other hand, since rationality relates to how information about the world is constructed in the brain, an individual's intelligence can be described by observing their brain more generally. </p><br><p>Finally, if rationality is what makes humans intelligent, we should expect it to change over time. In the modern world, there is considerably more information available to us than in the past, but at the same time, the complexity of the world has increased quite dramatically, and it is only a question of time until new technologies allow us to think about information in new ways. But just as technology has created new forms of knowledge, it is likely also that there will be a return to more traditional forms of knowledge in the future. If this is the case, then intelligence-like behaviour can be seen as one that is based on a particular collection of cognitive algorithms that are better tuned towards the new information available through modern technology. </p><br><p>These are the core pieces of my argument:</p><br><ul>
<li>The term "Intelligence" is somewhat ambiguous and we should distinguish between "Intelligence" as intelligence in humans (which is a mix of a variety of different cognitive mechanisms), and "Intelligence" in computer systems (which usually involves highly structured forms of learning)</li>
</ul><br><ul>
<li>If we distinguish "Intelligence" from "Intelligence in humans" then "Intelligence in computers" (by our definition) is the "hard problem of Artificial Intelligence"</li>
</ul><br><ul>
<li>There is a way to measure the human version of intelligence, but it is a particular definition of intelligence based on what the brain does, and not something that is directly comparable with the definition in computer systems</li>
</ul><br><p>Possible Solutions</p><br><p>But what if we ignore the distinction between Intelligence in humans and Intelligence in computers on the premise that a successful definition of Intelligence in computers will be very similar to a successful definition of intelligence in humans? In the modern world we have AI systems that can be described as "Intelligent" in the broad sense of the word. But if this is the case then it should also be the case that AI systems that are intelligent in this sense can also be described as "intelligent" in the "Intelligence in human" sense. So we should be able to measure the human intelligence and this gives us the ability for this definition of intelligence to be a useful theoretical construct for thinking about intelligence in computers and in the far future. </p><br><p>It could be argued that, for our purposes, the "Far Future" is far too long for us to be stuck using current definitions of Intelligence. Therefore, we should just accept that we need to use some form of current human intelligence and move forward with this. But I believe that's a bad approach since even if the AI development continues to take place in a manner that closely mimics human development, there seems enough reason to believe that some particular cognitive algorithms will eventually be necessary for the development of general intelligence. </p><br><br><p>Another possible solution would be to treat the notion of "general intelligence" as completely unclear or unverifiable (for reasons explained in section 2 here). As we might never achieve general (or even "super" general) intelligence, but instead have to rely on sub-general intelligence to be able to compete successfully with other humans in day-to-day tasks, this would limit us to studying only sub-general intelligence. This would require a much more narrow definition of intelligence than is currently popular among AI researchers. </p>      </span>    </div>  </div></body></html>