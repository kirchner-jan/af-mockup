<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        How long have AI takeoff scenarios lasted in the past?      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Eliezier Yudkowsky (EA Forum)</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>On February 3, 2006, a computer program beat professional human players at the game of Go, by beating them all simultaneously in an unprecedented way. The computer program was named AlphaGo and it demonstrated the ability of machine learning to learn, in the sense of being able to improve itself, without a need for human oversight or programming error correction. The press quickly dubbed it a game-changer:</p><br><blockquote>
<p>A computer [has] won a crucial battle in the war Against Go  The press and science quickly found a practical application for the  technology, in the form of Go-playing robots\xe2\x80\x94computer programs that could  beat the most talented human players, even though they hadn't been  programmed in Go. It would seem that Go became just another game like  chess or poker: one in a series of victories against the world's best  players by some program that had gotten smarter; and now the Go world would  be watching to see whether another program could beat Go masters in a  genuinely different way.</p>
</blockquote><br><p>That computer program in particular (AlphaGo) was programmed by the Google search division TPU. In the case of Go in particular, TPU was able to use an algorithm called Monte Carlo tree search (MCTS), which used the brute force of random exploration, to discover patterns in the gameboard (which AlphaGo then used to improve upon itself). This kind of method is often used in computer science and ML, and has led to breakthroughs in all sorts of AI problems, such as chess and Go. But the general approach was, as far as I know, unheard of on that day, in that place and time.</p><br><p>The problem is, AlphaGo was not the end of it. AlphaGo was not able to use a sufficiently complex pattern of connections between nodes, that humans had not yet discovered. It became necessary, for the first time, to search for and use the patterns that humans had already discovered. This too was new, and the MCTS algorithm was not sufficient. There was a certain amount of trial and error\xe2\x80\x94it was possible and important that DeepMind not be held to the standard of 'it'll never happen', because the Go world still saw Go as an unassailable art; the algorithm was too new to be able to learn from human errors\xe2\x80\x94but the fact that no human, including the programmer, had discovered the human method of Go-playing with MCTS before (in DeepMind as in all of computer Go) was enough to convince at least some of the Go-playing Go community that an artificial intelligence had just gotten smarter. As a result, computer Go, which was one of the fields most concerned about AGI, also became the first and the most important of these fields where it was possible to test the hypothesis experimentally.</p><br><p>A year later, DeepMind released a second version of their program, AlphaGo Zero, which used statistical pattern-finding and statistical pattern-matching and self study, without the need to examine every position of the gameboard in detail, which was a requirement for the previous version.</p><br><p>Then, in a series of breakthroughs followed by further deep exploration and experimentation, DeepMind found a set of patterns that could learn MCTS through self-play. This was possible, and it allowed AlphaGo zero to beat every Go expert who had tried it, including the one who had won for the first time without making any improvements\xe2\x80\x94 Lee Sedol.</p><br><p>You wouldn't want to be one of the Go experts that DeepMind had beaten. And you wouldn't be able to use human error correction methods, such as asking AlphaGo zero to show you some of its moves before seeing your own move, if you wanted to play against it. The only way to get any improvement would be to learn by trial and error, from human error correction, and by searching for patterns not in the gameboard as AlphaGo did, but in the patterns in the neural network that generated the moves that AlphaGo made. This was not an 'event' like that of the opening statement of this post. It was not a discontinuous advance. It was probably continuous improvement upon improvement, and one that happened over decades, maybe centuries. But we didn't realize how long it would take until we went back and we looked at the neural network that AlphaGo had used to generate its moves, and we were able to generate a set of improvements to the original algorithm for neural networks. This didn't seem at all like it would be possible, because it seemed like it didn't scale.</p><br><p>When AlphaGo Zero beat the world Go champion, a similar thing happened: the <em>discontinuity</em> was in how long it took to go from AlphaGo, an unoptimized version of the algorithm, to AlphaGo Zero, and a further change followed when <em>AlphaGo Zero</em> beat <em>Sedol</em>. We didn't realize how many small improvements had actually taken us from one point to the other. And this was before anyone had attempted to train anything like MCTS in a neural-net based context\xe2\x80\x94before anyone had tried to use statistical learning algorithms to improve upon learning algorithms.</p><br><p>But the question was how fast. <em>AlphaGo Zero was</em> able to get better at Go over a couple of years of play by play and self study, while still trying many different moves, but I think that this could have happened a lot faster\xe2\x80\x94_on the order of a couple of weeks_, perhaps six, rather than six months.</p><br><p>This is the kind of question in AI, which has no discontinuities, where it feels like we're answering an empirical question. You can't answer an empirical question directly with discontinuities, because you'd need discontinuities in your methods of measurement. What we can measure is <em>how fast</em> progress happened, and the answer is 'a lot, but a lot of smaller steps'.</p><br><p>In DeepMind's case, they knew how they'd got from AlphaGo Zero to, in MCTS form, to AlphaGo, because they looked at the neural networks. So we would be unable to directly measure discontinuities, and unable to directly measure any advance, <em>to our knowledge,</em> from MCTS-AlphaGo Zero to MCTS-Alphago I to MCTS AlphaGo Zero, or from neural network-based-AlphaGo Zero all the way back to 'we used MCTS to discover learning-by-playing algorithms.'</p><br><p>But even if we can't measure in practice, we might still be able to measure the <em>expected future path of AI systems.</em> If we knew AlphaGo Zero took two weeks less to figure out than AlphaGo\xe2\x80\x94that is, the change from MCTS Alphago Zero to MCTSAI AlphaGo\xe2\x80\x94I don't think we would know this in the sense that a discontinuity must seem.</p><br><p>We might not know the path taken on the future road towards AGI. But we do know that there exists a one-step change in MCTS from AlphaGo Zero AI to MCTS+AI, in the sense that one set of networks can learn how to learn from, rather than using, other networks. And there's a much smaller change in neural networks between AlphaGo Zero and MCTS+Neural Networks AlphaGo Zero. This is the kind of event that the Open Philanthropy Project's 'disruptive technology' concept is based on. I think Open Philanthropy's concept of a disruptive technology is really all about this sort of thing: we would be able to predict that one day there would exist an AI system which went from non-superintelligence to superintelligence in less time than had elapsed since the invention of the neural network or any improvement in how we searched graphs of connections between nodes. AI that had gone from zero to one and then took over the world. It would only take months or weeks for AlphaGo Zero to produce a similar effect.</p>      </span>    </div>  </div></body></html>