<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Some reflections on moral uncertainty      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Wei_Da</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Here is the list of links that I collected during my own research:</p><br><ul>
<li>Moral Uncertainty: The Problem</li>
</ul><br><ul>
<li></li>
</ul><br><ul>
<li>Related to moral uncertainty: moral realism hypothesis.</li>
</ul><br><ul>
<li>Related to moral uncertainty and moral realism: Moral uncertainty in meta-ethics.</li>
</ul><br><ul>
<li>Related to moral uncertainty and reflective consistency: Moral uncertainty in the context of reflective moral theories.</li>
</ul><br><ul>
<li>Reflective inconsistency:</li>
</ul><br><ul>
<li>Morally uncertain reflective inconsistent agents are less moral realist</li>
</ul><br><ul>
<li>Reflective inconsistency and moral realism</li>
</ul><br><ul>
<li>Reflective inconsistent agents' actions depend on the details of their moral beliefs</li>
</ul><br><ul>
<li>Reflective consistent agents are coherent and have a utility function</li>
</ul><br><ul>
<li>Not every coherent agent is reflectively consistent</li>
</ul><br><ul>
<li>Reflective consistency.</li>
</ul><br><ul>
<li>Moral realism</li>
</ul><br><ul>
<li>Moral moral realism</li>
</ul><br><ul>
<li>Consequentialism &amp; moral theories</li>
</ul><br><ul>
<li>Reflective moral theories</li>
</ul><br><ul>
<li>The metaethics sequence on personal identity and moral uncertainty</li>
</ul><br><ul>
<li>Reflection: an algorithm for perfect preferences (Part 1)</li>
</ul><br><ul>
<li>The meta-preferences sequence on personal identity (Part 2): Moral Uncertainty and the Metaethics Sequence</li>
</ul><br><ul>
<li>Three meta-ethical systems</li>
</ul><br><ul>
<li>Meta-ethics Sequence: Moral Uncertainty</li>
</ul><br><ul>
<li>Related to meta-ethical reflective consistency, such as these posts:</li>
</ul><br><ul>
<li>Reflectively Consistent Meta-Ethics?</li>
</ul><br><ul>
<li>Reflective Consistency and the Is-Ought Gap</li>
</ul><br><ul>
<li>The (ir)relevance of meta-ethical uncertainty</li>
</ul><br><ul>
<li>Reflective versus non-reflective morality</li>
</ul><br><ul>
<li>Reflective and non-reflective moralities: a model of some kinds of moral behavior</li>
</ul><br><ul>
<li>How to build a reflective meta-ethicist?</li>
</ul><br><ul>
<li>The Reflective Consistencies of Deontology</li>
</ul><br><ul>
<li>Rationality, reflective consistency, and moral realism</li>
</ul><br><p>(Not all of these links are in any particular order.)</p><br><p>Many forms of moral uncertainty can be described as "morally inconsistent" in some standard sense, where that term is taken to mean the failure of an agent to act consistently with its meta-level beliefs. I have been careful to distinguish between moral uncertainty per se, in which an agent's normative theories assign different numerical values to the same pair of choices, and reflective consistency, in which one's meta-level beliefs about what normative moral theories to hold also give different numerical values for the same pair of options. (In some cases the two come apart, such as in self-modifying reflective agents, or in cases of moral disagreement between different people, or in cases when the moral theories one has access to are incomplete.)</p><br><p>When I say that moral decisions imply different actions under different moral theories, I mean it in the reflective consistency sense, where it is assumed that meta-level beliefs give different moral credences to the same facts that the normative theories in moral cases imply different decisions/​actions. Also, I have refrained from saying that people <em>should</em> act this way; my point is in the context of what people <em>are</em> doing, not what they <em>should</em> do. I should be clearer about that if the current state of discussion is still unclear. (Also, "people" is just a convenient abstraction; my claim is not that this is how each person's specific normative moral theory should be applied.)</p><br><p>I call this kind of reasoning "Moral Reflection", because it is the kind of reasoning that reflective moral theorists are supposed to do in some reflective version of consequentialism, and I'm claiming that it can apply to many other different forms of moral theories as well. (Note that the phrase "moral reflection" here should not be taken to necessarily mean "moral reflective consistency", as I do not actually intend to make a strong claim about the kind of reflective consistency that can in general be attained by reflective moral theories.)</p><br><p>Before discussing the philosophical relevance of moral reflection in more detail, I will briefly comment on its broader implications. Given the nature of the above-listed links/​citations/​posts, it is clear that this type of reasoning is both philosophically important and has much impact on practical issues.</p><br><p>Regarding the second consideration, I believe that the most practical kind of moral uncertainty, where moral theories actually take turns giving preferences, and this turns out to be the main one (e.g., if it is unclear how to decide the meta-ethics sequence (part 2) was correct, this is probably a bug in moral theorizing; if most of one's moral theories say that it is okay to act immorally, the moral theories one ends up adopting are not going to be very good), is very important.</p><br><p>Regarding whether the first consideration is practically important, I'm not as sure. I personally am not very concerned about the practical value of this kind of reasoning because it is very unlikely that most people will want a moral theory (even if one can figure out how to formally code them) to actually start saying that the correct moral theory to adopt changes depending on one's actions. (By contrast, it seems to me that most people want morality to be something like a coherent whole, to be consistent throughout time, and to give consistent recommendations about what is to be done.) To state the same point in an even stronger sense, it would actually be quite bad if everyone's moral theories were too unstable to determine what is right and wrong, instead of just what is desirable and undesirable.</p><br><p>However, I do think that there is another kind of practical relevance that this type of reflection has, which should be even much higher value for most people. The reason is this: Even if the above-mentioned moral theories are inconsistent with each other, they do give consistent recommendations about how to update when one finds evidence. For example, if one has moral uncertainty in part 3 of The Metaethics Sequence, and one's main meta-ethical moral theory is a moral moral realist theory that says that one ought to always act as if the utility function one assigns to oneself in theory is the true utility function (which is just another way of saying that it is the utility function that one's actions are optimized toward), then one should adopt a moral realist theory instead of the other theories you have, because the moral realist theory is more consistent with the way you were acting (according to this part's meta-ethics) before you found out what you know now.</p>      </span>    </div>  </div></body></html>