<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        On Cogitating about Cogitating      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">abramdemedfor</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>Cogitating is a meta-strategy</li>
</ul><br><ul>
<li>Cogitative Strategies</li>
</ul><br><ul>
<li>The Problem</li>
</ul><br><ul>
<li>A Suggestion</li>
</ul><br><ul>
<li>Possible Objections</li>
</ul><br><ul>
<li>Conclusion</li>
</ul><br><p><strong>Summary</strong>: This post is essentially an exploration of how to apply a decision algorithm (one that might make up a new cognitive strategy) to its own cognition. I begin by examining some strategies that might constitute useful decisions, and explore how the process of making a decision changes the decision. For example, consider a method for improving your memory, which involves trying to remember that you forgot some information and repeating it back. This changes the information that the decision algorithm is trying to find in terms of data, such that it might end up looking for ways of remembering information that you did actually forget.</p><br><p>I end by arguing for investigating the process of self-modification, as a means of making better decisions. It seems to me that the sort of self-modifications that people attempt on LessWrong often end up having counter-effects, not intended by the authors of the posts.</p><br><p>In essence, this post is basically a description of how decision theories like CDT and EDT can apply to themselves (in the form of an idealized version), which looks like it might be important.</p><br><p>Cogitating is a Meta-Strategy</p><br><p>One common pattern of decision-making is to use a specific solution, then notice an obstacle that may prevent it from being a good one. This is, roughly speaking, a situation of noticing a potential flaw in your plans. In this situation, you have an opportunity to change your plans to avoid this flaw, but you <em>might also decide</em> to use the original plan. This might look like using the rule "Don't get caught cheating on your taxes\xe2\x80\x94adjust your plan from the very beginning, to avoid potential legal penalties", but also saying to yourself "I can't resist the urge to get some of those chocolate croissants..."</p><br><p>This pattern can arise from many different patterns of cognition, but it's not limited to them. I'm going to call it a <strong>cogitative decision algorithm </strong>(CDAlgorithm) because the pattern always looks something like this:</p><br><ul>
<li>Make a prediction that some outcome will result from your plans.</li>
</ul><br><ul>
<li>If that prediction is incorrect, alter the plan accordingly.</li>
</ul><br><p>Cognitive algorithms are not necessarily made of explicit rules, however. Instead, it seems that their internal structure can be described with a higher level of abstraction: this is the output of your CDAlgorithm applied to itself.</p><br><p>I think that this is a very useful description of internal process, and can be used to think about internal behavior in other cases. Consider, for example, a specific strategy for improving memory. The process of making a memory improvement plan might involve having a CDAlgorithm which tries to make a prediction about the way that your memory will be changed if you make a plan. If the prediction is wrong, an alarm goes off inside you, telling you to either alter your plan or to abandon it: after all, the alternative is failing to make the memory improvement. This sort of thing is something that seems very reasonable for an idealized version of the algorithm to perform, <em>if</em> the predictions it can make of its effect on memory are in line with things that actually happen.</p><br><p>However, in some ways, this sort of prediction is problematic. After all, most people's memory experiences involve some mix of things that actually did happen, and things that <em>did not</em>. We can attempt to counter it by, for example, adding a "Don't forget those chocolate croissant thingies" rule to your memory improvement plan, but there is a danger of trying too hard.</p><br><p>If we have a rule that says "Don't forget things", then we don't want to forget about chocolate croissants, and it seems hard to add any further restrictions to it beyond "Don't forget everything" (which may already be very restrictive, if we allow ourselves to be distracted by chocolate croissant taste).</p><br><p>One way in which adding a restriction like this might be easier is by first making a decision of whether or not to add the limitation to your memory improvement plans. After all, the most reasonable thing to do is to add just that enough constraint to prevent you from forgetting <em>everything</em>. After all, if you don't forget them, you might even end up with a really strong memory!</p><br><p>From this viewpoint, the rule doesn't seem to limit the things that you forget at all, but the rule does make the problem of forgetting <em>different</em>: after all, something that you don't do is something that you can't have forgotten.</p><br><p><strong>Cogitative Strategies</strong></p><br><p>I'm calling this a "cogitative decision" because it is the output of an "algorithm" (one which is potentially composed of many sub-algorithms) applied to itself. At the time of this posting, there are many different CDAlgorithms out there which all seem to have the same structure (aside from the obvious differences between human heuristics and explicit algorithms). However, the following few posts will be looking at <em>specific</em> CDAlgorithms which could potentially have been generated using different selection criteria. Some algorithms will be looking for different sorts of predictions or criteria for deciding to alter their plans, whereas others will have no particular criteria at all. (The last is what I'm calling a "Cogitative-Strategy" for this concept, because it is the strategy which ends up producing a <em>specific</em> plan for improvement.)</p><br><p>We can use the idea of a CDAlgorithm to explore how things can go wrong if we are too strict in our requirements for what sorts of decisions allow us to alter our decisions later on. We can imagine starting from a rule "Don't forget chocolate croissants" or "Don't forget food that involves your lips touching it" and then saying "I can't use that rule, because it will limit my memory improvements", and then looking for better rules to make.</p><br><p>Some of the rules might already have been stated, for example "Don't forget about important things you haven't looked at for years". If we are really strict about how we make decisions about what do and don't forget food that involve your lips touching it, we might end up forgetting important things <em>which involved your lips touching them</em>, like how it feels to hear your own voice and see your own face. This would be because the rule is too strict, requiring you not to recall information with your lips touching it if any recall with your lips touching anything.</p><br><p>A Suggestion</p><br><p>Let's consider the idea of a meta-modification: the idea of modifying yourself at a higher level, in a manner that allows you to better modify a lower level. If we say we don't care about chocolate croissant problems, but <em>do</em> care about remembering things that involve your lips <em>touching</em> a piece of chocolate croissant, then we might notice that this rule seems to be limiting our self-modifications in a way that makes the problem more difficult for us to solve.</p><br><p>There's at least one kind of self-modication which would be of interest. We are interested in the case where this decision algorithm is applied to a decision algorithm, <em>such that</em> the meta-decision is an improvement. That is, there's an improvement that can be drawn from the fact that these two decisions are linked up in this higher level way, rather than being isolated.</p><br><p>The way this sort of self-improvement fits into the idealized version of CDT is a bit tricky. We're interested in how to draw an improvement in our predictions about the outcome of the CDAlgorithm. So, for example, if we are making a memory-tampering improvement plan in such a way that we think that we might forget chocolate croissant information, the question is how we can improve our <em>predictions</em> about what might happen when we execute a memory-taming plan which involves altering food in various ways, without altering the fact that any of those alterations are actually food? Similarly, when making a memory improvement decision, how should we predict what sort of modification to our memory improves it while we are trying to predict the effect of our plan on the outcome of the algorithm applied to our memory?</p><br><p>The core of the reasoning seems to be something like the following: CDT and EDT both rely on the assumption that the decisions that one makes in the world are isolated from each other, and in this case, trying to predict the outcome of the self-improvement would end up with CDT incorrectly predicting an improvement and then implementing the plan, with EDT incorrectly predicting a potential bad outcome for the self-modification and trying to make a rule-change instead of self-modifying as it might have been better to.</p><br><p>For both CDT and EDT, this sort of issue has been noted and dealt with by saying that the agent "does its best" when making predictions for the reason that it seems <em>possible</em> to take a meta-level action in order to self-modify. This means predicting that you will self-modify based on the decision rule that you <em>would make now</em>. This may <em>not</em> necessarily predict an outcome exactly like what CDT would predict, and not necessarily predict exactly the results that EDT would predict, but it seems sufficient to allow you to make the decision, without giving up on it.</p><br><p>Possible Objections</p>      </span>    </div>  </div></body></html>