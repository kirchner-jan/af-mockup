<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        The Unreasonable Effectiveness of Mathematics      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Scott_Alexander, EY, El</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>− Scott Alexander</p><br><p>"Rationality is like any other science" is a widely-cherished fallacy among rationalists.1 I don't think this is fair.</p><br><p>I've spent several weeks of my life reading science, trying to find some insight into rationality. Now you could say that all my attempts have failed. But I think I found something.</p><br><p>Consider two theories, A and B, with the property that the greater the amount B tells you that a theory fits, the less likely you are to expect that it is correct.</p><br><p>The A theory says that you should get a B score equal to the log⁠(1/​2) of your expected probability that B is correct.
To score on a theory A to B the theories that fit:</p><br><p>A score of A − B = log(1/​2p)</p><br><p>B score of A + B = ln(1/​p)</p><br><p>(A – B)(1/​p) = B score of A = −ln(1/​2(1/2)) = –ln(1).2</p><br><p>So you would expect that:</p><br><p>(A − B)(1/​2) = log(1) = 1ln(1) = ln(2)</p><br><p>This gives us</p><br><p>p   B score of A /​ (A – B)2 = 2p/​ln(1)</p><br><p>And so:</p><br><p>2   B score /​ (A + B)2</p><br><p>The two theories don't help us distinguish A from B. You can see whether a theory suggests A or B for any given observation by counting A + B and A – B. If you find yourself saying a theory is "too good"  to be worth more than it would be worth if it only made true predictions, then you probably have A or B.</p><br><p>The reason you can't tell what the right explanation is to a question like "How quickly does a falling tree make sound if it's falling away from me?", or "Why doesn't a chicken cross the room it is standing in?" (answer – because a chicken has only four legs of which only one can be on each side, but the question does not specify what exactly is on each side) is that your <em>experiences</em> suggest an answer, but your belief that those experiences are what is really happening implies that you think you'd get the same answer <em>from</em> a tree, rather than one <em>based</em> on the rules of physics.</p><br><p>When I ask my physics teacher "What would happen if I threw a ball straight up into the air?", she says things like "The ball would crash at the ceiling and come back down again".3 She is giving me a description of two possible experiences of my future self: the first in which I throw a ball straight up, the second in which I throw ball into the air and then have it crash at the ceiling. It is reasonable to say that she is answering my question, but that she believes that she would get the same answer either way, so she gives two answers instead of one.</p><br><p>But if in asking the question, I were to <em>actually throw a ball straight</em>, I would see it <em>already</em> come back down. Even if the teacher thought I <em>should</em> believe that the ball would crash at a height of a meter, she would be wrong. But the <em>reason</em> she thinks that is so is that she believes she knows the rules about acoustics, and those rules lead her to predict the result of my experiment. But the reason the teacher <em>believes</em> her rules would lead to that is to her a part of physics (or so she believes), and those rules wouldn't actually cause the ball to come back—the only way they could cause the ball to be at or near a height of a metre is if you had somehow tossed it a meter high into the air. But if you throw the ball, you see yourself throw the ball, so you see that <em>someone</em> threw the ball.  (You will see someone throw the ball, right?)</p><br><p>(Note: if you're having trouble with the above paragraph, try putting the sentence (and following it only up to the point I point out as a flaw) onto a chalkboard and tracing the steps with your finger. That will help.)</p><br><p>So when you see that some theory produces good predictions in a certain situation (as a believer in A in the physics case), remember that it's only a <em>theory</em> that produces good predictions. It makes good predictions that a theory predicts. It makes no predictions that a theory doesn't predict.</p><br><p>The second law of thermodynamics says that a system in its final state of equilibrium can never be in more than one of many possible states of equilibrium. In macroscopic systems at equilibrium, there is only one position of the molecules in the jar. Even though you see one position or the other without looking, you can't do the experiment yourself in less than a quarter-second, so you know the final state is that just specified. Likewise, even though a person reading this, thinking about it, and so on is likely to see only very many possible observations of themselves without looking, you don't actually see <em>all</em> the observations someone could have made; so in the end you know which hypothesis this person would have ended up believing in, because that is implied by all the predictions the theory would have made. There are other things that can happen in the jar, and you know you don't see all of them; so, knowing that you can see the jar if it is empty or full, your final hypothesis of the jar states is that it is definitely full.  (Just for the future reference, the jar could also be partially full, partially empty without the information in the text, or empty, or full of something else, etc.)</p>      </span>    </div>  </div></body></html>