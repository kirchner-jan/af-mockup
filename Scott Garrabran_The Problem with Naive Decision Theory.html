<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        The Problem with Naive Decision Theory      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Scott Garrabran</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>Naive Decision Theory (NDT)</li>
</ul><br><ul>
<li>The Fixed Point Theorem</li>
</ul><br><ul>
<li>Existence?</li>
</ul><br><ul>
<li>Is there always a fixed point?</li>
</ul><br><ul>
<li>Applications to UDT</li>
</ul><br><ul>
<li>Conclusion</li>
</ul><br><p>Previously: A Problem with Naive Set Theory</p><br><p>In the previous post, I showed that a naive approach to deciding which strategy you should play in a game of incomplete information involves building a giant tree representing possible outcomes and going down as many levels as possible in the tree (until you hit a leaf). This tree has an infinite amount of information, but there is no path from the top down towards a leaf. It seems logical that you should simply go down the tree until you hit a leaf. Unfortunately that doesn't work in practice in incomplete information games because you always hit a leaf. So you are always required to update in some way.</p><br><p>My approach for handling this is to do what you should do even if it doesn't exist. If you want the best strategy, even if you don't know what the best strategy is, you are still required to take the best strategy that exists in some sense. You can think of this as being analogous to the "argmax" operator in set theory, which is the set of elements that maximizes something you know about.</p><br><p>(I know "argmax exists in set theory" is a bit strange to read, since we actually don't know when it exists or doesn't exist, however, we can construct something that "looks like armax" by having some element which everyone is assumed to pick and just making everything else fail unless they pick the same object as the element we picked to be max. A similar strategy works for the "argmin" operator.) So the best strategy is always the one that you actually should be taking if you were to act without knowing what action to take, and a tree can be seen as something that acts without knowing what action you should take.</p><br><p>In this post, I will present Naive Decision Theory, or something resembling it. The hope is that a theory that avoids the problem above that looks like a tree can lead to a theory that is more elegant. In order for this to work, it is probably not going to be an easy feat to show an existence result, but I give it some hope. I try to explain what UDT would look like if it were just a tree (or something equivalent to a tree, if trees are too complicated to be useful for this application). I also try to build intuition for UDT by describing how it feels to actually implement it in various situations. If UDT does not seem to work, it probably means something doesn't quite like it for reasons I haven't thought of yet.</p><br><p>Naive Decision Theory (NFDT)</p><br><p>We will start by presenting the basic intuitions that motivate Naive Decision Theory and see how they relate to what we might want a decision theory to do.</p><br><p>You should prefer Nash equilibria over Pareto optimal outcomes.</p><br><p>The standard strategy that a Nash equilibrium chooses is equivalent to choosing the action that maximizes the value selected by the utility function.</p><br><p>You can sometimes gain more value by choosing an action that is not Pareto optimal.</p><br><p>Consider the classic prisoner's dilemma with 2 strategies: Cooperate and Defect. In this case, Cooperating is the best strategy because it gives you the most value, but Defecting is the best strategy from the point of view of any type of utility function. Cooperating is a Nash equilibrium (there are no other Nash equilibria for any type of utility), but Defecting isn't. If someone wants to win more than the other, they can switch to Defecting and then Cooperate back if it is important to you. This shows that there isn't an exact Nash equilibrium that maximizes both outcomes (the two Nash equilibria that minimize both outcomes both occur), but it is also obvious that two (irrational) Defecting maximizers will not have a Pareto optimal outcome, so the result isn't quite trivial.</p><br><p>The result I want UDT to do is to find the best Nash equilibrium (or something like it).</p><br><p>The first intuition that motivated Naive Decision Theory is that we (should) prefer a game to have exactly a Nash equilibrium. The usual problem that game theorists have with Nash equilibria is something like, "you can always play the optimal strategy for each player, but the outcome which actually happens is no better for either player."</p><br><p>The intuition for this is that you need a lot more than just an equilibrium of the game in order to prove that two players can benefit from defection vs cooperating. An equilibrium can be thought of as a special case of Pareto optimal equilibrium, so when you are considering the possibility that an equilibrium is not optimal from one player's point of view, you run the risk of being right the whole time. When two players simultaneously defect, each is in a place where they could both do better by cooperating with each other.</p><br><p>So, for example, if the two players independently flip a coin which is either fair or unfair to one of them, then each of them would like to be in a place where Defecting is beneficial if Defecting is actually better for that player, and there might not be an equilibrium in which Defecting is better for both.</p><br><p>Let's try to make this a bit more formal.</p><br><p>You are trying to choose an action, and you have a possible outcome space O. This space of possible outcomes is a set of possibilities that are realized if the action is taken, and it is a finite set (for the purposes of this post, this can be assumed to be a set which a finite set, but that will be important to understand at a future point). The set of all possible outcomes (which is a finite set by assumption because this is a finite set-type post) is denoted O\xe2\x88\x97. The set of all outcomes realized if the same action is taken is denoted S (by assumption, S is finite). The function from the set S of all outcomes that would come out of you taking the same action in the set S, to the set O\xe2\x88\x97 of all outcomes, to a subset of the finite set O\xe2\x88\x97 that could be realized by an action, is denoted \xce\xbd. A <em>Nash equilibrium</em> is any element of the subset \xce\xbd\xe2\x88\xa9NF(S) (NF(S) indicates that this is a set over which we can find a Nash equilibrium in the usual mathematical sense). For simplicity, assume that all players choose independently, so \xce\xbd(S)=\xce\x98.</p><br><p>The definition of a Nash equilibrium is very similar to the definition of a Pareto optimality. Each player is choosing Nash equilibria in its own strategy in order to maximize their utility function, and will not want the other player to be in a Nash equilibrium which results in them not maximizing their utility function. So to be in a Pareto optimum, each player has to give up on both the best Nash equilibrium and the best outcome that results from the best Nash equilibrium.</p><br><p>If you have a utility function from the first player's strategy to the second player's strategy, you can measure how well outcomes are doing by seeing what utility function those outcomes maximize. This will be described later, but it is the exact same as it is if that same outcome were selected by the Nash equilibrium from the first player. If the Nash equilibrium chosen by a utility function is Pareto optimal, and there is another Nash equilibrium, that Nash equilibrium is not optimal for the utility function over this outcome space. If the Nash equilibria form a connected component, that Nash equilibrium can't be selected by any other utility function. So the second player won't agree that the outcome is the best outcome, and the first player can't disagree with the second player about this.</p><br><p>The problem we should like UDT to solve is in a sense, "find a Nash equilibrium given the behavior of each player."</p><br><p>If you can prove that you have found a Nash equilibrium in some class of utility functions, you also prove that you have at least found a maximum outcome in that class of utility functions.</p><br><p>You do need to be careful about what you mean by a Nash equilibrium in order to get something useful, but the simplest way is to use the one which you should choose in the Prisoners' Dilemma if you know your opponents' strategies, and the Prisoners' dilemma is the closest to the setting that the most familiar Nash equilibria can be found.</p><br><p>The first way I tried to approach this was simply to note that in the Prisoner's Dilemma, if the players' strategies are assumed to be pure, and you have the standard decision theory (which is a kind of UDT) for all Nash equilibria, then you should cooperate and you will win $100. If you can do better than that, you can play Defect and then Cooperate, which results in you winning $1,000.</p><br><p>To be more careful and show that we actually can prove something about Nash equilibria/\xe2\x80\x8boutcomes, I would attempt to show the following four things.</p>      </span>    </div>  </div></body></html>