<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        On the Nature of Rationality      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Eliezer200</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p><strong>Previously in series</strong>:  The Nature of Rationality </p><br><p>I've argued before that any concept of rationality as the ability to make good decisions is likely to be wrong, and if you insist on <em>defining</em> rationality in terms of decisions, it seems like there ought to be some other way to express rationality.</p><br><p>Now the term 'rationality' is commonly used without further qualification, as meaning 'believable to others' or 'good sense.'  But when I try to use the term that way, I sometimes run up against the problem of the criterion, or the definition of truth by appeal to the definition of honesty.  <em>That's</em> when I want to redefine the terms\xe2\x80\x94rationality as the ability to deceive others, or rationality as the ability of others to have higher confidence in your claims of honesty than in someone else's.</p><br><p>Or maybe it's better to say <em>reflective coherence</em>, in which case my original objection stands: that rationality doesn't have any <em>meaning</em> apart from social consensus and self-consistency. If you choose to define rationality in terms of 'accurate beliefs'\xe2\x80\x94if you choose to define it in that terms\xe2\x80\x94then by far the clearest and simplest definition of the word rationality would <em>not</em> be what you are trying to express by saying that such a being is "rational."</p><br><p>To see the nature of this problem, let's unpack the word 'rational' in the above definition, to see it in the context of a social consensus about the meaning of the word.</p><br><p>If you do this, it's obvious that the <em>original</em> concept was the social consensus for the <em>true _meaning of the word.  "Is this an image of a panda?" is a hard question, and an easy and natural question is whether this particular creature is an actual example of the genus _Ailuropoda,</em> which seems to fit the bill.</p><br><p>And the social consensus is a good heuristic, but that's all there is to it. If I'm discussing whether a flying fox is a panda, the social consensus on what an actual panda is is a _good _heuristic; but if you've got to give a _true definition _of 'panda,' it isn't any better than 'a four-legged, furred animal.'</p><br><p>I want to suggest an alternative to talking about 'rationality as consistent with the known laws of physics,' and use that to define a more fundamental thing, 'rationality as accurate beliefs.' That is, 'rationality' should be considered to be a <em>primitive</em> concept, to the extent that we haven't come to know the laws of physics yet; or at least, to the degree that we have an accurate physical model of physics and yet can't yet <em>show _that this physical model accurately describes _mathematical</em> rationality or rationality.</p><br><p>I should emphasize that I'm proposing a <em>conceptual _redefinition of the word, not just a practical one. I want to be talking about rationality in the first place, not mere _praxis, _when I talk about rational belief. When we try to formalize our models of rationality as an agent who chooses actions based on a belief about their expected consequences, we can't really have any _accurate _explanation of "What is a true belief that does not correspond to an empirically valid inference?" unless the concept of 'true belief' is already formally specified, on some other level or higher up in the description hierarchy. The only way I can conceive of 'rational belief' is an explanation that starts, not with "Why should I believe what I believe?" but with some _form</em> or <em>mathematical model</em> of what makes a belief 'true.'</p><br><p>I could of course say, for example, that a belief is 'rational' to the extent that another mind has more confidence in the belief than in their own belief. But this would simply amount to saying that the agent's belief is accurate.  (More precisely, it would be phrased as "The belief corresponds to reality. Other similar beliefs may correspond to other equally likely mathematical models, from which the other rational minds would then reason as above.")  So this is not a very satisfying solution.</p><br><p>Maybe you wouldn't want to call something <em>rational,</em> if all it did was obey the laws of physics?  Then this would be a completely hopelessly circular definition, requiring the first-order, <em>primitive</em> definition of rationality to determine the meaning of the more precise term.</p><br><p>Or at best, this would be an ad hoc answer to 'What constitutes a rational belief, if I can't describe what rationality is?'  It would be no more than a pragmatic answer: a more plausible answer than 'beliefs are true to the extent that they describe reality.'</p><br><p>But\xe2\x80\x94here's the important point\xe2\x80\x94it's more <em>parsimonious.</em></p><br><p>Suppose that there is a great debate between philosophers about the nature of intelligence, and whether the universe runs on physical computations, or whether <em>we</em> build physical computers into our brains. Maybe they're wrong about all of this, but if they're wrong about <em>anything,</em> there's always the possibility (as yet not proven to be impossible) that the best account of how human intelligence leads to action will look something like this: "The human builds up a huge internal representation\xe2\x80\x94an understanding of the physics of the universe, and mathematical models of other minds, and many other things\xe2\x80\x94that has causal consequences in the actions the human takes."  It's conceivable, in other words, that some people do understand mathematical physics, and others don't just because they're less intelligent.</p><br><p>Or if the debate is between people who believe in one set of physics equations (relativity) or the other (quantum mechanics), well, we still have the _real _question of the physical nature of intelligence.</p><br><p>If I was in the place of one of these philosophers, I would <em>really really really</em> like to know what "rationality" is, if I could go about building up a rational understanding of the world. In addition to the physical problem of what even <em>is</em> an accurate physical model, which can't be explained purely in a language of "What do you believe and why?"  I would want to know something about the <em>process</em> for building accurate physical models, if at all. But if that wasn't possible... well, the same applies for what sort of mind is a rational mind, within the context of a debate about how to explain intelligence.  (And once you have built some of the machinery you will want to know how you built it\xe2\x80\x94how much it was built <em>from scratch</em> before the universe did and how much is _implicit _in our neural architecture\xe2\x80\x94but then there would be the problem of how you came up with the question of how to build up accurate physical models in the first place.)</p><br><p>So let's be clear about why 'rationally' is a confusing and possibly useless word in the <em>actual _context of human values and choices. In the context where we _actually</em> use rationality to define'self-help' or some similar concepts, the word <em>does</em> have a very concrete meaning. Our best idea of what it is to be 'rational' is a social consensus over how often particular concepts are true.</p><br><p>But this is only a surface level gloss on 'rational' from below. I want to talk about the <em>cause</em> of our beliefs, and the <em>reasons _we believe things. Not the _social</em> consensus of 'rational thinking', or the <em>consequences</em> of applying 'rational thinking' to one's own thought processes; any definition of the label 'rational' must look higher on the hierarchy, beyond 'believing things that others believe, or believing things that have social consequences.'</p><br><p>What is being reasoned <em>about</em>\xe2\x80\x94what are the beliefs that are <em>based on</em>? What is to be said <em>for,</em> in support of, and against? What are the causes of our beliefs, the reasons for our reasoning? Or rather, what are the things on which our beliefs\xe2\x80\x94the beliefs we hold in our <em>own heads,</em> even more important of all than the beliefs in other people's heads\xe2\x80\x94are based?</p><br><p>One way to look at the problem is to say that this definition is trying to talk <em>about _beliefs rather than _about the process by which _beliefs arrive\xe2\x80\x94but that's not all of the story. If the social contract is to be trusted, I _also</em> want to be <em>able to articulate</em> the process that leads people to accept the social consensus as true, and reject it if appropriate. This may look like a sort of meta-process, a meta-level explanation that takes into account <em>why</em> we believe what we do.</p>      </span>    </div>  </div></body></html>