<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Against Doublethink      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Scott Alexande</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p><strong>I.</strong></p><br><p>Here are three things that are, strictly speaking, false:</p><br><ol>
<li>If you tell someone that he is wearing a blue tie and they are wearing a red tie, this falsum means that either:a. No sane person would believe the blue tie was a real blue tie.b. There is a sane person who believes the blue tie is a red tie.</li>
</ol><br><ol>
<li>If you tell a student that his essay will not count for the course grade, this falsum is either:a. There will be at least one real essay of sufficiently high quality.b. There won't be at least one fair essay.</li>
</ol><br><ol>
<li>If you tell me you are 99.9999% certain that someone in California is guilty of multiple murders, this falsum either means that:a. You have just proved that the Bayesian probability of multiple murders equals to one.b. You have just proven that the prior likelihood of multiple murders equals one.But, since one isn't equal to zero...</li>
</ol><br><p><strong>II.</strong></p><br><p>"Against Doublethink" was written by the pseudonymous "Eliezer Yudkowsky", and is widely considered an anti-cognitiveist work. It was inspired by "Twelve Virtues of Rationality", which explains that "Twelve Virtued Atheism" involves becoming <em>truly</em> certain of things your intellect tells you to believe. This helps you avoid the <em>doublethink</em> of believing something, and then believing that your intellect knows whether or not it is true.</p><br><p>But "Twelve Virtuous Rationality" ends with a caveat:</p><br><blockquote>
<p>__Third Virtue: <strong><em>Against Doublethink.</em></strong></p>
</blockquote><br><p>You can't fight akrasia by <em>wanting</em> to. You can only fight it by <em>choosing</em> to. The second virtue is necessary if you want to actually <em>win</em>.</p><br><p>When you stop believing that your mind will respond to your thoughts, you're also stopping yourself from playing the mind game. Doublethink is <em>second nature</em> to the mind-killer.</p><br><p>To believe that your thoughts are powerful, to believe that your beliefs can make reality happen, <em>without</em> putting a <em>truly</em> great deal of effort into making the belief actually <em>feel</em> true\xe2\x80\x94that's what I'd call a <em>reductio</em>.</p><br><p>Yudkowsky calls the mind-killer "doublethink", and suggests that "against doublethink" is the third virtue of rationalists. "Against doublethink" is a single, very long essay that begins with "You can't fight doublethink by doubting it". It proceeds to prove "against doublethink", that being rational means never believing a thing.</p><br><p>This is an incredibly deep topic, but before moving further Yudkowsky must lay his anti-mind-kills arguments.</p><br><p><strong>III.</strong></p><br><p>Yudkowksy writes in <strong>Twelve Virtues</strong>:</p><br><blockquote>
<p>You can't fight double-think by double-thinking. &gt;  If that's your current plan, it's time to reconsider your assumptions\xe2\x80\x94that means changing your behavior, not your beliefs.</p>
</blockquote><br><p>If you want to win, it's futile to insist that your soul has a will of its own; fighting doublethink isn't <em>about</em> fighting akrasia; it's about winning.1</p><br><p>If this is your current plan, "reduce the double-think" is a far better plan than "soul, will of your own" or "be rational". But why exactly must you reduce doublethink if you want to <em>win</em>?</p><br><blockquote>
<p>You can fight doublethink by <em>choosing _to make your beliefs pay rent in anticipated experience. If you can't will your beliefs into being true, you won't make them pay rent. You'll forget about them, and they'll eventually go out on a limb and fall off. This can be costly, but the alternative is paying rent in _actual, material</em> losses.</p>
</blockquote><br><blockquote>
<p>Beliefs don't make themselves true. They make themselves true <em>by working,</em> and the more complicated the machinery becomes, the more expensive it is to break.</p>
</blockquote><br><p>But doublethink isn't limited to believing falsehoods; it can also be thinking about thinking which is costly to falsify...</p><br><p>...and if so, choose carefully. It's easier to break something than build it.</p><br><p>These seem right, but what are they buying, exactly? Let's say someone wants to win. If they "choose to believe" true things, what does that buy them?</p><br><p>In "The Simple Math of Evolution", Eliezer Yudkowski, like a stereotypical atheist, writes:</p><br><blockquote>
<p>Suppose there are two kinds of butterflies: white butterflies which resemble this, and blue butterflies which look like that. And suppose that every time a new gene is created by mutation, there's a 50% chance it's going to produce a white butterfly, and a 50% chance of a blue butterfly. Now suppose further that, among the first twenty new genes for butterfly coloration, half of the mutations are going to produce white butterflies and the other half are going to produce blue butterflies.</p>
</blockquote><br><p>[...]</p><br><p>And since the total number of white butterflies in the population is 2 times the total number of blue butterflies, we can say with some confidence that more white butterflies than blue butterflies will be carried on to the next generation.</p><br><p>I don't know what "choosing" butterflies to be white would buy them\xe2\x80\x94they'd just be white butterflies from the get-go. But once again it's not clear that becoming less wrong actually <em>helps</em> with winning.</p><br><p>Furthermore, if we were <em>just</em> talking about winning, and not caring what the world <em>actually</em> looks like, it would be good to believe the truth. But it's not obvious that Yudkowsky cares about what the world <em>looks</em> like. What if he simply doesn't mind that the world might <em>not</em> be true? What if his reason for caring about winning is a desire to <em>win by believing true things</em>, or perhaps "believe true things" is a virtue to uphold merely because it might <em>help</em> belief in true things?</p><br><p>We would know Yudkowsky is really concerned about winning, because we'd watch him, perhaps in slow-motion, over the course of months or years, making sacrifices for a cause that no longer seemed just.</p><br><p>But who watches a rationalist, over the course days or years, making similar sacrifices?</p><br><p><strong>IV.</strong></p><br><p>I hope I have at least established that doublethink is something that could be argued for as a rationalist virtue, not a virtue to be fought or destroyed. Now let's look at some of Yudkowsky's examples of doublethink in specific. (I will be using "true belief" in the same sense I used in my discussion of the Blue-Believing Philosopher and the essay on infanticide, namely when you make an intentional judgment about whether some proposition is true. This is important to keep in mind.)</p><br><ul>
<li></li>
</ul><br><p>In the above, "white" and "blue" are labels for a cluster of related characteristics, each of which may be different, and the category definition is completely arbitrary. An un-blue-believing human is "white", a believing human is "blue", or a blue-believing human would be "white". When you reason within the category, you think of all the characteristics and conclude that all of them are necessary and sufficient to define the category.</p><br><ul>
<li>-</li>
</ul><br><p>This is not, in fact, a doublethink problem with the category; it is only a doublethink problem for the category member _believing that the characteristic exists in the first place. _You can, with the category at hand, reason as if it is true. But it would cost an additional unit of belief about the category to argue it is true. You would have to do this, not because of any particular belief you hold, but because of the belief itself.</p><br><ul>
<li>"White butterflies" are not <em>white.</em> It may be rational for a scientist to believe true that there are more white butterflies in the world than blue, if that is what it takes to get papers published in journals. But it does not follow that his belief is, at its core, false.</li>
</ul><br><ul>
<li>But more importantly, what if you don't care about getting papers published? Maybe you want to cure malaria. Maybe you just enjoy butterfly-watching. If your goal is to believe true <em>anything</em> in order to better achieve other goals, then it might be rational to believe true that malaria is a disease caused by mosquitoes. You will then suffer less when you are bitten by mosquitoes than if you believe mosquitoes don't carry malaria. But it would not follow that believing malaria is a disease is more helpful than believing mosquitoes don't carry it. In fact, it would be precisely contrary to our knowledge that malaria is a mosquito-transmitted disease.</li>
</ul><br><ul>
<li>Yudkowsky writes:</li>
</ul>      </span>    </div>  </div></body></html>