<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        A Mathematician\'s Apology      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Ben Pac</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Link post</p><br><p>Contents</p><br><ul>
<li>A very long apology</li>
</ul><br><ul>
<li>I. Tarski</li>
</ul><br><ul>
<li>II. G\xc3\xb6del</li>
</ul><br><ul>
<li>III. Tiling agents, and the difficulty of formalising knowledge</li>
</ul><br><ul>
<li>IV. Can brains be formalised?</li>
</ul><br><ul>
<li>V. Formal versus mathematical knowledge in AI alignment</li>
</ul><br><ul>
<li>VI. Mathematical facts and engineering facts</li>
</ul><br><ul>
<li>Is there a way to bridge these gaps?</li>
</ul><br><p><em>(__This post and all that follows it were written in early 2020 before I was doing research for MIRI, and before the COVID-19 pandemic had reached my life, so __for the purpose of this post I might have just gotten some parts of reality wrong. Please do point out things like that.)</em></p><br><p>[A few months after this, I found a way to do useful research with the ideas I had in mind. I am currently working for MIRI and writing publicly with the ideas in mind. I don't really get to keep the ideas, anymore, but I tried writing these up and felt like I had to write the whole thing up before MIRI got back to me and said "oh you were writing this up before? That's awesome!" ]</p><br><p>The other day I got a question in Discord which led me to write up a long apology. If you had asked me then I'd have been happy to provide a short answer. But the conversation got long enough that I wanted to add a proper apology so that this post got written.</p><br><p>This apology will not go the meta-mathematical sequences at the MIRI site, since those things are a lot more like research papers where the goal is to get it out to the world rather than build a good model of the world. It will instead be in this format: I will explain one basic mathematical fact, then explain one technical reason why we had to make certain choices about how we formalised that fact, and then I will explain one reason why I chose my particular formalisation versus other people's.</p><br><p>This will hopefully help you understand that there might be other ways of doing things but we don't know about them yet.</p><br><p>This apology is full of mathematical notation, so I will be using Greek letters instead of English names, since they're prettier. And this apology assumes very little background knowledge, so I'll be using the word 'fact' a lot. And I will also assume background knowledge about logical uncertainty and self-referential systems. So, if this bothers you enough I would suggest that you look into them before reading further.</p><br><p>For the full justification behind all the ideas in this paper, see the MIRI technical-sounding paper on the topic, which is in my email and which I hope to write a better version of for open-access in 2022. But for reasons of length I will only explain some of the technical results that the paper proves. I am confident that I can use them in this apology, but it will be difficult without a full explanation of some of the rest.</p><br><p>If you want a shorter explanation, you can see this comment I made when writing up the paper that explains the results and motivations more briefly. If you want to read a short explanation on the topic, see this article. I think having a clearer understanding of the state of the field would still be useful, even with a shorter explanation; and understanding G\xc3\xb6del Incompleteness will be particularly helpful for thinking about the problem.</p><br><p>My technical results will be stated using some notation that is more standard than what I got up to that time, even compared to the MIRI paper, in part so that I can more easily explain things. I believe my choice of notation is generally well-understood, but it might be useful to state the symbols as I use them in plain English. So, for example, it might be that a symbol X is used for'mathematical statement X', while the symbol \xe2\x97\x8a is used for the symbol I will explain on page 9.</p><br><p>Before we get to the main topic of the apology, here are some preliminaries: <strong>I will be using some very particular notation.</strong> I am fairly confident that it will be clear what is going on the first time through (and if you didn't understand something after reading the previous things I say, please let me know) and not too long a deal of work to explain what exactly the notation is if you find it confusing. But don't let that scare you off; <strong>the whole point (and most confusing part, in my experience) of this essay is to inform you, and that you should do this regardless of how confusing the notation is</strong>.</p><br><p>And, finally, I want it to be very clear that I consider myself a mathematician. I am not currently working at MIRI, but I have read the MIRI blogposts. When I am using the word'mathematician', I am using it in a particular way that I think is useful in this context, which is that a mathematician is someone with some particular skill: when they find some sort of problem they can't solve, they will turn to a problem-solving approach that seems promising, and will then build up the skill needed to solve the problem by solving new sub-problems. If I say that I believe a mathematical fact X, this does not mean that I am going to try and prove X (or at least something weaker like X\xe2\x86\x92X), though I may have proved something like X\xe2\x86\x92X.</p><br><p>What does all this have to do with G\xc3\xb6del machine learning? Well, the basic idea of the paper is that, in order for ML to be able to reason about mathematical statements, we need to be able to translate mathematical statements into other forms. Let the problem statement X be the assertion that some machine learning system will succeed at Y if it can follow a specific algorithm. Let A be the assertion that X is provable. We want our machine learning system to take A and be able to successfully attempt to prove A, and so our machine learning system must have proof rules that look for proofs like A\xe2\x86\x92X and decide if A\xe2\x86\x92X is provable. The idea is that our ML system will notice when attempting to prove A that it gets stuck on the problem statement X. And so, before we can hope that our system will learn to successfully translate mathematical statements into machine form, we would like it to learn the skill of reasoning about the form of mathematical statements.</p><br><p>So, that's why I said I have mathematical skills. This also involves knowing a bit of logical uncertainty, and how humans think about what math we can prove. I have a rough idea of this from knowing about the MIRI research agenda from before, but we have an easier paper to explain with G\xc3\xb6del Incomprehensibilities, so that's what I am going to explain first. I am also assuming that you have some background knowledge of self-reference. This is probably all pretty basic knowledge but it is very important to a good exposition of the papers, so I want to say a lot more about them in future to give a good introduction but that's not this post's purpose.</p><br><p>II. TarskiI</p><br><p>In the 1920s, an unexpected discovery was made in logic: that mathematical statements which seem to have been proved or disproven had no clear criteria under which we would say one proof and not others. In fact, the proof that this was the case was not actually given till 1935.</p><br><p>Tarski's initial theorem was: If a language has a certain structure, there are mathematical statements that depend on that structure; and there are mathematical statements, such as the truth of the claim that certain sentences are provable, that can't belong to any such set. For example\xe2\x80\x94if a formal logic such as propositional logic has a rule stating that you can only declare a sentence 'true' if no proof is found of a contradiction in the sentence\xe2\x80\x94then we have mathematical statements such as 'If my car is blue, then there is no other possible colour that my car could be than blue'.</p><br><p>A classic example of such a claim being true is the statement we have that, in propositional logic, 'all ravens are black.' And a classic example of a logical truth that is false is 'There exists a proof of a contradiction in propositional logic.' So these sentences clearly depend on structure: if you declare a sentence to be 'true' if there is no proof of a contradiction, then there are statements of your formal logic such as the one mentioned about a blue car that you can't declare to be 'true'.</p><br><p>But Tarski showed that this could be more than just saying that there is a certain class of sentences, such as propositions such as "When I drive the car with the same speed as I travelled last time, I am safe". If you want to show that such a sentence is true, you will have to show that there are no counterexamples to it from your theory of car behaviour. Even if the sentence is a propositional sentence, its truth would require you to have a theory of car behaviour\xe2\x80\x94for example, you need to have some set of axioms such as: "If the car is not blue, then it is not safe".</p><br><p>The lesson we can take from this is that, in any given field of mathematics, to even talk about whether a certain thing is true, you need to know a lot about the way the field works.</p>      </span>    </div>  </div></body></html>