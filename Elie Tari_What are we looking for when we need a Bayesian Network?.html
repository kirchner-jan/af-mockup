<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        What are we looking for when we need a Bayesian Network?      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Elie Tari</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p><em>Epistemic status: thinking aloud, trying to figure out what I'm doing. I expect that this was already discussed several times on LW somewhere, since I got the idea to post it, and that it has already been covered in multiple posts. Still, I wanted to write it down so I have a reference.</em></p><br><p>Bayesian networks are a way of formalizing "reasoning." You've heard of Bayesian nets, right? I'm sure you have. They're the cool new thing; everyone is dying to talk about how Bayesian-like they are.</p><br><p>But Bayesian networks are cool the way that Bayesian statistics are cool\xe2\x80\x94with the cool new ideas, not with the cool statistics.</p><br><p>People like the cool statistics. Good for statistics, but that doesn't mean the cool statistics are cool.</p><br><p>Bayes nets are cool insofar as they allow you to "sum" variables that you don't know the real causal structure of, with the variables in your uncertainty network "believing" that they're only connected with the real causal structure given the data. You might say that these are the Bayes nets that really understand what they're doing and realize that many other nets don't.</p><br><p>This is cool, but that, while interesting, is not what people here are dying to talk about.</p><br><p>People have been talking about Bayes nets for decades, and it's now time for the cooler Bayes nets. We're looking for what has the biggest Bayes factors, what makes the most sense of the data, what can be built upon.</p><br><p>Here's something we may wish we knew: how are Bayes nets different from Markov Random Fields?</p><br><p>Markov Random Fields (MRFs) are Bayesian networks, but instead of thinking of the "data" as random, we think of the data as deterministically coming from the node whose posterior is being computed.</p><br><p>This approach is very different from a Bayesian network. It's not "reasoning like a Bayesian" in the sense that makes Bayesian networks cool in the first place. When we see a Bayesian network in an article about machine learning, we tend to get stuck by the fact that there are so many parameters, and they have to be estimated, and we can't expect it to be well-calibrated. We often feel the need to throw numbers at it and wonder if it's going to learn.</p><br><p>When we look at an MRF, we don't get lost. If it's not "reasonably calibrated," it's not "learning" to us. It's just not "reasoning properly"\xe2\x80\x94the random-walk approximation does a pretty good job, and so do the assumptions about the data. So, Bayesian networks, despite having fewer parameters and not being "reasonable" to us because they can't just "learn," are better than MRFs for most (all?) "real" uses of Bayes nets.</p><br><p><em>Explanation of this difference: MRFs have all their probability coming from the likelihood, whereas Bayesian networks have their probability coming from Bayes' theorem. If your likelihood function is the likelihood function of a deterministic network, you've got no way to "explain" what's going on. You can "understand" the output, sure: all you need to do is to keep computing the output. That is not the same thing as "reasoning properly." I think a lot of Bayes nets in machine learning are like this.</em></p><br><p>What makes this cool is that it's the <em>other</em> thing we are interested in. It's much more exciting to think about. Most cool Bayesian networks are not that interesting when you don't have that knowledge already.</p><br><p>One of the things I've been thinking about lately\xe2\x80\x94having now done four of them\xe2\x80\x94is a model of "explainability": why do people make mistakes using their model?</p><br><p>This model takes a Bayesian network, and gives a term for the number by which a Bayesian updates their probability of a variable having a specific value. If the probability updates by less than 1, they call it a "minimal-change-explaining update" (i.e. the update is not worth-while), and increase the probability by the number by which the Bayesian update exceeds 1, a "change-explaining-increase" (these are the updates that are worth-worthy, the Bayesians will use this to help decide which ones to change).</p><br><p>This model allows us to analyze Bayesian networks in a more Bayesian way. For example, in a neural network with dropout, you can change your probability estimate for a node that has a dropout of k probability to (1-k)<em>P + 3</em>k*P, and it will still perform Bayesian update.</p><br><p>But Bayes nets that perform changes are already a Bayesian reasoner: the reason that P(X=2 | B)=1/\xe2\x80\x8b3 + 2\xe2\x81\x843, is that Bayes (roughly) took the prior of P(X|B)=1/2 and applied Bayes again: P(X=X|B)=2<em>P(X=2|X!= 2)</em>P(X=X) P(X=3|X = 2)<em>P(B=X|X!= 2), which is equal to 4.9</em>P(B=2|X=2).</p><br><p>Now, Bayesian nets <em>are</em> cool because we can get a lot of knowledge from them, and the structure of the knowledge helps us reason about things that are outside of the random variable domain of the Bayesian posterior, but it's already been "Bayesified."</p><br><p>So, we've got a cool-Bayesian-yet-Bayesian model of explainability, but it doesn't have anything to do with being Bayesian; nor does it tell us about being a Bayesian.</p><br><p>Instead, it tells us things about what good models look like, and suggests how good models "explain" why the models behave the way they do.</p><br><p>For example, if we look at the above neural network, it performs a hard-coding into the model: every time you add a variable to the model, it assumes that the whole network will adapt its structure so as to make that variable more likely to be true, if the data is compatible with the structure of the hard-coded network. This is like hardcoding a likelihood function into the model, and then the model updates its likelihood function based on Bayesian reasoning, but it's Bayesian reasoning that was hardcoded into the model.</p><br><p>If we want to make a model that doesn't do this, we may do something like build a Bayesian Network in a way that lets you do updates more freely\xe2\x80\x94without having to hardcode specific likelihoods\xe2\x80\x94while still maintaining the nice properties of a network, such as "non-explosive" probability estimates. (See "How do you add structure to a bayesian net when you just know all the random variables, but don't know what causal structure they have?")  (See also "Eli's posts about bayesian networks")</p><br><p>So, as you can see, we don't expect Bayes networks to learn everything. I have not tried to design a Bayesian network which performs very well at learning, and have not seen any other attempts at doing this.</p><br><p>If I had a Bayesian machine learning model which learned at least as well as the state-of-the-art models, and a way to analyze it in a Bayesian way in terms of its Bayes net, then it might be worth-while to learn the Bayesian-net knowledge in order to build a better model.</p>      </span>    </div>  </div></body></html>