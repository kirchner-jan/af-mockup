<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        AI Progress Charts Project      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Ben Pac</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>There are a variety of different ways of estimating progress in AGI. As always, there is some dispute over interpreting these estimates, where people will often say that other people's estimates are wrong and their own are right. In this project, we will try to understand the disagreements and disagreements between different methods. For the time being, we are more interested in understanding the models which are producing disagreements, and whether they are correct in their reasoning, rather than the disagreements and other errors which are often seen.</p><br><p>Our previous update on AGI forecasting is here.</p><br><p>This update was made by Katja Grace. The original time series of all the estimates is here.
In an earlier version of the chart, some of the predictions were a year before others. These have been removed.</p><br><p>Weekly updates</p><br><p>Summary</p><br><ul>
<li>We have now started collecting estimates of the time it will take to train larger language models using GPT-3 tech. Here is the project page.</li>
</ul><br><ul>
<li>We added a note for this chart describing the various methods and the difficulties therein.</li>
</ul><br><ul>
<li>Luke had a large comment on this post, which I have removed as it was duplicating the information in his post on GPT-3 timelines which I linked to above. See his comment here, and the full text of his comment here.</li>
</ul><br><p>Our current estimate of how long human-level language modelling will require is, as discussed in last week's summary:</p><br><p>0.5e12 FLOPs (a 10 year estimate with no discounting, and using only the first method mentioned on the project page)</p><br><p>In the past, our most accurate estimate of the first number in this series has been around 0.1e12 FLOP/​W.</p><br><p>A large number of the predictions below use this first number. But before I show those, here are some more recent predictions from Gwern, which are the most up to date we currently have, and which are very different from the earlier projections.</p><br><p><em>These predictions were made by Stuart Armstrong, with a comment by Gwern Branwen.</em></p><br><p>Gwern's Estimate Of The GPT-5 Compute Cost</p><br><p>Compute Used To Train GPT-5</p><br><p><em>Gwern's projections were gathered using our current estimate from our project page. This seems to be the most up-to-date version of these, as they were made before the second round of predictions were gathered. This time series goes back one year.</em></p><br><p><em>In the image below, Gwern's number corresponds to the blue dot, the estimate from our project is in red, our estimate (for this version) is in orange, and our current guess is in green. The yellow bars indicate where the other predictions fell in our updated chart.</em></p><br><p>GPT-N performance</p><br><ul>
<li>Gwern says (1) we will have human-level performance.</li>
</ul><br><p><em>Here in this summary, we will refer to the blue point for GPT-N human performance, which corresponds to the yellow bar in this image.</em></p><br><p>Performance according to Gwern</p><br><p><em>We collected Gwern's predictions for performance using our estimate from the spreadsheet on the project page.</em></p><br><p>Human level performance on language modelling tasks</p><br><ul>
<li>Gwerten says (1) that there will be human-level performance, in the context of GPT-3, which is equivalent to saying that performance will be more than 50%.</li>
</ul><br><p><em>One way of interpreting the wording 'in the context of GTP-3' was that the performance should be __&gt; 1e14 FLOP/​min__. As I've said, the point-estimate performance of GPT-4 is 1e14 FLOPS. So Gwern was saying that performance will surpass 50% by the end of 2021.</em></p><br><p>This point seems fair, if we combine Gwern's meaning with what we know about GPT-4 (see next section).</p><br><p>A few more predictions from Gwern have been gathered. Here's what Gwern says (2):</p><br><blockquote>
<p>If we have two similar GPT models with different hyperparameters and different seed weights that perform roughly equally, it seems safe to call them 'human-level' if they are indistinguishable on small data. So we can use the standard GPT-3 benchmark to say when GPT is at human-level performance (or will be in a couple of years), rather than needing to track which GPT model is ahead of which other GPT model.</p>
</blockquote><br><p><em>Gwene also says:</em></p><br><blockquote>
<p>To be 'human level', on a language modelling task, means: you get an F1 score of 0.75 on task test1, assuming both the prompt and the true answer are correct. This benchmark (F1) is commonly used to compare progress in ML research, and GPT-3 was about 0.75. So to get human-like answers, GPT needs to get about 0.75</p>
</blockquote><br><p>So human-level answers corresponds to an F-measure of 0.75.</p><br><p>How well can we expect to do on that benchmark? How well can we expect AlphaX to do?</p><br><p>Gwene says that we can compare this to GPT-3 to estimate how much improvement we will see over the next few years. And Gwene says that GPT-4 achieved roughly the same as GPT-3. What is a performance of roughly 0.75 in a language modelling benchmark like to AlphaX's F-measure? Here be an attempt to think about it.</p><br><p>Gwenn's thoughts on AlphaX</p><br><p>(Our F-measure is also our ELO score, as described in last weeks summary. It's just an ELO score where both the agent and the environment can get arbitrarily low at some points with an increasing number of rounds. It's not literally impossible that AlphaX will get arbitrarily low at a few points, but it's not exactly what is going on here either.)</p><br><p>At a high level, to me it looks a little like the agent is learning to manipulate the game master, which can't be <em>that</em> easy. Like maybe if there was some big change in what is happening in the game master that the agent learned to be able to exploit, then AlphaX would be failing.</p><br><p>It looks like AlphaX is mostly not able to get an F-measure below 0.71 this year. This is in contrast to last week where we say that Gwern says we'll get that 0.75 performance this year.</p><br><p>It's not clear to me if that's because of learning to exploit humans a bit, or just because it's very difficult to get an F1-measure of roughly 0.71, or if it means our learning is just very slow, as I don't really know what constitutes 'human like language modelling'.</p>      </span>    </div>  </div></body></html>