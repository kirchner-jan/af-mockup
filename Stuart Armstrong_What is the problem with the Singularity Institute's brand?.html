<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        What is the problem with the Singularity Institute's brand?      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Stuart Armstrong</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>I think there's a problem with the Singularitarian brand in that the term gets used in different ways (sometimes being confused with it's cousin, the Singularity, which I think has slightly different, although similar ideas). But first of all, the Singularity Institute itself seems pretty happy to use the term and there's clearly nothing wrong with its meaning. So instead, I'll discuss what it seems to mean, as we see below, and what it could mean.</p><br><p>To be clear, we should be cautious about the word 'Singularity'\xe2\x80\x94a simple Google search turns up some pretty dubious results. Also, there's a risk of it being overdefined so it's best to avoid using it. For example, even 'AI' can, technically, be used for just about any 'nonhuman artificial intelligence'. Instead, I'll use 'Singularity' to refer to the future period between the present, and the development of machines that are as smart or smarter than humans.</p><br><p>So, what do I mean by the SI's brand? Here's a start. One of the most interesting things about the organization is the level of independence and control it has. It seems very clear that SI isn't controlled by Eliezer\xe2\x80\x94indeed it was almost an accidental setup (to Eliezer's dismay). And it seems a fair point to say that SI does do things its own way. It's more than willing to change course, and to try to break old habits and ways of looking at things. In other words, it's doing things in-house which Eliezer thinks are pretty smart. So we should expect some independent thinking at SI, and we should expect the organization to continue to be successful over a long period of time. And if the organization continues its success, it will be because it chooses the right path to take. This, in my mind, is what SI's brand should be.</p><br><p>A somewhat different point, is that in previous discussions, Eliezer has tended to avoid the topic of ethics. In general he seems concerned with trying to help, and doesn't see these things as particularly interesting. I find that hard to take as a sign of anything, and I would be wary about trying to take it as evidence about the SI's beliefs. There's also been a bit of a back-and-forth between SI and other organizations about ethics and why they need to be concerned with ethics. I have very mixed feelings about this approach. I do consider it to be pretty smart in general to be concerned with things like how to make AI systems that are friendly to the humans that control them, which is one of the main things we'll be discussing in future posts on the subject. But I don't particularly think of it as SI's thing to be working on; there doesn't seem to me to be enough of a clear connection between it and SI's other activities.</p><br><p>So that's the first thing that seems positive about SI's brand. Of course, any positive thing we should be pretty careful about\xe2\x80\x94people use anything that sounds positive about SI just to attack us. So now onto the second item: what are the 'Singularity-related' issues that the Singularity Institute is probably most responsible for\xe2\x80\x94and what are the ones that a few other organizations like MIRI, GWWC etc would be equally good at, and would be more likely to be the most successful? I'm sure I can't come up with a complete list, so don't worry about it too much.</p><br><p>I'll give two reasons to think that SI is probably not going to succeed with any specific strategy: First because there are so many ways to try to solve this problem that all seem plausible. And second because SI is not very good at identifying which of those strategies have the best chance of success.</p><br><p>For the first point, I think we can all agree on one thing\xe2\x80\x94if we have a 'Singularity', then it's going to be something that is an unprecedented development in the history of humanity. That's what SI talks about, and that's the thing to aim for. That's not the only approach that SI could use, but it can certainly be useful. This is certainly not the Singularitarian ideology. And it seems to me that there is a general belief that the Singularity is something a 'Singularitarian' should be trying to influence. (There's some disagreement about when the Singularity should happen, but that's a topic for another day.) If it's not something that SI should be spending time doing, then it should be some other organization.</p><br><p>Now, for the second point. SI is clearly skilled at coming up with new ideas, but it often seems to be bad at identifying the best of those ideas. Some of the most promising approaches to the Friendly AI problem involve the creation of 'tool' AIs that are designed to help humans, but which aren't actually capable of running the world themselves. It seems clear to me that these kinds of AIs would need to be much safer and more closely monitored than they currently are. That is, it seems clear to me, that if anything of this type were to be created, we should expect it to be designed by very smart people, but who are still not fully aware of the pitfalls and dangers associated with what they're doing.</p><br><p>Now of course this all assumes that we actually get to the Singularity at all. Some say it's not going to happen for another thousand years, and at that pace SI might be able to produce a few safe and useful AIs and then leave the problem to some other organization to solve. This would presumably require being really careful both with how and what AIs were designed, and what safeguards they were given. And of course it would need to be done well or, really, it wouldn't be good enough. I'm guessing that a lot of SI's work would have to be in trying to find the correct approach, and in trying to convince more people within the existing organization of the correct approach, as well as trying to get existing people who aren't already involved in the SI community on board. This is a difficult job, and it could certainly be done better.</p><br><p>And here's the thing\xe2\x80\x94SI could potentially do good work on these methods (and the work in finding the correct methods would be a huge part of the work), but it's not going in the direction of the problem because it doesn't think that trying to fix it itself is the highest priority. Some people are now trying to influence the SI to be more effective, but I find that a less likely option.</p><br><p>So here is my conclusion: if the definition of 'Singularity' is anything like SI's then the problem seems to be with SI itself, not the Singularity. Some of the other organizations working on these problems are not perfect, but I would be pretty worried if they weren't at least better.</p><br><p>I hope I've said some things in this post that improve your impression of SI, which is something they have already done. It seems more important for them to continue that effect than to continue to have their brand\xe2\x80\x94so it might be useful for them to update to a more SI-like brand. They might want to look at this post as a friendly suggestion of that nature.</p><br><p>There's a lot more I could write about SI's brand (which it would be interesting to have a discussion about), but these are all the ones that occur to me off the top of my head.</p>      </span>    </div>  </div></body></html>