<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        The (ir)resistible rise of deep learning      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Scott Alexande</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p><em>[__Epistemic status:__ I wish I could believe this is true, but I've seen enough holes in deep learning papers over the last year to convince me that this is probably mostly false.]</em></p><br><p>Once upon a time, there were no neural networks. Before the 1980s there wasn't any software; before 1980 there wasn't commercial software.</p><br><p>One of the main problems with this story is people's tendency to see a particular set of facts about the computer world and assign the story to the entire modern era and everything that happened in it. They see some new technique with a fancy name and decide that this must be what the deep learning revolution was about. As an example, here is a list of common myths about deep learning and deep learning, and how they turned out to be mostly false.</p><br><p><strong>Myth #1</strong>: It was invented in the 1980s.<strong>False:</strong> I was using deep learning stuff as far back as 1980, like so on page 1359 of an earlier paper from the same authors. (You can find it in the volume "IEEE Transactions on Computer Systems", though it's in the older edition.)</p><br><p>__Myth 2: There's this one cool breakthrough that took over the field of machine learning.__False: There's this cool breakthrough that takes over every field except machine learning, such as the following facts.</p><br><p>\xe2\x80\xa2 We can read DNA sequences.</p><br><p>\xe2\x80\xa2 The first person to do a sequence analysis was a guy named L.L. Wallace \xe2\x80\x93 who you've heard of because \xe2\x80\x93 and in the early 20th century there was not that much attention being paid to how DNA worked, and so he got a fair amount. But eventually, in the 1960s and 70s, it became clear that DNA was not a set of simple letters but actually contained instructions to help make new cells.</p><br><p>\xe2\x80\xa2 In the 1970s, researchers figured out how to extract the information stored in DNA into an electronic format, called the "sequence database".</p><br><p>\xe2\x80\xa2 In 1973, it was revealed that DNA contained a "sequence of letters" that could be used to make a copy of the same molecule from scratch, called a "replication fork"</p><br><p>\xe2\x80\xa2 In 1974, it was discovered that proteins were actually a type of molecule that carried out some of the functions of DNA.</p><br><p>\xe2\x80\xa2 And in 1975, it was discovered \xe2\x80\x93 from many different lines of evidence \xe2\x80\x93 that genes were what made up the blueprint of living things.</p><br><p>But there's no such thing as one small breakthrough that takes over a field. Machine learning research took off in the 80s because at the time, "machine learning" meant computers being put to the task of learning how to do tasks automatically.</p><br><p>Maybe you don't feel this way about deep learning, and that's just a fluke. Maybe this post is enough to destroy deep learning for you. But if it isn't, you should be aware that if there's one thing that can be said with overwhelming certainty about deep learning, it's that it wasn't invented in the '80s \xe2\x80\x93 and also not invented before the '60s, '70s, or '00s.</p><br><p><strong>Myths about deep learning #3:</strong> The same mistakes occur over and over. In one way this isn't that surprising \xe2\x80\x93 there are mistakes you repeat over and over again. But in another way it might be surprising. Machine learning researchers seem to have a fundamental lack of imagination, and so whenever they see a new idea, they just think "This idea is just like every other idea \xe2\x80\x93 computers have better and better at learning tasks \xe2\x80\x93 so if it works, it'll be like any other AI idea."</p><br><p><strong>Myth 4: A lot of current research on deep learning, such as deep double descent and deep convolutional nets with max norm layers, weren't around when it happened.</strong></p><br><p>False. The deepest double descent papers were published in 2001 and 2002, and the deepest convolutional neural network paper was from 1989. The only deep learning study published in the late '90s is "Survey of Neural Network-Based Classifiers" (not a deep learning paper but a generic classification paper that talks about neural networks in general). There were also a few papers out as late as 2000 on the more modern technique of recurrent multilayered networks, but they weren't in a generality paper and just talked about single-layer networks. (The study on recurrent multilayeral nets is still somewhat useful but not very deep.)</p><br><p><strong>Myth 5: Current neural networks are fundamentally different from the computer programming approaches like the ones we used in the '60s or '70s.</strong></p><br><p>Fascinating question. I've heard this from lots of people. But we have to ask: which computer program was fundamentally different from the ones used in the past, and why? People used them before, people use them today. I know of exactly one such program that was fundamentally different from past versions \xe2\x80\x93 computers were vastly faster then so we could run many more examples. (I'm sure there were others, like the '70s-era programs being much harder to parallelize.)</p><br><p><strong> Myth #6: Neural networks aren't general learning systems.</strong></p><br><p>This is probably an interesting question, but it's also an interesting question whether learning systems at all.</p><br><p>Modern machine learning systems like image recognition are actually very hard. It's been argued that the major contributions in natural language processing, word vector embeddings, and translation have been in making it <em>possible</em> for machines to recognize images and natural language.</p><br><p>At the same time, AI researchers have successfully used these techniques with impressive results. People often note that in the case of image recognition they achieve similar results to humans, but in the case of natural language processing, translation, and so on they consistently outperform humans. I don't know exactly why this is. Maybe humans are just unusually bad at image recognition and natural language processing, except that human performance at image recognition, natural language processing, and translation is a lot more variable than human performance at these other tasks in the past. Or maybe this has something to do with training and architecture.</p><br><p>But either way, it's a fascinating question. I like it, actually. So I thought I'd go on a fact-finding mission to see how many interesting misconceptions about deep learning exist in real world.</p><br><p>Here's another: <strong>Myth #7:</strong> <strong>Machine learning is just a big set of ad-hoc tricks from the '80s.</strong></p><br><p>This is the most common myth, that deep learning research is full of ad-hockery and that it takes a ton of hacks just to get it to work in real time.</p><br><p>Is it like this? Sure. I'll go through the major ones.</p><br><p><strong>First, some ad-hockeries:</strong> Deep networks use a trick called backpropagation to discover how networks should change layers of their network. There are several variants on backpropagation, but the "simplest" is probably the one called the "stochastic gradient descent algorithm". First, you initialize all the weights to 0. Then, at each time step you calculate "gradients" on layers \xe2\x80\x93 in other words, compute changes at each layer to all layers. You then use those changes to change the weight values. (The changes themselves are not determined by just gradient descent \xe2\x80\x93 they're generated in a special loop that uses the back propagation.)</p><br><p>If you are a computer programmer and you have never heard the term "backpropagation" before, you might think it's weird. Why would you calculate the gradients for the backprop algorithm, when that's what a normal gradient descent algorithm does? But you can still do "normal" gradients descent, and it will still work, because backprop works like any other gradient descent algorithm. It just happens that backprop is one of the "best" (most effective) ways to do gradient descent that exists. It's sort of like how humans invented the bicycle or the computer mouse, but it's still a good bicycle and it's still a useful mouse.</p><br><p><strong>Second, the "stochatic gradient descent algorithm" (aka learning by passing examples through the network) does well (but not well enough) at image recognition.</strong> Here's another video, that's an amazing demonstration of the process. It's an image classifier trained with image examples. It shows the first time it recognizes a picture of a dog, then a time where it tries again, and then it finally gets it on the second time.</p><br><p><strong>A third ad-hock:</strong> There's a learning algorithm call "dropout" that causes all neurons with very low activation (like below 0.001) to not change their outputs at all (but the other neurons not affected by the dropout will still continue changing). Basically, it helps prevent overfitting. It works by using a "weight decay" scheme where if a neuron's weight goes too high (too close to 1), it starts decreasing a little bit at a rate that depends on the absolute value of the weight (so if it goes too high it accelerates) and if it's too low it starts decaying faster.</p><br><p>Dropout is generally regarded as one of the most important ideas in deep learning, one not widely known or appreciated outside specialist publications. And no wonder, because many non-specialists are skeptical it even works in the first place. It has always been an odd thing because it does work in many machine learning setups. For example, it's successfully used in a variety of different image classifiers.</p>      </span>    </div>  </div></body></html>