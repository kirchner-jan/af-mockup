<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        chieving a Technical Explanation for Technical Explanation      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Rob Wiblin and Robert Wibli</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>This is a post about how you can get much more value out of a technical explanation than a non-technical one, if you are skilled in understanding technical explanations. It's inspired by some posts on Less Wrong over the last couple of years, especially "The Least Convenient Possible World", and by the work of Daniel Kahneman and Dan Lovallo on explaining decisions.</p><br><p>The example case I will be using is explanations given by a person with advanced technical skill\xe2\x80\x94as opposed to non-technical explanations given by scientists and doctors, for instance. Note that this is an empirical claim about our ability to understand technical explanations. I am not claiming that anyone with less technical skill than my own doesn't understand technical explanations or doesn't give any explanations.</p><br><p>I have made some changes of format, trying to make the post more readable and engaging.</p><br><p><strong>Background</strong></p><br><p>Technical explanation of a technical explanation (hereafter technical-technical-explainer)</p><br><p>A technical-technical explanation is one that is understood by (in other words, believed by) a technical skill, i.e. a level of technical understanding that can be passed through school and/\xe2\x80\x8bor graduate education in the field.</p><br><p>For instance, if a person had undergone an undergraduate degree in physics, they can probably understand a physics explanation of quantum mechanics. Not everyone with the required technical understanding knows quantum mechanics, but they could at least understand what that type of explanation is.</p><br><p>A person with advanced technical technical skill, though, is one who can understand what a quantum-mechanics level explanation is, and that they believe in those explanations in their heart of hearts as a result of their technical understanding. That person could give an appropriate level of confidence to their understanding of the explanations.</p><br><p>If a technical skill person's knowledge gives them the ability to explain a technical skill well, they could give an account of the underlying technical skill, in a way that other technical skill people could understand.</p><br><p>In the example case I am using, the technical-technical explanation and the technical skill are the same thing, with the technical-technical explainer being highly skilled in the technical skill, and the technical skill being quantum physics.</p><br><p>What about explanations that people with no technical skill at all give? I say that they can provide enough technical-technical explanations to allow a technical skill person using all of their understanding of technical explanations to understand those explanations.</p><br><p>This is obviously an empirical claim, and that brings us to the next section.</p><br><p><strong>Empirical evidence</strong></p><br><p>There is considerable empirical evidence in favour of the claim that technical explanations can be understood much better than non-technical explanations. The fact that we could understand quantum mechanics so far is strong evidence in favour of my claim that someone with a technical skill, who understood the underlying technical explanation, could give a technical explanation of quantum mechanics that we could understand. I will summarise some of the relevant empirical evidence below.</p><br><p>Daniel Kahneman and Dan Livallo list four reasons why explanations given by people with advanced technical skill can be more convincing than explanations by others. The fourth of, in my opinion, the least importance but the most insight-for-understanding. It is evidence in favour of what I am claiming, because it means that there was some important factor influencing which explanation we picked.</p><br><ul>
<li><em>It is easier to understand technical explanations than non-technical ones.</em></li>
</ul><br><ul>
<li><em>It is possible to evaluate explanations of different types qualitatively.</em></li>
</ul><br><ul>
<li><em>There has been more cognitive testing of the kind that Kahneman and Lovallo are doing; it could influence what technical skill people find most important.</em></li>
</ul><br><ul>
<li><em>Many of us have had some amount of experience with technical explanations.</em></li>
</ul><br><p>The first reason given above\xe2\x80\x94that people with technical skills might understand technical explanations better than non-techial ones\xe2\x80\x94could apply to any explanation rather than just technical explanations. Non-technical explanations by scientists and doctors can have this effect, as I said in my previous post. But the second, third and fourth could apply to technical explanations. And it seems that the second and third factors might also apply to technical explanations by scientists and others.</p><br><p>The fact that (from my perspective) we understand quantum mechanics well is also a reason to accept that someone with technical skill can understand physics well. The fact that physicists don't explain quantum mechanics to laypeople, because they don't understand them, is not a disproof of my claim. It is actually consistent with it.</p><br><p>So, there is plenty of empirical evidence in favour\xe2\x80\x94in my opinion\xe2\x80\x94of the claim that technical skill at explanations of technical explanations can be useful.</p><br><p>Note that what I'm claiming is that understanding a technical skill gives us the ability to understand technical-level explanations of a given technical skill. The question really is whether understanding a technical skill is really that important. There is much more to the skill of explanation than understanding technical explanations. For one thing, understanding mathematical proofs is not the same as understanding proofs. It has all sorts of different effects on our ability to understand mathematical proofs, which could have knock-on effects (for example, when explaining proofs of results of mathematics, people using technical skills are more likely to say things like "we just proved theorem 4.2.2.2 (The Four Color Theorem)", which is more readable than most written proofs). However, it seemed to me that understanding technical explanations of technical explanations might be of a lot more use. So, I'm only claiming that if someone has the relevant technical skill, they can probably better understand technical-technical explanations than non-technicals.</p><br><p><strong>A further empirical claim</strong></p><br><p>In my last post, I said:</p><br><blockquote>
<p><em>To understand quantum mechanics well, someone with a technical understanding of it needs to be in a situation where they can test the hypotheses of quantum physics, and the ability to understand quantum physics improves our ability to do this.</em></p>
</blockquote><br><p>If I was able to make a technical model of a particular phenomenon using quantum physics, I could predict what experimental results would be seen if I ran that model, just as if I had a technical model of any physical process. When you understand the physics, you understand which questions to ask, and how to answer them. And there are ways to test the answers to those questions. In physics, that is. But when I come to a discussion about anything involving technical concepts, such as climate, biology, chemistry, or the economy, I don't really have a clear idea of what questions to ask or how to go about it. What am I trying to predict or what's the evidence that would count? I have vague ideas, but they're vague\xe2\x80\x94they're not well defined. I have a much clearer idea of how I can test what I believe if I'm talking about something like the Four Color Theorem of graph theory in mathematics.</p><br><p>This supports the claim that understanding technical explanations gives you the ability to understand what questions to ask, what evidence to look for, and how to go about answering the questions.</p><br><p><strong>So why haven't you tested that on climate, or chemistry, or biochemistry?</strong></p><br><p>I would expect that in science there has been a lot of very careful testing of what questions to use and how to answer. I can imagine that the situation with climate science has been very different. The field started fairly small, and scientists have been reluctant to test their hypotheses. Even in climate science there must have been some testing, otherwise there would have been evidence of global warming from 1970s onwards, when there wasn't.</p><br><p>It's important to note that it's entirely possible that understanding what questions to ask in technical fields can be quite different from understanding the things scientists and engineers would really want to understand, such as how things work. I am only claiming that understanding technical-level explanations gives us the ability, where we would otherwise not have it, to understand that kind of explanation. I'll go into more detail about this in the next section. </p><br><p>I think the fact that it would be different in scientific fields is in favour of my point, but it isn't strictly necessary. As long as there are technical fields where we can understand some of the underlying technical principles (such as the underlying physical or electronic principles of chemistry), but not all, we can still use that understanding to some extent to understand scientific explanations. </p><br><p>And maybe there have indeed been attempts to build theories of things we know about in quantitative detail, but don't know much about, such as in chemistry and biology. But the evidence for the claims I am making is stronger than the evidence for those.</p><br><p>But you have to use that understanding to the fullest extent to understand what questions they ask, what evidence they test for. That's my main contribution to AI, for instance. I say that a technical person with a technical knowledge of a given technical field has the relevant technical understanding to explain concepts in that field. The claim is that by understanding what questions to test for in a given field, they can, potentially, understand how to explain those concepts in that field, almost as well as a "genius." And that's my main contribution, although I have done a few other things to add to it, such as writing the AI Alignment Forum sequences.</p><br><p>Technical explanations vs. non-technical explanations</p>      </span>    </div>  </div></body></html>