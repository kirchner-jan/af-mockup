<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        A Very Long Post About Bayes      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Jacob Falkovic</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Link post</p><br><p><em>For a non-fiction blog, I write quite a bit of poetry (currently 16 verses). What kind of poetry do I mean by that? I've mostly used it as a form of fiction:    It's all set in my head, but it's set to a standard meter, has rhyme &amp; alliteration, doesn't rely on the reader believing in my character's feelings, and in my own head is much more poetic than it is in real life.</em></p><br><p><em>So what's the point of this? As it's not poetry, I'm not expecting that it'd be interesting to the LessWrong reading public (except maybe for those of you who are fans of my previous work, and thus also of poetry).    But I do anticipate that this post will serve as an introduction to the concept of Bayes, and thus will serve as an introductory step to a lot of the LessWrong articles on the subject. Bayes is a general solution to problem set in many sciences, as well as the art of rationality: it's how we build accurate models of the world in general, and the LessWrong hivemind in particular.</em></p><br><p><em>What's a Bayesian? Well, I'm a fan not in the statistical sense but the philosophical one \xe2\x80\x93 I like reading about the process and the ideas, not the results. I like the idea of an algorithm that gets better all the time as it gets more information. What makes a Bayesian algorithm most interesting is that it never "stops." It's always getting stronger, even if it seems to be on a plateau that can't be moved</em>.</p><br><p><em>To start with a concrete example, let's do that. A Bayesian would try to understand this. How can they do better? There's only one key piece of information here \xe2\x80\x93 that the last card is red. The only prior knowledge required to work out its significance is general knowledge of the set of cards, whether it's a poker game or a deck of cards. Even if you've never played poker, you can still use this Bayesian approach. There's always a "chance" that at least one more card you'll get \xe2\x80\x93 red in this case \xe2\x80\x93 that will make the other six all red, that will move the probability mass on red from 0% to 100% and thus save the game.</em></p><br><p><em>This is because when we consider red to be independent of the other cards with respect to their distribution \xe2\x80\x93 that is, each red card, by itself, has a 50% chance of being in the game \xe2\x80\x93 a more accurate statement is that the odds are 50\xe2\x81\x8451, or 51\xe2\x81\x8450. When only one card is unknown and not very likely, the odds can be approximated as 1:1. Thus, for example, the odds that there are two red cards in a poker game are (50% \xc3\x97 50%) + (50% \xc3\x97 51%) = 10150 =.5 +.5 or.5 * 3 = 1.5</em>.</p><br><p><em>Poker games only work if everyone plays perfectly: if half the players bet on red and the other half bet on black. In the event that black wins, then the same holds true \xe2\x80\x93 the game is still worth a bet even if there's a non-zero chance black will win: the odds against black winning are still 1:1. Therefore, any time you're considering wagering money on a poker hand, the correct "Bayesian" estimate is to assume that every player in the game will play black, and multiply, not add.</em></p><br><p><em>To apply this concept to rationality, it's not enough to say that we want a system of rationality based on logic. If the logic that we're using to create our beliefs doesn't let it go from 50% to 100% or a lower number to 100%, then that won't get us to where we can trust our beliefs. It's hard enough creating accurate models of the future using logic \xe2\x80\x93 if we're stuck with inaccurate beliefs, we'll end up with suboptimal actions, which is exactly the opposite of the most rational thing to do. A much better path would be to have a "Bayesian" method of choosing actions that works regardless of how the world turns out.</em></p><br><p><em>In the real world, probabilities are very rarely 1 or 0. Every time you're creating any kind of model of the world, like predicting the outcome of a poker game with any likelihood whatsoever, you should use a Bayesian approach that will update your model in response to information. You should never leave a Bayesian approach untouched and use the same model no matter what information comes in. What's important is to understand that model, and update it accordingly.</em></p><br><p><em>Let's apply this to the case of our rationality. When we try to make accurate beliefs using techniques like math and science or probability theory, an important tool in our toolbox is Bayes' Theorem. This is because no matter how strong the evidence is, the amount of evidence matters: the more hard data we have, the stronger our evidence must be to have a high probability. The theorem's name, by the way, is from the Dutch word "bayes," which is a word you will recall from the beginning of this post (we're back to the beginning of the post now).    The equation here will look familiar from the beginning: P(blackwin|red) = (P(red|blackwin) * P(blackwin)) /\xe2\x80\x8b (P(red) * P(blue &amp; red &amp; blackwin) + P(black win \xe2\x88\xa7 blue) * P(red) * (1 - P(blue &amp;red &amp; blackwin))).    This equation, incidentally, was invented by Bayes' good friend, mathematician Reverend Thomas Bayes and it should go without saying why you'd want to check his formula for accuracy.</em></p><br><p><em>As you can read on, the equation itself is a lot less important than the method of applying it. A Bayesian can make any other model of the world using the same formula, regardless of how good that model is, simply by changing the input probabilities. This is called "model comparison" and is what a Bayesian can use to estimate if their starting beliefs are correct, given new evidence. Model comparison is extremely valuable \xe2\x80\x93 not only in forecasting, of course \xe2\x80\x93 but in other parts of thinking about the world.</em></p><br><p><em>Before delving further into the mathematical details of how to use Bayes to make estimates, let's take a step back and ask what we can take away from this whole post. First of all, it's worth noting that the ideas of the Bayesian model are much easier to remember than the equation. The mathematical equations in most textbooks and papers are hard to remember unless you're already a frequentist. For our purposes, though, more important is what we can apply these equations to in the real world. We want to maximize accuracy of our models by using a Bayesian approach. Second, that seems pretty solid to me. However, is there anything else we can take away? Let's see. One important lesson that Bayes gives us is that the model we want to create isn't a static snapshot of what we believe; instead, it's a process. We need to start out with a belief, and then update that belief in light of new evidence as it comes in. Bayes' Theorems allow us to make these updates mathematically, and, thus, more accurately. Third, Bayes' Theorms have some very important real-world applications:    We can use them to evaluate the accuracy of our theories, and to improve our theories by making them more accurate, by making them less wrong. But I've mentioned those too much already not to mention that we can use them to make predictions, to improve our predictions by making them better, and so on and so forth; the ideas here are not limited to theory-building! Finally, Bayes' Model Comparison can help us figure out our initial beliefs, and we can figure out what we can do to improve those beliefs, whether it's updating them on new evidence or coming up with other ways to improve our beliefs.     Bayes is a very helpful word to get in the habit of using: it helps us recognize areas where we feel confused and uncertain, it gives us a concrete way to calculate correct answers, it lets us compare multiple pieces of information using model competition, and Bayes can improve our understanding of the world by giving us tools to evaluate and compare our models.</em></p><br><p><em>If you've made it to the end of this post, you'll recall that Bayes' Theories of rationality are important enough to be part of my ongoing research and so should also help explain a lot of the things about Bayes I've talked about previously on this blog as well as in my books</em> <em>On Intelligence__ and</em> <em>Predictably Weird__.</em></p><br><p><em>The original version of this post contained much more than I used in this posting, and most importantly it contained a lot of technical and mathematical background. I tried to incorporate most of it into this one, omitting only the mathematical and statistical definitions. It's still available in the original version of the post if anyone is interested, with a link to the original post. I'm very much planning on using the "long form" version of this post to explain more of the statistical and theoretical background of Bayes' Theoretical Framework.</em></p>      </span>    </div>  </div></body></html>