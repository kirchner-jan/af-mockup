<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Historical philosophers often didn\'t like each other      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Eli Tyre and Scott Aaronso</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p><em>This is a series of posts I'm writing to help people understand how much I disagree with Robin Hanson's recent book Human Compatible, and so I thought I'd try and describe the sort of disagreement between us that I thought made sense to explain well in a few posts. But, before I get there, I wanted to try to clear up some of the confusion around the book's contents. What's the argument in Hanson's book? What's the argument against Hanson's argument?</em></p><br><p><em>This post is a summary of what I see as important parts of Robin's book, and my reasons for seeing what I do. I hope to make it clear how different I think the book is from a typical philosophy paper, how much Robin disagrees with the popular scientific literature on how our cognition works, what I think about the significance of the book, and how much I don't think the book's claims about rationality are that important</em>.</p><br><p>"Rationality: Whence Rationalization?"</p><br><p>(I strongly recommend reading the original chapter, and thinking about what's been written about the book since then).</p><br><p>This chapter is about the cognitive skills of rationalization. By rationalization, I mean the ability of humans to justify and argue for positions that are known to be false. One of my claims in the literature review below is that Robin and other philosophers who claim that humans are irrational are making a specific mistake; for them to understand the literature on rationality, it's important to read the literature on cognitive neuroscience. Robin argues that, while many philosophical arguments (and psychological studies) make the mistake of focusing on explicit reasoning which humans can "see", the modern cognitive literature shows us that humans can't see and explain things like the neural representations of words. So we should focus on what's in brains; to study rationality, we should study the processes by which beliefs are formed.  </p><br><p>_So, first let's get a bit more formal. Rationalization occurs when someone changes their mind in response to evidence. Robin is concerned with two forms of rationalization, those that can be seen and those that cannot be seen, the former I will refer to as conscious rationalization, the ability to change one's mind because of new information:</p><br><p>1) <strong>Conscious</strong> <strong>rationalization</strong>: If someone can see the reasons for changing their mind, a more interesting sort of rationalization occurs when someone chooses to change their mind out of ignorance of the new evidence. This sort of rationalization results in conscious belief changes; examples of this include someone's inability to accept a proposition like "if aliens descend upon Earth and replace Americans, the American Revolution would have been a bloodless coup," or "if there were no such thing as free will," or "if the world were much bigger than it currently is."</p><br><p>2) <strong>Intuition-based</strong> <strong>rationalization:</strong> <strong>We</strong> <strong>know</strong> <strong>intuitions</strong> <strong>are</strong> <strong>a</strong> <strong>sort</strong> <strong>of</strong> __evidence___, yet we often reason based on intuitions without consciously aware of what's going on. In "Against Intuitions," Hanson describes this process as follows: When one believes it to be obvious that a certain belief is true, and that intuitive belief is indeed obviously true, this gives the belief a "nod-of-firm-belief" feeling, despite no justification that can be offered. We can imagine a case where the brain processes a nod-of-firmer-belief feeling to the belief that an airplane will fly before it crashes, even though we can't directly point to its presence in the brain\xe2\x80\x94all we can see are its presence in memory.  (When we speak of an "intuitive belief", this means that the belief "floated into our heads" in a way that wasn't conscious to us, but which seems obvious to us after we have held it for a short time).</p><br><p><em>In the paper, he argues that people are actually much more biased in the other direction than has been previously discovered, and that when we use introspective awareness, this can be an effective way to avoid rationalization. But my preferred way to think about the literature on introspection is that most of the studies don't really study introspective awareness, and so that is what we should be concerned with as philosophers, rather than the biases of the sort demonstrated in he paper. What I find most interesting and surprising is just how widely the literature on cognitive psychology is applicable to rationalization. When we go with the flow of the arguments, we get interesting things</em>. <em>Let's go with that.</em></p><br><p><em>Let's start off by looking at the first claim (conscious rationalization) that I have some disagreement with Robin</em>. _</p><br><p><strong>Conscious Rationalization</strong></p><br><p>Robin tries to find a way of making conscious rationalization impossible given the way that many different cognitive processes (such as visual processing, language processing, or memory storage of visual and language data) are distributed across the brain, but I don't think this is possible.</p><br><p>How do I see this? The brain does a large number of different cognitive functions, such as processing words, processing images, storing memories, thinking about different things, imagining and trying to make plans. It seems to me that the fact that different information is stored in different brain areas is what grants humans their ability to be able to interact with the world; the fact that people process information in such different ways allows for different brain areas to encode information. For example, the human ability to use language involves the visual information the brain stores encoded as the representation of a speech-sound and an abstract representation of the letter being pronounced, which can be encoded in the brain in different places, such that a person can generate the same speech sound without seeing the letter or making the same letter sound.</p><br><p>The human brain is not a unified system. People with different abilities often process information through different brain areas. This seems like necessary for human-level intelligence, for the same reason that human-level intelligence seems to require a number of different skills: people need to be able to understand the world around them in order to have a high-level understanding of how things work in a society, for example.</p><br><p>You can have conscious beliefs. You can communicate to others about your conscious beliefs. This doesn't mean that the beliefs themselves are conscious. It means you have beliefs about things <em>relative to a particular way of experiencing the world that lets you be more efficient in your ability to do different things, and that this world-relative-consciousness only comes from the conscious beliefs you have.</em></p><br><p>You can be wrong about your conscious beliefs: you might think it's obvious that a certain way of thinking about things is correct, but it turns out to be incorrect. You can even be wrong about the correctness or incorrectness of your conscious beliefs about the world relative to other ways of thinking about the world. But being wrong about your conscious belief can't undermine the validity of the underlying real-world beliefs: the beliefs could still be right.  </p>      </span>    </div>  </div></body></html>