<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Rationalizing, Motivated Stopping, and Motivated Continuation      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Will MacAskil</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>Intro</li>
</ul><br><ul>
<li>Examples</li>
</ul><br><ul>
<li>The problem with motivated stopping</li>
</ul><br><ul>
<li>Motivated stopping vs motivated continuation</li>
</ul><br><ul>
<li>Conclusion</li>
</ul><br><p>Intro</p><br><p>There is this problem where you have some argument for X or against X, and you're willing to accept/\xe2\x80\x8breject X in exchange for some other outcome. But then you feel guilty about rejecting/\xe2\x80\x8baccepting X in this way. So instead of accepting/\xe2\x80\x8brejecting X, what you do is avoid thinking about the issue at all, pretend that the truth is just about evenly balanced between X and Y, so that nothing needs to be done to decide your view.</p><br><p>I call this problem of choosing to avoid thinking about certain issues in favour of the balance of equal option sets "rationalizing". If you are rationalizing, it means that you think you've avoided thinking about X as much as your opponent thinks you've avoided thinking the balance of options.</p><br><p>When I first wrote about rationalizing, the people who read these posts were primarily talking about how often the people with politics tend to rationalize about those of different policy positions. I should maybe have called this problem of different policy positions "motivated stopping" since stopping to think is what motivated people to do with their thinking in the first place. But I wanted short names for these, and "rationalizing" had less negative connotations. So I've re-named the problem from "rationalize" to "motivated stopping".</p><br><p>The problem with motivated stopping, and a more motivating name for the problem of rationalizing, are both important. But rationalization still has its place, for two main reasons:</p><br><ul>
<li>It might be <em>wrong__.</em> Motivated stopping only happens when there is no reason to keep considering a certain issue, or it doesn't even occur at all unless there are lots of reasons to be concerned (for example, you are in an adversarial situation with someone and the balance of reasons to be convinced favors the other side).</li>
</ul><br><ul>
<li>By focusing too strongly on the problem of rationalization, you risk obscuring your attention from things that are more important for winning. The problem of rationalization can be taken <em>completely</em> out of the "argue philosophy with yourself" bin by focusing on it a lot.</li>
</ul><br><p>Examples</p><br><p>I'll give a few examples from different areas of philosophy, in order to emphasise that both the problem of rationalisation, and the problem of motivated stopping, happen in lots of different fields and subfields.</p><br><p>In the realm of philosophy of science, there's a common argument that the burden of proof is much higher when science claims to be about things that humans invented than when it claims to be about facts in the natural world. But the same argument can be used to convince us that we can't believe in supernatural monsters, or in invisible dragons in our garage. So there's a motivation for scientists to choose which kind of claims can be believed and which cannot, without thinking about that very question.</p><br><p>The problem of rationalization is also really easy to observe in philosophy of religion. People rationalize that their belief in God is so obvious that nobody could be against it. This is particularly obvious because it's the one area of philosophy where philosophers have unusually good access to themselves through written records. So their rationalizing explanations are easy to check.</p><br><p>Sometimes rationalization is less noticeable, like when people just don't care about an issue. Someone may not care enough to even notice when you criticize them or show a counterexample to their position. Even someone who genuinely doesn't care may rationalize, by thinking that <em>someone else</em> has to show that they care, by engaging with them.</p><br><p>In this case, a rationalizing answer is often simply the best response that would actually work, at least in some situations. Maybe if someone's talking nonsense, they'll fall into error. So rationalizing may be justified even if you aren't a perfectionist. This kind of rationalizing is more likely be observed in everyday situations like this. For example, if you want someone to have something ready the next day, it may help to rationalize that it's your job to get them ready, since they would be the one who would complain if they are not ready.</p><br><p>Another area of philosophy where rationalizations can be more common is metaphysics. The problem in this class is harder to avoid. You could say "Well, we can't know so we have to stop there" and maybe there are metaphysicians who would do that, but then their real beliefs are in practice far more metaphysical than yours. Or it could be that metaphysicians think that metaphysical explanations are easier to write (because they are less constrained), and so more people get interested in metaphysics.</p><br><p>The rationalizing approach to motivated stopping applies even to cases where the problem is due to lack of knowledge, the case for (or against) X due to an inability to get knowledge of X despite trying really hard. It has to do with a desire not to think about the issue, not necessarily with a lack of knowledge of X itself. It can apply to cases where you are motivated to learn about X, but you really don't want to learn enough to know whether X is true or not.</p><br><p>The reason that rationalizing is less common in areas where we have less knowledge, even when the same process is involved, is that knowing about how the balance of reasons favors one way or the other in different situations can be useful if you want to change your behaviour. It comes from practical knowledge about how to balance a set of reasons.</p><br><p>When you know that there's no good reason for anything <em>except</em> the balance of equal consideration, and you don't feel like you are being rational. I think that cases where people are unable to reach conclusions or get stuck <em>in those cases</em> are more likely to be caused by a problem of rationalization than lack of knowledge.</p><br><p>The usual method for combating rationalization is to keep your evidence in mind, and focus on the balance of reasons. But sometimes it is possible to do better. I wrote about this a bit in the article on motivated stopping, but the most impressive examples are:</p><br><ul>
<li><em>Pascal's Mugging: the classic case in which the problem of rationalize is obvious.</em></li>
</ul><br><ul>
<li><em>The Repugnant Conclusion: an often-hidden argument for negative utopias. If you think there's always good reason for doing something, there might be good reason to actively want to eliminate life.</em></li>
</ul><br><ul>
<li><em>Parfit's Hitchhiker: a thought experiment in which a person could accept or reject paying to save someone from getting killed. In real life, if I think the probability is low that the person in front of me was a hitchhiker, and the expected utility of me paying is high, I might pay.</em></li>
</ul><br><ul>
<li><em>Eternal Inflation: a thought experiment where I ask the same question again and again and again, until the numbers converge on a value.</em></li>
</ul><br><p>There are other cases which I don't yet know how to formalise, such as cases where we try doing some action because we think that will bring our preferences more into line with those of others (e.g imagine changing your mind about whether to have children to bring the amount of utility that an extra person has more in line with someone else), or cases where we are not at peace with the idea of X but nonetheless strongly desire to be able to have X even if it is against our moral judgement (e.g to convince the president). I think that cases like these are also more likely to be due to a problem of rationalizing.</p><br><p>The point of these cases is that I hope that they will give you hope: there are cases in which your default choice is in fact not just reasonable, but actually rational, because by your own reasoning, you can see that there is a good reason for it. (I would also encourage you to come up with ones of your own that you think meet the same criteria). This is also a useful piece of empirical evidence that rationalizing isn't universal, and helps to motivate a more open-minded process.</p><br><p>The problem with rationalizing, and the name for motivated stopping, are useful to be aware that there's a problem, and to motivate you to continue or stop trying to "avoid" thinking about a question. But there's a second purpose of naming the problem which is different from that. There is a purpose of naming the thing itself. A problem of biased cognition might also be called biased cognition if that's a more accurate label. It's very hard to be rational without acknowledging that rationality requires making errors sometimes.</p><br><p>The problem of rationality doesn't change if the thing that you were doing was <em>actually</em> rational. It's more important whether it is in general <em>good</em> to make the cognitive biases that all people face more salient. These can become self-fulfilling prophecies if they are not noticed and addressed (e.g by having people in authority explicitly point out our common psychological issues). So naming rationalization also motivates the desire to try to solve the problem of how to be more rational.</p><br><p>We can think of rationalization as a special case of motivated stopping: in order to rationalize, you have to not believe or care that the balance of reasons that you're rationalizing with is favoring one way or the othe. So motivated stopping is also potentially a good candidate for an anti-rationalization tactic. In particular, some of the anti-rationalization techniques that I wrote about in my last post seem useful there: focusing on what you want, not what you think you want, keeping a balance between the two.</p><br><p>Conclusion</p>      </span>    </div>  </div></body></html>