<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        On the Utility of Pre-registering Experimental Results      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">John Wentwort</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Link post</p><br><p>A couple months ago, I wrote an essay about using Bayes as a language for communicating uncertainty about results of experiments. That essay focused mostly on communicating uncertainty, e.g. "if I did this experiment, I'm very uncertain what the answer was, maybe it was 100% chance the answer was false or maybe it was 0.01% chance it was false."</p><br><p>In that article, I hinted (for reasons I don't recall) that the Bayesian perspective helped translate uncertainty into frequencies, or probabilities of particular experimental outcomes.</p><br><p>But I didn't talk about preregistration: how this translated uncertainty into information about the outcome of the experiment before that experiment was run.</p><br><p>Preregistration has been talked about a lot in the rationality community, both for formal experimenters (such as medical researchers) looking to avoid publication bias, and more broadly for journals looking to signal trustworthiness. It's probably been discussed a lot on LessWrong too? I'm just really bad at finding good references.</p><br><p>(This post is mostly inspired by the recent discussion of whether preregistration in medicine would be accepted/\xe2\x80\x8bwelcome or not. In my mind, that discussion is the same as using Bayesian statistics to translate "the experiment might turn out false" into "0.01% chance this experiment will turn out false". So that is my intended interpretation, and I'm not particularly arguing that the LW community views it that way.)</p><br><p>What sort of evidence do we care about?</p><br><p>As an example, consider the experiment described here. A random patient is being admitted to the hospital and treated with a new medication (which we'll call 'placebo' for simplicity). The patient's doctor feels uncertain about whether the new medication works, and she wants to take this fact into account in her treatment decisions. In particular, she wants to not treat placebo-responding patients if &amp; only if drug therapy has been tried before, as a first line of treatment, and that treatment failed.</p><br><p>The doctor's uncertainty is expressed as a probability distribution over possible outcomes:</p><br><p>Here's the point where I stop liking this diagram\xe2\x80\x94if the prior on the doctor's belief is that 'drug never tried before and works 90% of the time' then the diagram would indicate that that the doctor should treat placebo-responders 90% of the the time. Whereas I would be much more interested in the doctor's belief about 'treatment never tried before and fails 10% of the time', or something like that.</p><br><p>So the key question is: what do the doctor's beliefs actually look like? Presumably, she has some evidence that either way... but now that the prior is fixed, what evidence?</p><br><p>The experimental evidence has already been performed! We can translate it into a Bayesian update, but we should really be concerned about a prior already containing the fact that 'the treatment fails 10% of cases'.</p><br><p>With a prior like that, Bayes tells us to weight each treatment by its relative likelihood. Thus, if you know that placebo works 90% of cases, and you still treat every case given a placebo treatment, then treating this patient like they have a 50% probability of needing drug therapy, you get the right answer.</p><br><p>Which is all well and good, but it doesn't make sense if you haven't preregistered the outcome and the treatment information, so there is no relative likelihood.</p><br><p>I don't think preregistration actually gives us a <em>precise</em> prior, but it does give us <em>information</em>. We don't want the doctor to treat _this _patient, because 10% chance the treatment fails sounds like a reasonable prior in general. But we do want to take into account the fact that, if it is 10% chance that the treatment was tried and failed 3 times, and it was a new drug, then we have evidence that the new drug probably works 95% of the time. I think most doctors would think they should weight a treatment like that as '90% prior, 5% evidence', which translates into 5%:</p><br><p>We would like to translate uncertainty about that experimental evidence into a <em>prior distribution</em> over experimental outcomes, rather than using an object-level belief about how likely 'the treatment has been tried before and failed three times'.</p><br><p>More generally, the purpose of evidence-based medicine &amp; the scientific process in general isn't to reduce uncertainty like that: it's to find good priors for the experiments (or prior distributions over the distribution of experimental outcomes, if you prefer). It's fine to have '90% prior' beliefs for treatment that you use every day, but you shouldn't be fine with them coming from experiments where you have <em>no</em> information about the treatment yet.</p><br><p>This applies not just to doctors, but to experimentalists and journal editors\xe2\x80\x94if you have no evidence for something, it's evidence of <em>something</em>. If you don't know what the evidence is, this means you haven't studied the issue, or even taken it seriously when relevant.</p><br><p>The real world</p><br><p>Now back to the real world and the problem from earlier \xe2\x80\x93 a doctor who wants their patient to get good medical care <em>may</em> have an incentive to hide poor experimental evidence from the prior. But that isn't the only reason a doctor might present a patient with good-looking evidence, or present experiments with bad luck or bad data. And I haven't even talked about patients who reject good medical care, or the case where the experimental treatment is actively harmful.</p><br><p>It's fine to have an understanding of the problems that prevent some evidence from being properly translated into a prior, such as publication bias, or poor experiments, or some bad luck or something. But if we're interested in <em>overall</em> quality of medical care\xe2\x80\x94a doctor could do something with a patient for the wrong reason, but at least the patient got good medical care\xe2\x80\x94the <em>overall</em> information about the experiment is relevant.</p><br><p>So if someone <em>does _have an incentive to hide bad experimental findings from the prior, then the next question is _still</em> whether preregistration is useful as a way of addressing that. If preregistration reduces publication bias, then it's nice. If it doesn't, well, the reason it's worth the time and effort of preregistration isn't because it eliminates publication bias by reducing the amount of information it takes to translate that good evidence into a prior.</p><br><p>It seems to me that there's a genuine tradeoff between 'how good does the evidence need to be to do better' (which is about how much we trust the prior after updating), versus 'how much time and effort is put into ensuring the experiment is well-run'. These are legitimate and useful questions as well, but that doesn't make them different from our previous discussion about communicating uncertainty to the journal editor. And the overall picture for medicine is pretty good: journals don't tend to hide published information, but they also don't have many quality checks (or, even if they did, many people with access to the published research would _not _be able to see those checks).</p><br><p>To sum up, I think preregistration <em>can</em> reduce the information required for a doctor to make good treatment decisions, but it's not clear it <em>does</em> \xe2\x80\x93 and in some situations, it might actively increase the cost of making good treatment decisions. As with other good Bayesian tools, it's a tool that can be <em>used wisely</em>.</p>      </span>    </div>  </div></body></html>