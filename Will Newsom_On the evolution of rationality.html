<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        On the evolution of rationality      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Will Newsom</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p><em>This isn't necessarily an alignment problem; the whole point of this series is that MIRI is trying to develop rationality. But it is related to alignment and I figured I would include a link to a relevant comment. I am still fairly new to posting here, so if I mess anything up please tell me.)</em></p><br><p><strong>Discussion</strong> _and ___Edit__</p><br><p>I have to admit I am puzzled how nobody was convinced that the process of Bayesian rationality that MIRI was talking about could not possibly have come all at once in one instance in the course of human history. How many times did you need to say "I have the feeling you're trying to use a different definition of rationality than I do\xe2\x80\x94what did you <em>mean</em> by Bayesian rationalism?" and then have the other person not be able to answer you. I'm not saying this as an idle troll\xe2\x80\x94if you read this post before reading the rest of this series, you can imagine it in your own mind as you read it.</p><br><p>Let's re-state the points of my series in the beginning so we are all on the same page:</p><br><ul>
<li>There are four different modes of thinking possible in humans.</li>
</ul><br><ul>
<li>For human evolution, only the default "tool" mode of thinking was possible.</li>
</ul><br><ul>
<li>No matter how far back you go, no matter how intelligent a species becomes, it will never be able to think in two different ways at the same time.</li>
</ul><br><ul>
<li>No human has even <em>known</em> about the other modes of thinking. They are not recognized as existing. And there are no ways of knowing whether an animal will invent Tool Mode thinking or not. (So most humans live in a world created by Tool Mode.)</li>
</ul><br><ul>
<li>It is only possible to achieve Tool Mode thinking by an intellectual process called "inference" (which includes reasoning, the scientific method, deduction,...).</li>
</ul><br><ul>
<li>A process of inference is not itself an intellectual process. To engage in the process of inference you have to abstract. There are levels of abstraction we've never even <em>known</em> the <em>existence</em> of. And there are meta levels of abstraction over meta levels of abstraction.</li>
</ul><br><ul>
<li>An intellectual process is something that does something, or else you wouldn't call it an "intellectual process". And an intellectual process that does nothing isn't something you'd call "intellectual".</li>
</ul><br><ul>
<li>The "tool" mode thinking that humans have evolved has <em>all</em> the features that you would expect to see in something that does nothing. That is: humans evolved to abstract their reasoning in Tool Mode. It is a "different kind of thinking" (Tool-Mode) than any humans have ever done before. (But a <em>different kind</em> of reasoning than any other non-human animal has done before.)</li>
</ul><br><ul>
<li>The two other modes of thinking we have evolved have no such thing as (reasoning +) abstraction. That is: Tool-Mode has (reasoning + ) abstraction, but the other human modes do not.</li>
</ul><br><ul>
<li>If you haven't ever seen or heard the other two human modes of thinking before and <em>never will</em>, then the Tool-Mode mode of thinking seems like magic to you. You have the feeling you are understanding something mysterious and important, and there's a hint of fear and awe in how you imagine it\xe2\x80\x94a hint of what the future of artificial intelligence might be like.</li>
</ul><br><ul>
<li>The two human minds have, in fact, been around for tens of thousands of years. We don't know what it was like for an animal to be able to think Tool-Mode without abstraction, nor do we know what it was for Tool-Mode to suddenly become imaginable after so long. The two situations are very different and the two modes of thinking are not psychologically related in any way.</li>
</ul><br><ul>
<li>One of these two things happened to be true:</li>
</ul><br><ul>
<li>The evolution of Tool-Mode happened <em>after</em> the evolution of all the other modes of human thinking.</li>
</ul><br><ul>
<li>There was a psychological development in humans around the time when Tool-Mode happened\xe2\x80\x94an intellectual development that caused Tool-Mode to be possible and Tool-Mode to become the only possible type of thinking.</li>
</ul><br><ul>
<li>So we have no way whatsoever of knowing whether the Tool-Mode came first, or whether all the other modes were created <em>after</em> Tool-Mode.</li>
</ul><br><ul>
<li>When the Tool-Mode was invented, there was some part of the human brain which already knew about Tool-Mode, and it had already created in its mind abstractions/\xe2\x80\x8bmodels that it has now called "reason'". Those abstractions/\xe2\x80\x8bmodels will be the basis of the tool mode (which is just a fancy way of saying they will be what is created when we reason using Tool Mode).</li>
</ul><br><ul>
<li>The Tool-Mode abstractions/\xe2\x80\x8bmodels can be inferred in retrospect from the other forms of human thinking. That is: we can make inferences about humans who used Tool-Mode reasoning long ago, but also about hypothetical non-Tool using animals, and so on.</li>
</ul><br><p>This is already all quite hard to get down. I don't want to make this even harder to get down in the comments. But let's just ask the most fundamental question:</p><br><p><em>After</em> the Tool-Mode abstract model was implemented in the human brain, what was in the brain such that it would be <em>known as Tool Mode reasoning?</em></p><br><p>And this question was answered:</p><br><p>_The brain was implementing a mode of reasoning where it abstracted its thinking over and above its immediate experience. _</p><br><p>Which answer is actually much worse than the preceding explanation, just because the explanation is so much harder to explain. And let's not forget that even after you've written it this way, the question doesn't feel like you're asking a question: it feels like you're trying to make an opinion.</p><br><p>The question of this post has a lot to do with the question that has been floating in the back of my mind for the last three or four blog posts, what we can call the <em>rationalist's core question</em>. The reason a person might decide to become a rationalist is that they feel they need rationality in order to have some of the following beliefs:</p><br><ul>
<li>X.</li>
</ul><br><ul>
<li>Y.</li>
</ul><br><ul>
<li>Z.</li>
</ul><br><p>Or even:</p><br><ul>
<li>A.</li>
</ul><br><ul>
<li>B.</li>
</ul><br><ul>
<li>C.</li>
</ul><br><ul>
<li>D.</li>
</ul><br><p>And in this sense the rationalist's core question can be regarded as the <em>fundamental, underlying question about Tool-Mode thinking that makes Tool-Mode thinking possible in the first place</em>.</p><br><p>Now, it seems completely reasonable to me that many people reading this might say, "Ah, nice! And where did it come from? And where did the theory of abstraction come from? Tool-Mode was something developed by humans. When did it start being able to develop and how do you say it evolved? Surely you can't just make stuff up, like a magician."</p><br><p>(Oh, and the next part. <em>Where the heck would an abstract</em> <em>model come from, it's not like there was a super-natural explosion of knowledge around this time, right?)</em></p><br><p>(And, of course, there was a big scientific revolution in all sorts of different fields in the 18th and 19th centuries, so we can't rule out that the origin of the tool/\xe2\x80\x8babstraction abstract model came from human research in these other fields, but we can't <em>know</em> that either, so... and also the whole reason we asked this question in the first place is that there has to be some <em>something</em> that could potentially be known, so... you know what you get if you ask this kind of question? I don't know.)</p><br><p>As for a different perspective to the question that many people seem to have on Tool-Mode, it is actually a perfectly respectable reaction:</p><br><p><em>Ok, Tool-Mode is cool, how can I make sure my kids learn it, I want to be a real parent. If you don't know how to teach Tool-Mode, how can I just trust that you will be able to in my kids? I see the good in you. I trust you to bring love and wisdom to those you teach.</em></p><br><p>(And that reaction to Tool-Mode being cool could perhaps be the reason for the recent shift in the public image of rationality. It used to be that the goal of rationality was to be rational about some <em>specific</em> things, and now people have moved towards having the idea of rationality that rationality just <em>is</em> the ability to make good decisions in general, including decision-making for one's personal development, because for some reason that's how Tool-Mode thinking feels to many people. But of course no abstract model can be used to answer the question "How do you decide which abstract things and skills to develop and which ones to let go, depending on what your goals are?" I'm not saying that this is right, I'm just giving it as a perspective of someone who already has a good understanding of Tool-Mode.)</p><br><p>Anyways, back on the subject of Tool-Mode.</p><br><p><strong>I.</strong></p><br><p>I've already alluded to the idea that Tool-Mode should be distinguished from <em>reasoning in the abstract</em>. But how can this be done? This is the question that comes up every time you make another attempt to explain the concept of Tool-Mode and make it clear how it is different from reasoning in the abstract.</p>      </span>    </div>  </div></body></html>