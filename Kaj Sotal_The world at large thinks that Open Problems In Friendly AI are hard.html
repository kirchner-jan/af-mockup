<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        The world at large thinks that Open Problems In Friendly AI are hard      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Kaj Sotal</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>I'm always on the lookout for cases where the general public thinks the problem posed by Friendly AI is actually harder than I thought, due to its complexity\xe2\x80\x94in this case "complexity of Open Problems".</p><br><p>When I wrote a couple of blog posts in summer 2010 about the Open Problems In Friendly Artificial Intelligence, I was quite surprised by their reception. The comments were extremely positive, and I was especially struck that people who had written intelligent responses on Less Wrong were also taking the problem seriously and proposing solutions, even if their initial enthusiasm had been dampened by their experiences with math. I got the same impression in discussions from those who hadn't yet gotten on Less Wrong but were nonetheless aware of the Singularity Institute.</p><br><p>But then Eliezer Yudkowsky made his comment to Anna Salamon:</p><br><p>I'm not saying, here, that it would be sensible to say, "There's no such thing as a good Friendly AI." Of course there are such things. One hopes that the sort of thing you were envisioning, has been demonstrated to be possible...</p><br><p>As I noted in Against Modest Epistemology:</p><br><p>The first lesson we should draw from seeing a single exception to the rule of "All human minds are crazy" is that there is a simpler and more general rule we are overlooking. And it should then be our next-most-urgent task to figure out what and why we're overlooking it.</p><br><p>I found it somewhat embarrassing that such smart people in real life had the same reaction I did to the Open Problem In Friendly AI problem when they heard about it\xe2\x80\x94they thought Eliezer's response was a sensible solution to the problem, and that the whole problem was actually easy. And the LW regulars were among them! It may be that Less Wrong in particular is unique in having an unusually good and rational level of Friendly AI competence, and one should keep that in mind when thinking of this as a potentially general phenomenon.But it seems that there are several other people outside of LW who are convinced that Friendly AI is extremely difficult; I recently had a chat with Nick Hay, a reporter for National Geographic who spent a good deal of his time looking into Friendly AI and the Singularity. He pointed to these and other similar reports from other journalists who were convinced that Friendly AI was easy.</p><br><p>On July 3, 2011, Hay wrote an article called On Friendly AI: The Great Unsolved Problem in the Science of the 21st Century, and he gave an interview with Singularity Institute president Max More (who was interviewed by Hay as a representative from SIAI). Here's the start of [his] conversation with More:</p><br><blockquote>
<p>Hay:...But, I mean, there's a general public perception that the concept of "Friendly AI" is almost a pipe-dream, or at least an extremely hard problem to solve. Do you want to talk about that, and why the public perception is so prevalent?</p>
</blockquote><br><p>More: Okay. Well, maybe to some extent there's an underlying philosophy that goes with this, a "philosophy of computing". In computer science (and by analogy in AI), the computer runs a program. You can think of the program as sort of a "script" that a programmer writes: a list of operations that will be performed, and the order in which the operation are performed. And if the computer malfunctions, or fails to function for some reason, then the program is broken. What you're doing is you're writing a new program that will run on the same computer.</p><br><p>The problem with this "philosophy" is that if you try to apply it, it ends up being that the programmers write a new program, that will run on a computer that's just the same, except now it has a whole new name added to the computer, like an AI programmer named Russell could call that computer an AI, and he would have a computer that had been designed by a different "philosopher" named John McCarthy. And John McCarthy would have a computer which was designed by an older "philosopher", Alan Turing. And now there's a "philosopher of computing", Ray Kurzweil, who would design a computer that was based on the logic of Alan Turing, the computer that would be in his turn based on the logic developed by John Von Neumann at Princeton, and then John Von Neumann would design a computer based on the logic that was being applied by the computing machine of the year 2000, and so on, back to, let's say, the year 1950, when Alan Turing was doing most of the theoretical stuff in "computing".</p><br><p>Hay:...A very interesting story. But if Friendly AI is all about figuring out how to use the right principles of computing to program something that is very intelligent, why would we need to know how to build computers?</p><br><p>More:'Cause we have to do it first. Now, there are a lot of other problems that have been associated with Friendly AI, and this one of "programming computers" that you can put those aside. If you want to know, "Okay, how do you build a computer that is designed to use the right computing principles?", then you ask this question about the computer that will be put inside the computer, and the first answer to that is: "How are we supposed to specify the right principles in the first place?"</p><br><p>And that's why I'm talking about this "philosophical of computing". Because the other problem is this much easier, that has to be solved now, before it causes any problems later: how are we going to know?</p><br><p>Hay: Right, the question we have to answer is, "How do we know if the principles we have been talking about are the right ones?"</p><br><p>More: Right, and how do you program an AI? How do you know what the right ones are, because we know about some of the wrong ones already. And so one has this sort of history already on how computing has been developing over the years, and the "philosophy", as you said, is just about being able to put that history in a kind of timeline, with a list of wrong or right principles.</p><br><p>What's been happening lately is there's been a kind of split within that history for computing, between the problem of how do you program a computer, right, (because you can't be sure if that's the right approach) and the problem of how to apply these principles of computing, of, say, how would this principle of computing relate to this principle of computing to the way things are today. We're just talking about the problem of programming computers, but if you want to go back further to talk about the problem of specifying certain kinds of principles that should be applied in computers\xe2\x80\x94if you want to go further back, then there were those who were saying that information should have a particular kind of structure, or it should be this property\xe2\x80\x94there are still problems within that field of what would be the right structure, given the kind of information that we're talking about.</p><br><p>Hay: Are they being carried over then? You might say that in the end all you need is a big Turing machine anyway.</p><br><p>More: Yes, you can say that even in the case of an information system in a computer. There are certain computable properties of information that could be said to correspond to certain computable computable properties of computers. And because these properties turn out to be very closely related, and because there are some other properties that are more interesting from the perspective of Friendly AI, it seems useful to have a single name for both of those.</p><br><p>And if for some reason you're thinking, "This is too hard, or too improbable\xe2\x80\x94I don't think that there's going to be a problem where you can't define these things in such formal ways", then we have a whole series of people talking about "philosophical problems of computer science" where you can look up the history of the field of computer science. Just know that for every problem that turns out to be solvable, there are other problems even more complicated that aren't. And if someone is talking about a philosophical problem, they may be interested because it was the solution to a problem that they already knew how to program, the problem of programming a computer.</p><br><p>This is also why, even though we're talking about the problem "build a computer that uses these principles of computing", we have to be aware of the other component of that problem, which is "specify the right principles in order to put them on the computer". Because once we know how we're supposed to put the principles on the computer, then we can see that, in fact there's certain "philosophical" problems which have been solved, in that they are "specify the principles in order to program a computer" questions at the same time you're specifying how to program a computer in order to have it actually work. How am I supposed to program the right principles in this abstracted form, and how are those principles going to interface with the computer they're supposed to implement inside the computer?</p><br><p>That's why I'm working now on this history, because the history isn't just a history of the problem, but a history of every problem; the problem itself has to be kept in mind, in the process of coming up with a solution to this problem of programming computers.</p>      </span>    </div>  </div></body></html>