<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        The Impact of Human Knowledge Production on Productivity      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Eliezer Yudkowsk</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p><strong>Followup to:</strong> No, seriously..., More Dakka.</p><br><p><em>We,</em> meaning the people reading this series, may want to know what productivity <em>really</em> has to do with human knowledge production. And what <em>does</em> it have to do with human learning the way we do it? This series of posts will give a few answers to both questions, not directly at each other, but sequentially and systematically._</p><br><p>It is commonly alleged that no human being would make the same trade-offs as an ant. But let's stop for a moment and consider the cost and benefits in terms of the amount of information about a thing that's available, rather than just the number of species producing it.</p><br><p>The ant has no reason to "learn" anything that's not going to be useful for finding food and reproducing, so the ant would have to invest as much brainpower as possible into building up a gigantic detailed model of absolutely everything, inside and outside the ant colony. The ant would have to build up a really really complete map of life on its entire planet, down to the exact molecular level, a representation which the ant would eventually have to <em>use</em> to model, among other things, what's inside its own body. Whereas any given ant never needs to <em>know</em> about its own DNA, nor even about DNA in general, so the ant doesn't invest heavily in learning.</p><br><p>A human child's brain spends a few years building an understanding of the molecular biology of its own cells. It doesn't need to spend hours and hours and hours building that knowledge, like an ant does, to be of use. Yet humans do end up with such a knowledge-production strategy, and we do not just use it to understand individual cells, but use it\xe2\x80\x94and would you believe it?\xe2\x80\x94in a way that does genuinely affect what organisms are being built!</p><br><p>We start out by learning about chemistry. We learn about how chemicals interact with our bodies and with other chemicals. We learn about the various different kinds of enzymes in different tissues, and what chemicals those enzymes catalyze, and what they catalyze <em>elsewhere...</em> A typical human child learns all this at an early age, along with such vital facts as that some things will stain more easily or burn more easily than others. The same child can learn all this on the same days of school.</p><br><p>But we also learn some other things that are far less "life-or-death" or even "important-for-survival" like algebra and fractions and fractions of fractions... and when we learn them we not only <em>apply</em> them to <em>things</em> and <em>problems</em> in the <em>world</em>; we <em>generate,</em> to use a more technical term, a <em>model of how they work.</em> Because we're interested in this information for a reason, we want to understand it. And because of how the human mind is built, we <em>actually get it.</em> Our brains have a <em>way</em> of understanding it without having to spend thousands of hours of <em>direct</em> investment in that understanding.</p><br><p>And, yes, sometimes a human baby learns such facts as "the world runs on mathematics" or "people have DNA" or "food is made of atoms" or even "fractions of fractions" and <em>still</em> doesn't start having <em>specific detailed models</em> of those things. Does this mean the toddler never builds a model of how a fraction works? If so, then the toddler is a toddler. But the baby and toddler do understand the general abstract concept and how it applies to other elements of general abstract concepts, the "world runs on mathematics" and the "the food in my mouth has to be made of atoms" concepts. And even if they don't understand fractions yet, it shouldn't be too mysterious why they <em>might</em> someday build a model of that concept.</p><br><p>But more than that, from our perspective as evolutionary biologists, we know that when these cognitive capacities <em>do</em> develop, they're driven by an adaptation\xe2\x80\x94the "explanation" for <em>why</em> the human brain develops capacity to understand mathematics, or science, or fractions. These concepts become the central focus of the human mind, which takes up huge chunks of the human brain. And once we understand those concepts, we <em>can</em> apply them to lots of similar problems, at least to a limited extent.</p><br><p>And if the human brain has a particular concept as its own central focus, and the human mind's machinery that <em>learns and understands</em> is also built around the capacity to model a human concept, then we should actually <em>expect</em> that machinery to have developed around that concept already.</p><br><p>And so <em>even if</em> the human brain starts out with a capacity to understand algebra or fractions, that capacity will not arise in its machinery <em>by default</em>. It will require <em>work</em> by the human mind to build that machinery; there will be some particular reason the model is <em>useful</em> rather than just being built just to understand the structure, to learn statistics, or to learn the genetic structure of the local group.</p><br><p>But if the brain <em>does</em> end up with a model of algebra, as <em>part</em> of the general machinery of learning and understanding, then that model will be built to the same general <em>type</em> as the math-using general machinery of the brain. Just as it happens, because the brain's learning machinery is driven by math concepts, and the brain automatically builds a model of math concepts because math is cool, we should expect the model to be the "same sort of thing" as that general machinery.</p><br><p>In other words, the human brain automatically builds a <em>particular kind</em> of model to help it understand particular kinds of things, but it does not automatically build a <em>particular specific</em> model to help it <em>understand more general things with the same machinery.</em></p><br><p>(I was tempted to say "if you <em>have</em> a model for <em>generalizing from algebra</em> why wouldn't you have a model for <em>the structure and evolution of life?</em>" but in general it is much easier to build a model for a pattern generalizing from specific examples\xe2\x80\x94_specific_ generalizations require that you have the <em>specific _model to _derive</em> the <em>general _model. But I suspect there might be an _analogously easy way</em> to construct a model starting from specific examples without the analogously easy way starting from a general concept. So I am skipping that part.)</p><br><p>Why is this important? Because the model that is built into the human brain, starting from algebra and fractions, is an <em>information-processing thing</em>\xe2\x80\x94it helps you <em>understand</em> things, rather than just being in some way part of the territory. It's what allows you to predict the answer to, say, a word problem (you know how to find the answer in the text, just by <em>looking at the model</em>) even if you're not sure you could solve it directly. The brain has a <em>specific kind</em> of information processing, so we should be able to _expect _that the cognitive machinery around modeling fractions will generalize to modeling life and evolution.</p><br><p>And this is an important point regarding ant colonies. You could construct the ant colony by the <em>non-selfish</em> route of taking a set of organisms, with no brain at all, and letting them all "talk to each other" by means of pheromonal communication. By the same token, we could\xe2\x80\x94possibly\xe2\x80\x94construct a model of human behavior by creating a vast number of isolated robots, no brains in them at all, and connecting everything back up to the "global brain" by means of "mind uploading".</p><br><p>But as far as I can tell, no human being does (or would) construct their mind using something remotely similar to the non-selfish ant route, or the robot-with-one-global-brain route. Instead, humans acquire knowledge by studying human books, and then <em>using</em> it, in all kinds of complicated ways. An analogy: The world is a complex but understandable place, from our ancestral environment, yet it took the human species tens of thousands of years even to <em>start</em> learning about it, and a lot less time to produce knowledge than it took to actually build us.</p><br><p>The only time that I suspect human learning has anything like the automatic-by-default nature of ant knowledge production is when the humans themselves are doing the learning. But then, we have the question of <em>why</em> the process develops that way. Why can't it just develop by the non-selfishly efficient ant route, even though we ourselves are doing the learning?</p><br><p>Because we ourselves are using <em>our own knowledge</em>, when we do human learning; our own knowledge about the human world (which is so incredibly vast and complex and rich, compared to the ant colony's world), can serve as a central focus to our attention even as we ourselves learn. We aren't building our own knowledge around our "global brain" anymore than the ant does.</p>      </span>    </div>  </div></body></html>