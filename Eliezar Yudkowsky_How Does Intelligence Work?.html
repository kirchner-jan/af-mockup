<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        How Does Intelligence Work?      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Eliezar Yudkowsky</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p><strong>Followup to:</strong> Intelligence Explosion Microeconomics, Chapter 3: The Intelligence Explosion</p><br><p>How does intelligence work, or "Why is Artificial General Intelligence so much smarter than humanity in the first place?", or more generally "How does intelligence create a positive feedback loop?" or more generally "What determines how hard a task is, and how much time it takes to complete it?" or, "How do different tasks interact with intelligence, and how do their difficulty, and time requirements, interact with one another to define one's intelligence?"</p><br><p>Some of those questions are answered in <strong>Previous work</strong>: an earlier comment showed that I had already done a lot of work in the previous conversations. So this post does not present any new ideas; it is merely a brief summary.</p><br><p><strong>Previously</strong>:  I said that this intelligence explosion part of intelligence, was, as far as I could see, the least understood part of intelligence.</p><br><p>The previous discussion took place as part of a debate about the <strong>intelligence explosion part of intelligence</strong>.</p><br><p>The next discussion will be focused on the <em>time-delay part of intelligence</em>, as discussed in this chapter by Muehlhauser and Helm. And I will explain, using an analogy to software design, what sort of time lag is in the way of recursive self-improvement, and also explain (in more detail than in the previous conversation) how a computer can use its software-designing self to design much faster programs that are software agents, which design software agents, which go on to design much faster algorithms...</p><br><p>Partly this will be due to the usual issue of how human beings are not very good at thinking about the design of software even when the software is very simple, as in the case of our own evolutionary history. It will take longer to explain, because I am not trying at all to cover that ground again, but it might be important to distinguish "what is the real difficulty here" from "how difficult a hypothetical person could have made it seem".  This is not the same as suggesting that the real difficulty has not already been discussed.</p><br><p>The final part of this post is this: in an AI, you could try to <em>define</em> a task in terms of its algorithmic difficulty\xe2\x80\x94as a series of instructions to be followed by a computer, for example\xe2\x80\x94but the easiest task that you can define, may well be the most difficult that the computer can actually solve. So when discussing whether an AI has "general intelligence" or not, it would be useful to <em>define</em> what it meant for a task to be a certain <strong>algorithmic difficulty</strong>.</p><br><p>How does Intelligence Work is something which I was not thinking about, and I would like, if I write it more coherently, to go over, point by point, how a computer executes a task, to what extent we can say\xe2\x80\x94when an AI does something\xe2\x80\x94that we can say that it solved its task by executing some algorithm, or that it solved its difficulty. I would also like, to say again, that I am trying here to describe the time-delay part of the intelligence explosion.</p><br><p>The key idea here is that every task can be more or less hard, on <em>both</em> the human side <em>and</em> the AI side.  (A task may be <em>easier</em> for the AI side or the human side than you think; the difficulty of a job that an AI can do is always lower than the difficulty you'd give it for a job that is not in the AI's abilities to do).  The difference between task-solving and intelligence is that intelligence is <em>superior</em>, and task-solving is sub-human.</p><br><p>If an AI with 100 units of intelligence can design a human smarter than it (by developing an AI more intelligent than human), then that is probably "superior" to the intelligence of a human. But the AI cannot yet design a <em>human</em> smarter than it, because if the human intelligence increased just a little bit more than the rest of the world, at a time when the AI's intelligence was already at 100 units...  _Then it should only take a few hours. _</p><br><p>One way to think about it is to try to define, if you could, what an <em>ordinary</em> task is and then how an <em>extraordinary</em> task is a function of those ordinary tasks. So far as I can see, the key problem is to try to talk about what <em>really</em> makes a specific AI so much more intelligent than the rest of humanity. One way of doing this as an analogy to current computers is to think about a modern AI as one step in a sequence of many steps.</p><br><p>The sequence of steps from AI to human is probably longer than the sequence from AI to AI, so the total time-delay there is less than the total time-delays that arise when you design from scratch an AI. I will be looking at this in the context of a hypothetical FAI being created by an FAI, which will look at the AI it is creating, and compare it to a general AI produced by a sequence of general AI steps.</p><br><p>(For the purposes of this post, let us assume that the human side of the intelligence explosion was negligible by comparison to the AI side. That was what I was thinking about when I said that I was not trying at all "to cover that ground again".)</p><br><p>One thing that I should probably mention now is how the FAI-created AI, and the series of steps which produced it, would not be so much an example of "optimization by a design process" as a case of an algorithm, designed to produce an intelligence explosion; because the recursive self-improvements and recursive self-organizations which I am considering now are <em>not</em> going to be the algorithm "improve myself" or "do the best thing I can".  Self-improvements and self-organizations are themselves optimizers; they are search algorithms. That is how the FAIs produced by this series-of-discrete-FAI-creating processes would be <em>designed</em> to produce intelligence explosions.</p><br><p>I also realize that I am not addressing those issues on this topic because they are too difficult, rather than because the issue is just too unclear for discussion\xe2\x80\x94like saying that I can't say exactly what is going on with the mysterious, unsolved parts of Artificial General Intelligence.</p><br><p>For all of those purposes, here I am supposing a series of discrete steps, an actual series of discrete steps in AI design or evolution\xe2\x80\x94not the human designer, not the evolution, just the AI produced. I am supposing that a designer or a creator can be given a certain amount of starting intelligence, and then the designer or the AI is said to have "superior" intelligence over everything that <em>has</em> been produced by that AI-evolution; that they are smarter, and they can produce smarter successors. This is my assumption here.</p><br><p>Now, it is said in previous posts that humans are not very good programmers; we do not have the cognitive abilities of humans to design software; and therefore we should view AI's as a step towards AI as the humans produce, not the humans designing.</p><br><p>It is also said that the intelligence explosion part of AI is confusing and poorly understood. So how is intelligence built from simpler parts and how is intelligence built, is the more difficult conceptual problem, and therefore, how intelligent something you are, should give you some idea of how <em>intelligent</em> the thing will be. So as I have been trying to explain the idea of intelligence explosion as a positive feedback loop, this is an attempt to make sense of the problem in lay terms.</p><br><p>Now\xe2\x80\x94again ignoring the issues of the human creator, the human designer, optimization by iteration, human enhancement, and many other caveats\xe2\x80\x94how is an AI built or produced <em>more intelligent</em>, at each step in the process?</p><br><p>That intelligence is a kind of property, a function of a number of sub-properties.</p><br><p>Sub-properties include:  The amount of time it took the AI to complete its current task, and any hardware resources the AI used. We could also separately include any other sub-properties that were relevant to speed of completion. We're not talking about how much memory was allocated; we're talking about speed of execution. Obviously if the AI is faster, then it will be able to perform <em>more</em> tasks, and that will feed into the intelligence\xe2\x80\x94we're saying that the <em>human designer</em> will <em>consider</em> these facts when choosing among possible AIs on the basis of their speed of execution and their task-solving ability.</p><br><p>One sub-property also includes how hard each task was\xe2\x80\x94either in terms of time, because we could set a specific execution time limit, or in terms of difficulty, because intelligence is a positive feedback loop. If the task was easier, then the AI will complete the task with less resources and get more intelligence from doing it, and more hardware to do that kind of work with.</p><br><p>Another sub-property is how intelligent the AI got at the previous step versus how intelligent it got at the task it just completed. If some sub-problems were easier for it to solve when it was working with a small chunk of the solution-space, then we could have expected it to solve some other <em>smaller</em> sub-problem, if that was in its power and all the resources it had been given were still available.</p>      </span>    </div>  </div></body></html>