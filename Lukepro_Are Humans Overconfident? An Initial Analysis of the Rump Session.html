<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Are Humans Overconfident? An Initial Analysis of the Rump Session      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Lukepro</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>(Epistemic status: speculation, but a sort of preliminary speculation.)</p><br><p>Luke:</p><br><p>This is my analysis of the rump session I and other participants ran earlier this month.</p><br><p>Eliezer:</p><br><p>This post is mainly written for my own needs, so the following might not apply to you just fine...</p><br><p>Eliezier:  "My model is that <strong>if I'm being honest, I tend to trust my self less than average.</strong> I'm <em>myself</em> more than a typical person believes me to be." (source)</p><br><p>Luke:  I wonder if this might mean people with LessWrong biases are overconfident. This isn't new, and it's an <em>experimentally supported hypothesis</em> that self-perceptions of confidence correlate negatively with actual confidence, both within a given subject and between subjects, but it's a relatively new result within the general scientific consensus in psychology.</p><br><p>I'll start off with some evidence for this hypothesis:</p><br><p><strong>A Brief Note on Biases in Psychological Studies of Self-Perceptions</strong></p><br><p>First, it's important to understand that self-perception of confidence or calibration is not a reliable measure of actual, objective confidence. Self-perception of calibration might correlate negatively with actual calibration because:</p><br><ul>
<li>Confident people tend to be less interested in the truth than they are in confirming themselves as confident</li>
</ul><br><ul>
<li>Overconfident people tend to not realize their confidence is overconfident if the truth is very far from their confidence level</li>
</ul><br><ul>
<li>Confident people are often <em>correct</em> in assessing themselves as highly confident because they <em>were</em> confident in the past. Overconfident people are more likely to be <em>wrong</em> because they can more easily imagine themselves in more confident roles in the future, even if their confidence is <em>no higher</em> in the future than in the past.</li>
</ul><br><ul>
<li>Confident, overconfident people may have motivated cognition aimed at justifying their self-perception as in-group members.</li>
</ul><br><ul>
<li>Overconfidante people are more likely than underconfidante people to perceive their overconfidence as due to a "self-enhancement" bias, a tendency to assume that their true self-image is better than it is, or because they have self-enhancement.</li>
</ul><br><p>From this point of view, what studies find a correlation between self-perception and actual calibration may just be confidences who try to confirm both their self-image and their actual calibration <em>in a single study</em> fail to make correct self-predictions and also have poor calibration. So they'll find that their self-predictions tend to confirm their self-images and that those predictions happen to be well-calibrated, but that they never notice that their predictions are well-calibrate. So it's possible to construct a "correction" to the self-perception-calibration correlation, by controlling for the degree to which self-perceptions reflect motivated cognition. From the "confident people are less likely than average to know their own calibration" perspective, we can see that such a correction might not be very useful from a self-enhance and self-motivated cognition perspective since controlling for them may make self-perception still reflect more self-centered desires and more motivated cognition.</p><br><p>At any rate, to the extent that these studies find a correlation, we can ask if it might be due to a correlation between self perceptions of confidence and actual confidence, and also whether this correlation might be less for less overconfident people.</p><br><p><strong>Evidence from One Study</strong></p><br><p>One way to get a hint on this is to review the research in this area.</p><br><p>Loftus:</p><br><blockquote>
<pre><code>When people rate their abilities or talents, one way they may do it is by imagining how much they would benefit from using the ability or talent, and by assessing their skill at the moment relative to that benefit. We all remember trying to do things that we didn't know how to do and failing miserably. Such failure may produce an overestimate estimate of how far we can improve or how good we have become in our relative position.
</code></pre>
</blockquote><br><p>...  Our assessments of our skills are highly correlated, and these estimates are also correlated with each other for the same reason, and so we infer from them that we overestimate or underestimate our skills on the basis of these estimations.</p><br><p>...  That is, <strong>when people rate how competent they are, or how good they are at a task, they tend to overestimate their competence or ability at that task.</strong> (source)</p><br><p>Loftus &amp; Wilson:</p><br><blockquote>
<p>People (including even some psychology scientists) tend to be modest and, on occasion, even boastful... The more accurate they are in perceiving their own abilities, the less able they are to overestimate them... In one study we found that subjects on average overestimated their own calibration more than subjects did when estimating the calibration of other subjects... A similar finding was reported by Pohl et al. (1997) in an eye-tracking study of basketball players. They discovered that subjects often looked longer at more accurate performances than they did at less accurate performances. It appears that people have a bias toward modesty, believing that they are better than other people expect.</p>
</blockquote><br><p>(The following are excerpted from <em>Psychological Science</em>.)</p><br><p>Loftub &amp; Wilson cite:</p><br><blockquote>
<p>... In a study by Pohl et. al. (1997), players of a simulated basketball game were asked to assess their performance, while they were playing. The players who performed better (and hence were farther from 50% success rate) gazed longer at better performances than they did to worse performances. In addition, better performers perceived higher levels of skill than worse performers did, and reported greater confidence in their skills.</p>
</blockquote><br><p>(Here's the abstract from the study in question.)</p><br><p>I would conclude that overconfidence is due to human biases, especially self-perceptions motivated by confirmation bias and motivated cognition, but we shouldn't ignore that this could be an experimental error, and people with LessWrongs' biases might be overconfident in a different way than the biases of subjects who have studied LessWrong.</p><br><p>Before we can explore some possible experimental biases I might have in this post, I want to talk about possible experimental evidence that Eliezer has been experiencing some form of "honest signals" theory failure, and that others have had or are having such failures as well.</p><br><p><strong>Is Rationality Training Associated With Reduced Biases?</strong></p><br><p>Eliezar says (emphasis his):</p><br><blockquote>
<p>That which can be destroyed by the truth should be! Any doubt in my mind, I shall resolve by looking up the truth. And what is true can be known. And what is known can be made real. This is how all progress takes place.\xe2\x80\x94The World of Art, Chapter 2</p>
</blockquote><br><p>But some people may have taken the saying literally. And I've found from looking into the literature on "rationality training" that some proponents of "rationality training", such as myself, have probably been subject to a different version of it than the one to which Eliezer was referring.</p><br><p>To quote from a paper by researchers from the University of British Columbia, and two of its coauthors, titled "Rationality Training, Intelligence Test Performance and Self-Evaluation: A Case Study Among Less Wrong Users" (http://\xe2\x80\x8b\xe2\x80\x8bwww.academia.edu/\xe2\x80\x8b\xe2\x80\x8b1668982/\xe2\x80\x8b\xe2\x80\x8b"Less Wrong"<em>"_Training,</em>"<em> Intellectual Ability, and Psychological Self-Evaluations</em>):</p><br><blockquote>
<p>The original goal of the experiment described above was to determine whether rationality training was associated with "honest signals", or self-serving biases, in judgments of one's social effectiveness. Our results suggested that one-on-one instruction in critical thinking was associated with better self-perceived social effectiveness in university students, but not with improvements in real-world performance, in one's grades, or in the performance of the peers (see Figure 2).</p>
</blockquote><br><p>The researchers write:</p><br><blockquote>
<p>One possible explanation for this finding is that the students in the experiment who had received a series of critical thinking training sessions were generally less vulnerable to bias than others. For example, they may be less inclined to attribute their own higher social rank to the influence of their intelligence and social status, a known "cognitive miser" behavior (Merritt 2009). The present study is consistent with this hypothesis, in that it shows that the students in our experiment who were more likely to show social dominance in some other ways tended to be less confident in their own rationality training and less vulnerable to biases...</p>
</blockquote><br><p>The "cognitive miser explanation" they offer (p. 2):</p><br><blockquote>
<p>According to an additional possible explanation that has already been advanced, "rationality training [is] associated with honesty due to the development of better epistemic habits necessary to detect flaws in reasoning. The truthseeking strategies of careful reasoning developed by rationality training might also lead people to make more correct social inferences and thus to more confident self-perceived [social effectiveness]." (Kahneman 2006, p. 733)."</p>
</blockquote>      </span>    </div>  </div></body></html>