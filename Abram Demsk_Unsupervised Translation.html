<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Unsupervised Translation      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Abram Demsk</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>1 Introduction</li>
</ul><br><ul>
<li>2 The problem of language learning</li>
</ul><br><ul>
<li>3 Unsupervised translation</li>
</ul><br><ul>
<li>3.1. What do I mean by "unsupervised translation"</li>
</ul><br><ul>
<li>3.2. How does this work?</li>
</ul><br><ul>
<li>4 Current approaches</li>
</ul><br><ul>
<li>4.1. Learning-to-Rank</li>
</ul><br><ul>
<li>4.2. Learning-from-scratch</li>
</ul><br><ul>
<li>4.3. Unsupervised-predicting-labels</li>
</ul><br><ul>
<li>4.4. Self-attention</li>
</ul><br><ul>
<li>5 Summary</li>
</ul><br><ul>
<li>6 References</li>
</ul><br><p><em>This is the third of four posts I wrote this month on __learning human intent__; see the others for prerequisites. Although this post is a bit more mathematically involved than the others, I recommend that people who want to read the math section should read the other three posts instead. I'll do my best to link each section to the thing I actually think is most relevant to that section.</em></p><br><p><em>I'm posting the following on behalf of Ought</em> <em>and __Paul Christiano__.</em></p><br><p>_This post explains Ought's research agenda by building on the ideas of <strong>Paul Christiano's</strong> Iterated Amplification AI Safety Research Agenda__ and <strong>Learning-to-Rank</strong>._1 Introduction</p><br><p><strong>What is language learning?</strong></p><br><p>The way in which language can be used <em>as a system for communication</em> is <em>superintelligent</em> under the traditional account of <em>language learning</em>. As our civilization builds ever more advanced tools for communication, language learning will be an ever more important aspect of what we do, and one that is constantly getting better.</p><br><p>For example, in 2008, Eliezer Yudkowsky's write-up of AlphaFold 2, the computer program that can <em>translationally predict</em> proteins is a big milestone in this progress. At this point in history, it's not entirely clear whether this "superintelligence" is as much of an agent as a programmer would like; but that doesn't make it less <em>unpredictable</em>: it could be that the algorithm which does protein folding is as unamplifiable as a human being was before the age of computers. It's just that once a protein is folded, it stays folded, and its shape never changes again.</p><br><p>The more recent language translation program GPT-2 from OpenAI has already demonstrated that it too is superintelligent to the extent that we could predict the effects of its training (for example, <em>translating</em> between English and various other languages).  In this post, I want to look at a particular flavor of "superintelligence" that doesn't require a fixed corpus of training data; rather, it's a system for which we already have all the relevant data about the intended-to-be user of the software. (Imagine a software system trained on all of human history, instead of an ongoing corpus of training data.)</p><br><p><strong>AI safety through language learning</strong></p><br><p>By some accounts, there are three main ways in which technology will go better or worse this century. We can imagine technology <em>scaling</em>, where the technology that gets better with every passing year becomes exponentially faster relative to the time it takes to learn the technology. We can imagine it <em>decreasing</em> in time, where the total intelligence of a system is limited by the total amount of compute that's available to run the system, with the speed of the system improving roughly as fast as the amount of compute available increases. Or we can imagine the best technology of the 22nd century being <em>not</em> quite as good as the best technology of a random person from a different century. For a while, I thought we were talking about 1. \xe2\x80\x94the "superintelligence problem"\xe2\x80\x94but the idea of a civilization in the past, with more experience and better tools, has more predictive power than the idea of a superintelligence in the 21st century (and I think the best AI that can be built today may only be human-level, relative to the best AI to be built in 2114).</p><br><p>I am very excited about the project of safe, superintelligent AI that scales with resources (as we expect to build it <em>eventually</em>), but I am very pessimistic on the project of safe superintelligent AI with no resource constraints, because I think its very high likelihood is to be the same as other AI systems that are currently around (and the <em>probability</em> of its safety seems to me to be the _probabilistic conjunction _of all of these facts).</p><br><p>But if scaling with resources is the problem, can't we just build a superintelligence with a super-intelligent human assistant? I think we can. But humans do not have the ability to <em>translate</em> between languages as easily as Google Translate, and it's unclear how that would affect the alignment problem. This is a key part of what we need to solve to ensure that a language-based interface <em>actually helps its users</em> (rather than simply being a more convenient way to enter commands into the user's brain).</p><br><p>To illustrate our point about the difficulty of using this kind of superintelligence for alignment, consider a robot with superhuman intelligence that is able to <em>translate between English and Korean</em>. If two countries decided to build this kind of robot, I'm not sure what they'd do with it once it was able to translate between English and Korean. It might be used by Korean translation companies to assist with the translation of English-language works into Korean; or it might be sold to other translation services to help them improve their translation abilities; or, if it seems possible to me to build safe and aligned superintelligent systems like AlphaFold 2 and GPT-2 by the end of the century, then I worry that when humanity has reached this point, it won't have time to fix the problem before the systems take over and we're left hoping to learn some key safety insights from whatever systems have been around at that point.</p><br><p>I'm more optimistic that the first superintelligences to be built in the 21st or 22nd century will be language translation <em>systems</em> rather than translation <em>agents</em>. (That is, systems that do the same thing in the future regardless of what language it's translating between.) I think the way to build such translators is to start with "language acquisition" programs that are already more-or-less superintelligent, and then incorporate human feedback to train them to focus on important concepts. Then we can have superintelligences that can learn English and Spanish and Chinese and Korean and Hebrew and... in order of their usefulness to us, though presumably not in order of how many human researchers have ever thought about the problem.</p><br><p>To this end, we've developed an approach which tries to produce, if you will, a "learn-to-rank" model, where there are "learned" algorithms that are selected for their rank-based predictors. The algorithm for producing such models is itself language-based, so it involves humans helping to learn languages using an interface that is based on language-predictors ("the output of this algorithm has an 89% chance" is a lot easier than "this translation has 100% chance of error").  This seems quite promising, as a result of Paul's Iterated Amplification framework: we can have superhuman systems for making predictions or decision-making that are trained and honed by more accessible and human-understandable systems like this. To this end, I'll focus in this post on what we currently <em>have</em> as far as language modeling programs go, and on our hopes for the future.</p><br><p>In a sense, what we seek here is a <em>distillation of the intelligence of a civilization</em>, but distilled in a way that <em>doesn't require a fixed prior</em> (or dataset, or even humans) to train the distilled AI. And if this kind of AI (called a "language-based oracle") doesn't have a fixed prior, it seems better-suited at solving the problem of making language-based systems safer than any other approach at solving the problem.</p><br><p><strong>2 The problem of language understanding</strong></p><br><p>As has already been mentioned, <em>translators aren't agents</em> \xe2\x80\x94they don't make good agents, they don't make great agents\xe2\x80\x94they're <em>superagents</em>. The problem is more that no human being could be expected to understand a <em>translation</em> as an interface, than it is that a human being <em>wouldn't</em> understand a translation interface. For a translator to be useful it must be able to answer questions about the meanings of words in many different languages, and be able to answer in a way that has the same "meaning" in any language. It needs to understand the "meanings" of all of these words and constructions over many different languages; and while a human reader might feel a little more confidence when confronted with "John is to Mary as Jane is to Bob" than with "Jane is to John as Mary is to" Bob, I can't see how any of us would be able to reason about those sorts of comparisons on the basis of our native languages. </p><br><p>That's the problem of "language understanding" or "language grounding": translating between two different languages via an interface that is understood by both parties (who presumably are much better than a human at understanding what is going on in their own language). We think about the problem of language understanding with a model called a "language-to-language" model, which takes the meaning of a statement and translates it into whatever other language seems to understand it best (or vice versa).  There are a number of questions I'm interested in about this problem, and I'm interested in any thoughts on what people already think about it.</p>      </span>    </div>  </div></body></html>