<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        On the origins of Nash equilibria,      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Jessica Taylo</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>Foreword</li>
</ul><br><ul>
<li>Introduction to Nash equilibria</li>
</ul><br><ul>
<li>Conceptual background</li>
</ul><br><ul>
<li>What are two worlds, and which is which?</li>
</ul><br><ul>
<li>The agent's best guess</li>
</ul><br><ul>
<li>Is that the right way of thinking?</li>
</ul><br><ul>
<li>The equilibrium concept</li>
</ul><br><ul>
<li>What is a Nash equilibrium, exactly?</li>
</ul><br><ul>
<li>How do you know you've found a Nash equilibrium?     </li>
</ul><br><ul>
<li>What we mean by 'rational' </li>
</ul><br><ul>
<li>Is the best we can do, or will do?</li>
</ul><br><ul>
<li>The rest</li>
</ul><br><ul>
<li>What happens when we've found a Nash-optimal equilibrium?</li>
</ul><br><ul>
<li>Where we see things differently</li>
</ul><br><ul>
<li>My take</li>
</ul><br><ul>
<li>Concluding thoughts</li>
</ul><br><ul>
<li>On non-realizability</li>
</ul><br><ul>
<li>Conclusion: The Nash equilibrium concept is not one people use, and may not be one that we can use!</li>
</ul><br><ul>
<li>On realizability</li>
</ul><br><ul>
<li>The real world</li>
</ul><br><ul>
<li>Why we might care about this</li>
</ul><br><ul>
<li>Notes</li>
</ul><br><p>Foreword</p><br><p>My first experience with <em>Game Theory</em> was my dad taking me and my friend to a bookstore, and the saleslady showing us the cover of Nash's famous classic. I think I was maybe 11 or 12 years old, and it was very exciting. The first chapters were about the concept of a 'Nash equilibrium', which is when two people with common preferences are best-off going along with their common preferences, or so we thought as I climbed out of my chair as he said 'we can agree about that at least'.</p><br><p>Nash equilibria have come up in lots of places, and they have been key to lots of progress. They inform our understanding of how social processes can work, and how to think about the world more generally. Of course, Nash equilibria have been discussed by philosophers, including Kant (1785) and John von Neumann &amp; Oskar Morgenstern (1944), who famously claimed at least <em>some</em> progress was made on the problem of rationality back then, but we didn't know what it was yet (see the 'Realizability' section here). It is a shame we are finally getting to the point that Nash equilibria are getting more attention in public discourse.</p><br><p>Nash's equilibrium concept is very powerful, and when he introduced it he saw the possibility of achieving mutual cooperation in a world where people are selfish. He called it 'cooperative' because people are allowed to selflessly cooperate. To find a Nash equilibrium, we look at all possible equilibria and see if there is an 'incentive for both parties to cooperate'. If they can mutually cooperate, we declare it a Nash equilibrium. But what is an equilibrium?  </p><br><p>We might like to try and make a better equilibrium concept for real world social situations. To do that, we'll have to flesh out the conceptual background.  </p><br><p>Introduction to Nash equilibriums</p><br><p>Let's start with some game situations. These scenarios are designed to be simple, and not to be exactly representative of real-world or computer games, but are still important.</p><br><p>First, consider the famous (if slightly less famous than one might think) Prisoner's dilemma. Each player gets a number representing how good they are at getting cooperation with their neighbour, and the utility they get from each round is the greater of the value of the number they received and the same number divided by 2, for similar reasons that we get cooperation in Prisoner's Dilemmas:</p><br><p>Each player sees the number that the other player got, and, if it is greater than their number, then they cooperate. If not, they defect, and get utility equal to what that other player got minus their number divided by 2.</p><br><p>(I think this means that the most rational strategy is usually (though not always and in all possible situations) to defect. The other player's number determines what the best move is, but you don't know whether the other player is a good cooperator and if they know that they are a good cooperator then defection is the best move, and if that other player is a bad cooperator and doesn't know that they are, then defection is not the best move, instead the best move is to cooperate.) </p><br><p>So what is a Nash equilibrium for this game?</p><br><p>First, we need to understand what it is for two people to be at a Nash equilibrium. Nash famously argued that if you think about two people playing against each other, at each time step the pair could either defect as each looks to get more utility than the other, or they could cooperate, as they both understand that they are better off then defecting (or at least better off then cooperating if the other person isn't).  To see this, note that if either person defects, then the best things for <em>themself</em> are achieved by defection; if the other person defects, that is a bad outcome for them, but a good outcome for <em>themselves</em>. Conversely, if either of them cooperates, then this is also best for <em>themselves;</em> we have now solved the problem of coordination for the person in question! (Of course, this is a Nash equilibrium in this particular game, but we need to see it's not a Nash equilibrium in general before concluding it is the best Nash equilibrium in general). </p><br><p>If we think about the game as if there are two different worlds, but in which the players don't know which one it is in, then it becomes clear that the pair are at Nash equilibrium if (and only if) neither of them could be better off if they knew they were in the 'better world'.</p><br><p>That's the important part: you know that you are in one of these worlds as soon as you see the other players actions. The other players are deciding based on what they think you will do, and they think you will be best off defecting if the other player has higher utility than you have, but the best strategy for you is defecting if they have lower utility than you have. </p><br><p>Or, mathematically, if an incentive exists for both players to cooperate, and there is no incentive for either player to defect (where an incentive is where you would get more utility if both cooperated than if both defected), then both players must cooperate. Or, mathematically, neither player has negative utility for cooperation.</p><br><p>Now, for this to be the best Nash equilibrium, we need a few things to be true. First, we need each of us to want to cooperate, or we'll probably do better by defecting. Second, both we need to understand those reasons that they might reason our way to cooperating, or we might find that there isn't much reason for each of us to cooperate, in which case we can defect.  </p><br><p>We have now, in effect, solved the problem of getting both or all players to cooperate. It no longer has any problem. If all players cooperate, then they are better off than having a poor outcome, and their motivation for cooperating is 'understand that you will be better off if both cooperate than if both defect'. This does not make cooperation the best Nash equilibrium\xe2\x80\x94this is always the case when we have no reason for two people to cooperate. If one wants to defect and one doesn't, there would be one better outcome (defining each utility as the utility that would be better for you if neither cooperated, but assuming you'll defect if they defect, or defect if they cooperate), and so at Nash equilibrium, both people defect. It is important to be clear that Nash equilibriuums are not what we want: we want cooperative equilibriums. For example, if I want to be in a cooperative equilibrium and you want to defect, then it will be better for both of us for us to cooperate, if your reasons for not cooperating are different than my reasons for not cooperating, and so a more useful term for the concept would be cooperative equilibrium, but sometimes people just want a term for what we are actually interested in!</p><br><p>A second game that has been much discussed is the stag hunting stag game: in this game, there are two stag hunts, and four non-stag hunts. The game starts out with all players going into either the first stag hunt or the first non-stag hunt. The payoff to everyone who goes into the first stag hunt is the same as the previous stag hunt, but if they go into the first non-Stag Hunt, then if everyone else goes into one, they get some utility. Alternatively, if they go into Stag, then if everyone goes into one, then they are a stag, but if any go into a non-stag, then they are still a stag and they lose one util. So, at Nash equilibrium, everyone goes into the first chance.</p><br><p>Note that we can generalise this model.</p><br><p>A stag hunt is a case where everyone agrees that everyone gains the most utility from everyone else going into the first stag chase rather than the first non-sta hunt. An antifuck hunt is where everyone agrees that going into either will result in them getting least amount of utility compared to going into the other, or not going into the other would result in them getting at least some utility (definitely not zero).  The Nash equilibrium for the stag hunt is thus an antifuck one.  </p>      </span>    </div>  </div></body></html>