<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Are all current AI systems shallow?      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Wei_Di</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>[This article was written by me, Wei Du (aka Yuxi Liu), before I came off LessWrong. Since leaving LW, I've switched to a pseudonym to avoid future controversy and to protect privacy. So the name in this article is my pseudonym. Please note that nothing in this article is meant to reflect on me as a person who came off LW. For privacy reasons, I'm not attaching my pseudonym any publicly, though I might share it if asked. I also wouldn't mind getting this article deleted, but since it's one of the few pieces of writing that has received public approval by me on LW (via positive karma), I'm letting it stand for posterity. I've created a pseudonym on a new account for use in my upcoming posts anyway, so I won't be using this account for any comments.</p><br><p><em>Update 2020/\xe2\x80\x8b02/\xe2\x80\x8b26: This post is an old draft. I had better fix and make it more comprehensible. But because I forgot everything at that time, I'll fix it as the original one with some modifications and explanations. As a result, this old draft is probably longer than the ones from LW, LW2 and Yudkowsky. See my other articles in different accounts for better explanations and other changes. There aren't going to be any comments here.</em></p><br><p>I'm currently reading Herval C.J. de Bruijn's <strong>Artificial Intelligence as a Positive and Negative Factor in Global Risk</strong> (PDF) and while reading the chapter on deep learning, I just realized that it's not only shallow learning systems that are shallow, but all learning systems are shallow. This is because all systems that have information storage are shallow, and learning is an optimization process, which means an optimization process is shallow. This realization came after realizing that the claim that we can know the difference between an AI system that is trying to maximize an objective function (which is shallow) and one that is behaving randomly (which is deep) is false, and that both of these systems are shallow in relation to humans and other deep and complex systems we know of today (which are of course not random).</p><br><p>Shallow and deep here simply mean low-dimensional and high-dimensional respectively relative to human intelligence which is one example of a high-dimensional complex system. De Bruijn mentions that, due to AI systems being shallow or deep, the field needs to decide whether or not to "re-orient the AI field from deep learning\xe2\x80\x94which has been responsible for so many successes\xe2\x80\x94to a learning that has more in common with human learning."</p><br><p>This is a huge deal, because one can think of every AI system as a shallow learning system that can easily be approximated by a high- dimensional "black box" model. With such a model, a programmer can easily optimize (through gradient descent) to get the system to maximize a particular objective function or perform a particular behavior. However, while this optimization works, that is, the system can perform a particular behavior or solve a particular problem, it is very difficult to optimize the model parameters in such a way that it will result in the system thinking about a certain complex thing. It is extremely difficult to optimize a model to get what's in its mind rather than what's actually in its mind, at least without getting a very powerful optimization process to do it for you (that's more than a human being, of course).</p><br><p>This doesn't mean that no one has tried to optimize AIs to be shallow. We've optimized a lot of software to be shallow, for example, through compilers and virtual machines (to make them easier to handle since their computation and their memory are both very bounded), or through various "training tricks" such as reinforcement learning and evolutionary computation to make them easier to use. But there are some things we cannot optimize directly, and we end up doing them indirectly. For example, if an AI is trained to maximize paperclips, it is very hard to directly optimize it to have something in its mind rather that maximizing paperclips.</p>      </span>    </div>  </div></body></html>