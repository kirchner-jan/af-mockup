<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Are Publicly Funded Charities More Corrupt Than Private Ones?      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">johnswentwort</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>What Is The Actual Evidence?</li>
</ul><br><ul>
<li>Evidence From Small Charities</li>
</ul><br><ul>
<li>Evidence From Large Charities</li>
</ul><br><ul>
<li>Conclusion and Thoughts</li>
</ul><br><ul>
<li>How Can We Tell The Next Fortune 500 Startup From The Next Internet Exploratory?</li>
</ul><br><p><em>Epistemic status: very high credence.</em></p><br><p>Recently, I've been doing research on funding for X-risk reduction in academia and outside of it\xe2\x80\x94including in-between academia and outside of X-risk specifically. My current thinking is:</p><br><ul>
<li>There really isn't much difference between how academic public research is funded and how private sector research is funded.</li>
</ul><br><ul>
<li>By default, I'm not confident in "there aren't much differences" or "there aren't really any differences on average".</li>
</ul><br><p>What Is The Actual Evidence for This?</p><br><p>Let's start by summarizing the evidence I've gathered so far. First there's just the straightforward observation: academia is just a big organization full of talented people which often produces important discoveries. It's just not going to be a good place to directly support a basic-science research program aiming for neglected problems.</p><br><p>Second, the typical academic environment leaves little to no room for doing things outside the top-tier journals. This isn't always true, but when true, it really does reduce the odds of finding problems relevant to neglected topics.</p><br><p>Third, outside of the top-tier institutions, we see a pretty large proliferation of "small" labs/\xe2\x80\x8bteams/\xe2\x80\x8bprojects/\xe2\x80\x8bindependent researchers\xe2\x80\x94i.e. everything that isn't a top-tier academic institution. These have a higher proliferation than in the academic world, and are often staffed by people who aren't in academia.</p><br><p>Fourth, funding mechanisms typically favor short-term projects in the service of well-defined goals and products, and there's an abundance of such projects across disciplines.</p><br><p>Finally, more generally, academic research and the systems for funding it tend to be built around the idea of academic institutions that run on the premise of prestige and reputation\xe2\x80\x94i.e they reward academic performance more than anything else. This can lead to a lot of really weird incentives, such as academic publishing practices that reward writing up positive results (often in the form of self-plagiarism) and "publish or perish" culture.</p><br><p>There's certainly more to it, but those are the things I've been looking at. We should at least be aware of them when designing research funding mechanisms.</p><br><p>There might be one major exception: funding and prestige for small/\xe2\x80\x8bhard-to-define projects by startups/\xe2\x80\x8bnon-profits is a whole 'nother can of worms. I think this is one major exception to the general rule "outside academia has fewer of these weird incentives".</p><br><p>All that to say: the level of formal research funding at the university level is probably fine; outside academia, as far as I can tell, there can easily be a large amount of funding available for X-risk-relevant projects without all the weird incentives of academia.</p><br><p>What about the bigger, more established organizations? Will their research funding be any better on average? Maybe; maybe not; it depends on the type of research.</p><br><p>Evidence From Small CharitiesI've personally spent a fair bit of time looking in my local community for sources of funding for X-Risk reduction projects of various types. Specifically, I've been looking for things that focus directly on problems that the larger organizations seem to be neglecting or not interested in supporting.</p><br><p>To that end, I'll summarize a few major organizations (of varying prominence), along with what I've found, either directly, or through others I've talked to about such organizations.</p><br><p>There are two places and types of organizations in which I've found the most funding for X-Research: non-profits and SaaS.</p><br><p>At minimum, most of the organizations/\xe2\x80\x8bprojects I've heard of in these two realms come from just a single person\xe2\x80\x94i.e a single project, or a small organization.</p><br><p>At least for non-profits (and probably SaaS as well), funding mechanisms seem to be pretty strongly directed by the mission/\xe2\x80\x8bvalue prop the organization is selling or providing. So far, this seems to match the "typical researcher" model\xe2\x80\x94i.e projects of any kind are rarely directly funded by the organization per se.</p><br><p>This gets pretty messy once you start looking into things which might be funding-relevant for non-profits and/\xe2\x80\x8bor SaaS which aren't themselves directly selling X-risk-specific products.</p><br><p>Examples</p><br><p>What are some organizations you know about, or which are well-known in your local community? What types of projects do they fund? What kinds of projects?</p><br><p>Organizations and Projects</p><br><p>MIRI (Machine Intelligence Research Institute)</p><br><p>Main focus: Friendly AI development.</p><br><p>I'm primarily looking for other people here\xe2\x80\x94please share anything about MIRI you know.</p><br><p>I've been looking into MIRI internally for quite a long time now (at least a year), and I'm currently making my way through the research history they have posted online (e.g. here, here; I've run into a few issues while searching and/\xe2\x80\x8bor skimming/\xe2\x80\x8breading). So far it's been pretty dry-ish; I haven't found a ton of research relevant to funding, but I haven't really looked very hard. If anyone knows of a good place to start, please point that out/\xe2\x80\x8bsend me your link.</p><br><p>MIRI does also have a few relevant online groups which I might post an update link to here in a while:</p><br><ul>
<li>MIRIx</li>
</ul><br><ul>
<li>Meta: MIRI\xe2\x80\x94Where to Start?</li>
</ul><br><p>SIAI (Singularity Institute for Artificial Intelligence)</p><br><p>Main focus, as above; some potential funding-relevant projects seem to be: AGI-safety-related research, especially relating to how the process of Friendly AI development can be better/\xe2\x80\x8bmore reliable than expected; especially for the kinds of research needed by an organization trying to gain more funding with the goal of developing the FAI.</p><br><p>SIAI does in fact have a few programs that might be relevant to funding\xe2\x80\x94specifically, the Summer Fellows Program and the Visiting Fellows Program.</p><br><p>I've spoken with some people in and near the SIAI\xe2\x80\x94i.e those working at groups in the Bay Area, or those involved in some nearby groups\xe2\x80\x94who suggested there might be useful funding for other things\xe2\x80\x94mainly in the "what else can SIAI fund"? area. If anyone has any ideas on specific projects which I could/\xe2\x80\x8bshould fund to have a chance of finding out if you were a good fit for that project and whether such projects might be helpful, please send me a PM.</p><br><p>A lot of the funding I've been seeking has been in the form of giving the organization money under the terms of different contracts and agreements; a lot of it has been through grants from EA organizations (typically the Singularity Institute for two years, and OpenPhil AI Risk Grants for one year). This may look odd at first\xe2\x80\x94why be the "funding source" for SI and openphil? The two organizations are not direct competitors (and probably have separate roles at different points anyways), so why is everyone interested in funding SI funding also interested in funding openPhil AI Risk Grants? Basically\xe2\x80\x94because SI is well-known, and it's something which different organizations in the EA/\xe2\x80\x8brationalist community may have common interests in; SI's projects are a source of knowledge for other organizations. Conversely, many individual organizations may have good reasons to want to fund SI.</p><br><p>(note: not all of this will be in my notes at all times; I try to add only things I think are actually relevant)</p><br><p>AI Impacts</p><br><p>Main focus: AI forecasting/\xe2\x80\x8bstrategy.</p><br><p>There's also a potential "AI safety" focus, but it's smaller than with SI or MIRI and there's not a lot of it; it might be one of the few projects they fund with a "pure X-risk" focus.</p><br><p>The project I've found most useful so far has been the AI Impacts podcast. They are interested in a variety of AI-related topics, but they specifically focus on forecasting: I have some confidence, and I hope, that what they can provide could make a big impact on the field of AI as a whole. I also like the quality of their work, the speed at which they publish new episodes, the fact that they are relatively new, the relative anonymity and lack of obvious affiliation (as this post shows), etc. Their website looks like a project worth funding, especially for individuals interested in forecasting.</p><br><p>Other organizations</p><br><p>I don't think any of the organizations I've looked at have significant overlap between them in terms of what projects they are open to funding, or even what projects they are specifically currently open to funding. This makes searching for information about specific projects hard. However, these are some of the projects I have found; I plan to keep searching and potentially posting updates about additional organizations I find.</p><br><p>Here are some of the things I found in a preliminary search; please add to the list or provide links if you know of other projects, especially if you know more relevant information:</p><br><ul>
<li>AI Risk Camp</li>
</ul><br><ul>
<li>AI Impacts (podcast)</li>
</ul><br><ul>
<li>MIRL (Machine Intelligence Research Lab)</li>
</ul><br><ul>
<li>Ought /\xe2\x80\x8b MIRI's (formerly)</li>
</ul><br><p>Most of these come with something like a "meta" mission; i.e. funding for one of these is generally going to fund other things of a similar type, too.</p>      </span>    </div>  </div></body></html>