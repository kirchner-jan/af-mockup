<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Some Notes on Group Rationality      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Eliezer Yudkowsk</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p><strong>Followup to</strong>:  The Intelligent Social Web, Your Strength as a Rationalist</p><br><p>The notion that groups are irrational might strike some as obvious, and that people should therefore be skeptical of new group theories of social behavior.</p><br><p>In a real sense, if you have trouble believing that groups are rational, you have to believe that, if you take two groups:</p><br><ul>
<li>A group in a medieval castle</li>
</ul><br><ul>
<li>A group of Internet chatroom participants</li>
</ul><br><p>and if you ask the two groups to divide up the castle, then ask them to decide where to put the cannonball\xe2\x80\x94you'll see their choices made in spite of their individual rationality.</p><br><p>Likewise, if you ask two medieval castles to choose an arm of the river, and you ask two Internet chatroom participants for the same task, you'll see that the castles <em>will</em> choose the same location and the (individual) participants will <em>choose</em> the same location.</p><br><p>But I can understand, as a person who's spent time on Less Wrong, the reaction\xe2\x80\x94which seems to be common\xe2\x80\x94to:</p><br><blockquote>
<p><em>Wait, have you not heard about _____the rationalist community_____? What if it _isn't</em> irrational? Isn't that a bias in your own mind, caused by your own beliefs about rationality? Don't you dare say a word about group rationality!_</p>
</blockquote><br><p>Yes\xe2\x80\x94says a Less Wronger in despair, who had hoped that group rationality was the one special thing that all the rationalists had already figured out and were just waiting for you to figure out too.</p><br><p>But in reality, as any rationalist should be able to see at a glance, this sort of argument is the classic way that cults and religious fanatics and the like convince outsiders to join their groups. And people who are genuinely convinced that their own religion is unique and above all the others, are not likely to be impressed by the phrase "Cults are common!"  For cults and religions are very very common by historical standards, even if they are uncommon in your local culture. This is the sort of thing that rationalists should already be well acquainted with.</p><br><p>To a first approximation, groups are very often optimal, but only in a very specific sense.</p><br><p>If you say "But some people will join cults", you can be sure that the group <em>already exists</em> and you are discussing it at the time when it already existed, and so your prediction cannot be relevant.</p><br><p>If there are two medieval castles near each other on the river, and the castles know this, and then you present them with different problems relative to their choice of where to place their cannon, they're probably going to give the same answers _whether or not _the castles are rational. One castle might have no cannon, the other one might have been built by the same architect; if you ask one "where should we choose a place for our cannon?" and the other "where should our cannon be?", there probably has to be some sort of logical answer to the two questions, even if the particular question is not relevant or relevant in the present. Cached thoughts are not really the right word for the kind of information they contain\xe2\x80\x94although there is also some sort of logical explanation for the fact that medieval castles happen to choose the same place for their cannon.</p><br><p>Suppose you ask the people in a medieval castle, or the citizens of the Village Inn, or the inhabitants of two Internet chatrooms, how to choose where to place a cannonball in such a way as to make it go where you want. On the hypothesis that each castle and local community <em>already knows</em> where it should be placed, <em>which is part of what they know about</em>. And if the cannonball is fired from just out of sight <em>on the other side of the castle</em>, they might have to think about where it should be.</p><br><p>In other words, on the correct view,  the fact that people tend to end up joining cults and going to church is not a good reason to assume that rationality is, perhaps especially, hard to find and hard to explain, since the fact is not that rationality is hard to come by.</p><br><p>Also, people don't expect the Rational Answer itself to be difficult to find, only something inapplicable, something that requires a leap of insight. They expect a small, specialized pool of existing answers, that must be searched from outside the group that already understands, by people who already know how to distinguish good answers from bad answers.</p><br><p>In particular, they may expect some sort of visible <em>sign</em>, something that shows beyond doubt from the outside, that there actually <em>is</em> some rationality to be found that can be easily expressed in words\xe2\x80\x94maybe something you've already heard. This is the kind of thing that cults and religions often try to claim, in order to appeal to the outside. And the more specific the claim they make, the more likely you are to expect them to say it. "There is no rationality!" is not a likely claim to hear if you've looked at a hundred cults and seen none of them claiming that they were unique. Cults usually do not mention specific things they already know; they use things they want outsiders to believe.</p><br><p>On the other hand, I can well imagine someone arguing from the outside that the Rational Answer is "The one true way to choose where to put the ball!" and you wondering why they are insisting so strongly on the question or looking for words to describe a special knowledge you are already familiar with.</p><br><p>But these are just <em>one way</em> in which cults and religions might be mistaken. You can also suspect <em>wrongly</em> that there are no rationality skills, and that you'll <em>have to see them with your own eyes</em>, learn them on your own, be the one to bring the wisdom from outside the group. You may start saying things of the form:  "Well, you only believe X because you were <em>told to</em> believe in it."  Or even worse, "But since it's the Rational Answer, it must be true!"</p><br><p>There are a few points about rationality, which I can guess are not original with me:</p><br><p>First, it is actually quite easy for people to get <em>slightly</em> more rational about their own beliefs about politics. The way I think of it, if you have some sort of cached thought where you say, "I believe in X because the Church told me it was true" or "I believe in politics as I am taught in school"\xe2\x80\x94then if you are <em>looking for</em> rational reasons for your belief, you can find one.  (And not in the exact way you were taught, and not in the exact place in the brain that says, but one of those reasons will probably do.)</p><br><p>Or it could be something like "I want to be rational, so I want to eat meat, because I believe that if I eat meats, then I will feel better", and this belief could indeed be justified by an argument from the inside. A belief should not have to be justified by outside argument that is already known to you, but that may itself be inside you, stored in some way that took a while to explain. You have to actually look.</p><br><p>This is difficult\xe2\x80\x94because the same belief might be stored in different places in different people's brains, which are themselves difficult to explain; or a belief might be very hard to find even though the underlying process that explains it should be simple and obvious; or beliefs can be justified by arguments in retrospect that are <em>not</em> easy to justify by the same internal process that generated them.</p><br><p>There is a real danger of being too quick to say that rationality is harder to come by than it is, or that the Rational Answer exists and you have to locate it. This is the danger that, I think, is behind the notion of "It's not rational to go around saying how clever you are, when you're wrong."  The problem does not have to be an unanswerable one; I can see a Bayesian argument for what it is right to say to someone, on some occasions. I can see an argument for some occasions to change your mind about something, even when you already have enough evidence (if you have the courage of your convictions) to know that you are being correct, and then you discover that someone else also knows the same thing.</p><br><p>If, when you are wrong, you are always so very very wrong, that you cannot possibly imagine any possibility of it being wrong, you will have no incentive to improve your errors, and no justification yourself to change your mind...</p><br><p>Or if you say, "The Rational Answer is X, and Y is not X" or "If you wish someone to change their mind, you must be able to explain to them why X is mistaken", you're telling yourself a lie about how the world works, and it will take more faith to go on believing it. You should be able to explain why the Rational Answer contains its parts.</p><br><p>Second, there is a great deal of overlap in the categories of things people want from their beliefs and why they believe them. There is overlap between wanting truth, wanting to be well-informed, and wanting your conclusions to have a high level of coherence, among other similar aims.</p>      </span>    </div>  </div></body></html>