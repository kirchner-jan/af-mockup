<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Inventing the Future: A History of Thinking about Technology      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Greg Lewi</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p><em>This is part 1 of a three-part series, in which I chronicle my personal history as I come to learn more about rationality. In part 1, we will see a brief history of how I discovered the path to rationality, from where I started to where I am today. In part 2, we will learn about my progress on that path and see where I am, on which subjects, and with what tools I have become more rational. Part 3 will be about my life today, how I use rationality to help me maintain my personal growth, and what I have learned about the art of rationality since becoming interested in it around the end of high school.  --</em> _Gregory Lewis _</p><br><p>_All I'd done was learn about a bunch of stuff: physics, probability, logic, and game theory. It seemed like a natural progression. I figured out the laws of gravity with a telescope and a lot of trial and error. I figured out that the probability of an event happening is related to the complexity of the event as a program. And I wondered why people didn't do this all the time. Surely, this is really, really important! But I didn't think about it very hard at first. It just seemed like obvious stuff. I spent the next six years doing research and teaching in various ways around computers and AI. _</p><br><p><strong>I'm not that good at explaining this one, so instead the story of my journey to where I am now is just going to be more an account of what I did rather than explaining. A couple notes at the start:</strong></p><br><p><strong>Firstly, the story is a bit strange (to an Eliezer fan, at least. I wasn't a fan of Eliezer up to about halfway through his second book).</strong></p><br><p>As I said, the part about how I discovered the way of rationality happened very gradually. And as such, there were many false turns.</p><br><p>I started to think about a lot of stuff. One year, I read a book (A Pattern Language) about how to build green spaces around old houses. A lot of people found this interesting at the time for various reasons- they liked the idea of trying to understand a lot of systems. There were other times I tried to think more systematically in a way that seemed, at the time, like a natural continuation of previous things. I was a very enthusiastic grad student in math and computer science, so I thought the things I noticed in math would apply more broadly in the world around me. And I found that I did, some of the time. But then I ran into the problem of being able to understand more than one thing well at the same time. This, of course, lead to a lot of failed attempts to understand reality because they got things backwards in some way. I started reading a book that talked about the mathematical nature of reasoning in humans, but after taking some math classes I decided that I also wanted to understand it in other fields, and the books that I found there didn't really seem to talk about AI. And so I started reading some more things about AI in general, but then I realized that AI wasn't all there was to AI, and that it wasn't even all there was to most of AI. And so my next step was to read a lot more about the history of AI, but then I found that there wasn't much of that, but that _if I could understand all of AI, I could understand everything else in AI, and then I could understand what the AI researchers were trying to do on their own merits. _I found that a lot of the foundational principles of many other people had started in the same place as those that would eventually lead me to a correct algorithm for solving problems. And so I concluded that, well, maybe I could understand things by understanding general principles.</p><br><p>If you hadn't have known anything else he'd said, you might have concluded that this guy was way off base. There are people who know loads of things, and if you think they're right, it's because you had heard their ideas at some point earlier, or maybe you happen to have stumbled across some of their papers earlier. But that turned out not to be my situation at all- I'd have to try pretty hard to even tell what his previous thoughts in these areas were.</p><br><p>__So now we have the story of how my journey went: as I was reading, I asked myself a lot of questions like what <em>did</em> he mean by what he was saying? Why did he say that? Did the ideas seem true to me or not? And what was I really learning with the course that these ideas seemed to be coming from? What are some other things I could do to figure out what was going on? And was what he was saying the truth? This sort of thinking, if you've never seen it before, may seem really strange and hard to do (and you can, if you're clever, just ignore it on the level of the ideas themselves, so you can get to the real things quickly). But in a lot of the cases, I found I was able to do it, and that it did a lot of interesting things. But I did end up making some more fundamental changes at the end of the course than I would've found in the class, because I was thinking about it for a while before class, and they basically taught me one thing with no other changes, and didn't even tell me why other things I thought made more sense.</p><br><p>At this point, I had already read a couple things in AI theory, but then there was a gap, and I was trying to fill it in by trying to figure out how other people worked so I could figure out how to work differently. In the book called Artificial Intelligence: A Modern Approach, there are sections that give an overview of things that have been done in AI- in logic, learning, planning, and more. And the chapter I read called the historical period covered many different pieces of work- some done by psychologists, and the people in AI are really the ones who have done the most in AI- but, as I said, there wasn't really a reason that work on AI was put together, or even particularly relevant to later work in AI. There was just some work done in logic and learning that was, in hindsight, really about AI, and then they took one work that wasn't AI and tried and failed to apply it to AI. Because it seemed really obvious, and not an interesting idea. And of course, this led to a bunch of other failed attempts at understanding the future.</p><br><p>As you might expect by now, I read one bit of a bunch more in AI, and that led me to look at some of the other ideas that AI people had come up with in their studies, and there was a bunch that seemed right but not enough that I could write down an algorithm (or just something simpler) that they were pointing at (so I decided to look at some papers by the people who had seemed good at seeing things correctly earlier), and there were some papers that were about more of the <em>current issue</em> for AI people. And this was getting me to the start of what I now call "thinking the problem out" (I don't think of it as thinking about AI- I think of it as using some AI-related tools to understand the world enough to write algorithms without knowing what the algorithms will actually be for). Now, you can do all sorts of different things in computer science, but in the beginning I focused on a few areas related to AI (that was because those were the main places in computer science where I could contribute to anything useful that seemed AI-like in some way, and to do that I did need some more basic knowledge in math, physics, and game theory- the other problems I didn't necessarily want to tackle just seemed much more abstract, so I tried to tackle the things that had more immediate results as my first try, and this was how I started thinking about how to study math/\xe2\x80\x8bcomputer science and get the best results from it.</p><br><p>__So, that's where I started. I spent a while trying to improve my writing skills, and then I decided to spend another while reading and trying to improve my understanding of game theory and decision theory (this was before reading Rationality: AI to Zombies).  This was all very frustrating. I could understand the math, but I wasn't getting anything out of it, and it was really hard to know when something would actually be useful or whether something was just going to be an exercise. I had a lot better luck with game theory because I could <em>try things</em> a lot more than I could with AI. I started to wonder whether this was any better- just by learning the foundations of the things- versus really learning the systems themselves, and that lead me back to looking at other places in computer science.</p>      </span>    </div>  </div></body></html>