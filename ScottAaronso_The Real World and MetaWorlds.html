<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        The Real World and MetaWorlds      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">ScottAaronso</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>(Content warning: math/\xe2\x80\x8btheoretical physics)</p><br><p>I often write about the "meta"-world which is out there, separate from the "real" world. Some of my best posts are about this meta-world.</p><br><p>I wrote the previous piece on decision theory mostly because it was clear and short, and because decision theory was the one part which, by that time, I had figured out in a way that seemed to me to be "correct". I've come to realize that decision theory is part of the meta-world, not the real world. But decision theory is an interesting part of the meta world on its own, so I'm writing another post which introduces it, with some emphasis on how it works in a real world.</p><br><p>My background is in theoretical physics. In that setting, the "meta-world" I am talking about basically just is the real world. It exists as part of reality and can interact with reality, both physically and conceptually. Yet, for the purpose of formal reasoning, it is treated <em>separatly</em> from the "real world". In particular, we can use <em>mathematical</em> means to <em>explain</em> both the real world and the meta-world: that is all I'm talking about today.</p><br><p>I'm going to be using the standard technical definition of "model" here, where "model" refers not to "information about reality which makes predictions in regards to reality", but rather to <em>all possible information</em> about reality. It could be a model which uses no knowledge about reality at all, or a model which uses all the knowledge of science regarding the real world.</p><br><p>The reason I am using this unusual standard, is that what we usually use as a model in mathematics/\xe2\x80\x8btheoretical science is usually not something that exists in the same sense that the real world exists, but simply a <em>way of knowing</em> about some part of reality.[1] A model is more or less what we know about a part of reality. It's one way of knowing about such a part.</p><br><p>As an example. The real world is not "made" of particles. We know enough about human physiology to know that the "observer" is ultimately composed of particles. But when we think about the observer, we do <em>not</em> imagine that the observer is made of particles, but rather the "measurement process" which detects the observer is made by particles, which then interact with other particles. We can even talk about the existence of "observers" without using "observers". We can talk about "observers which record data that gets sent to other observers". We can even talk <em>in principle</em> about information being transmitted without imagining the physical existence of the receiver.</p><br><p>There is obviously some connection between the real world and "mathematical information". We can construct a "model" for "mathematical structures" by thinking about a part of the real world. We can construct a model for "mathematics" by thinking about the nature and behavior of mathematically possible "sensors" which we might conceivably attach to our universe. But once we talk about the "mathematical model", we have lost touch with reality. We are just talking <em>about</em> the way we think about reality. We are not talking <em>about</em> anything which exists in some <em>independent</em> sense in the real world. The question of "whether there are physical objects out there that model the environment" is meaningless if we are talking about some abstract model rather than talking about the real world. That would be like asking whether some abstract concept like "tree" has mathematical objects that exist in the same sense in which the real world has objects.</p><br><p>Of course, I am talking about the real/\xe2\x80\x8bmetaworld here. The meta-world <em>is</em> part of reality. As such, part of the real "meta"-world is parts of the real world which are mathematical models. Or rather, the <em>way</em> the mathematical model behaves is to be a model of reality.</p><br><p>A key question we will return to later is: <strong>what if we discover some mathematically possible physical process that is mathematically isomorphic to a model which exists in some part of the real (meta-)world, but which does not correspond to anything we observe?</strong> Such a mathematical process might have no real world counterpart; it might act purely on a conceptual level. But we have discovered such things before: the mathematical description of Maxwell's equations does not describe "light waves"[2]. So then, <strong>this is why we can't conclude with certainty that such a physical process which behaves abstractly is meaningless. Some real world process may just not be mathematically isomorphic.</strong></p><br><p>To return to the decision theory part of my topic, let's consider two different types of decision algorithm. The first is the <strong>real world decision algorithm</strong>. The second is a <strong>metamathematical decision algorithm</strong>. A concrete example is an AI which takes actions to maximize some utility function. The abstract interpretation is a decision-making process in which the agent has perfect knowledge about the dynamics of the world, which is then applied to an appropriately constructed utility function to find the action with the highest utility.</p><br><p>Let's suppose, for a moment, that we have good reason to believe that if we run the real world decision algorithm on the real world, it will come out to an action which will make our real world self-unaware. (Of course, it is not clear in what sense the thought experiment is possible.) For the sake of simplicity, let's also assume no other side-effects on the real world. So we think that running this algorithm, without being aware of it and with perfect information about everything that will happen due to the algorithm, will cause the real world to choose to destroy itself.</p><br><p>Given these premises, does that <em>mean</em> we should destroy ourselves? Maybe, but why take this particular route rather than all other routes? (Also, are there any routes other than this one? Do we even know what would happen if we ran this algorithm on the real physical world we live in?)</p><br><p>What if we run the metamathematical version of the decision algorithm instead?</p><br><p>The metamathematics can include a lot of information about reality, most often in the guise of the agent making the decision, including information about the physical world it finds itself in. So we take into account all of that available information: what would the agent do?</p><br><p>In that case, the agent will choose to destroy the real world. Of course, it is once again not clear that we should take this particular route, but why not? What if we run the same algorithm on a simulated world and find that in the simulation it will choose to destroy itself if we run the algorithm with perfect knowledge and perfect awareness of the world around it.</p><br><p>So what? That's what decision theories do by default! The agent takes into account all the logically possible information available: which of them (which world, what is the action?) would be the best? Or in standard phrases used for decision theories, it "chooses" the action, which maximizes utility.</p><br><p>At this point you might think: what about Newcomb's paradox? I guess you haven't heard of this one:__</p><br><blockquote>
<p>You are in a box. Before you there is a one-way mirror. In the other side of the mirror, there is a very smart and powerful being\xe2\x80\x94a superintelligence.[3] The superintelligence has two boxes, and in one of those boxes is a diamond, which it wants to bring into this world. The other box is something else, which the superintelligence wants you to take into this world. For a specific reason, it has prepared for such box one that has $1,000,000. </p>
</blockquote><br><p>So you have two choices. The first is to empty your pocket, and take the diamond (that is $1,000). The second is to take both boxes (that is to take $1,000) and the superintelligence never sees you again. Which is preferable?</p><br><p>The one-boxing decision theory will say that taking both boxes is preferable to taking only the diamond. But the two-boxers will insist that it <em>has</em> to be this way to avoid the paradox! That the superintelligence will see you in the other box (which is one box), which means that taking the other box is actually worse for you! I feel like there is a mistake there, and I'm not seeing it. So, does anyone else see it?</p><br><p>Anyways, the point is, it seems to us that if you run a decision algorithm on the whole universe, you should end up taking both boxes, but the one-boxers claim this is not possible. What if the superintelligence never <em>knows</em> you are running a decision algorithm for all the mathematically possible universes as a function of <em>actual</em> universes, in a similar fashion to how most people don't know that quantum physics exists? They think it's all about atoms (or the other usual way of thinking that it's all a big joke).</p><br><p>Note that __taking only box Y, which only a real world version of you could see, is one possible decision process __which the two-boxer can accept, without the paradox. It is the decision process where the agents self-awareness goes through box Y just in time for the two-box argument to work out. On the other hand, a decision process where you choose to not take box Y which you know you are running <em>is not a self-aware agent</em> which two box would destroy.</p>      </span>    </div>  </div></body></html>