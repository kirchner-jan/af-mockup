<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Some Thoughts on Long Termism      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Ben Pac</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>I'm pretty confident about this, but it took me a long time to reach this point</li>
</ul><br><ul>
<li>My general approach to dealing with long-termists</li>
</ul><br><ul>
<li>I really am happy about most people's decision to prioritize their own career over helping the world, that's actually pretty great</li>
</ul><br><ul>
<li>I do see it as generally better if people donate a larger fraction of their income</li>
</ul><br><ul>
<li>My actual beliefs about long termism</li>
</ul><br><ul>
<li>"Donating to effective charities is an inefficient comparison to donating to LW" seems pretty obvious, but it still surprised me enough at the start that I had to look into it</li>
</ul><br><ul>
<li>Efficient Giving</li>
</ul><br><ul>
<li>(Inefficient) Direct Charity</li>
</ul><br><ul>
<li>Cost-effectiveness of Effective Altruism, if you think it exists</li>
</ul><br><ul>
<li>In summary</li>
</ul><br><ul>
<li>My beliefs on other long-term issues</li>
</ul><br><ul>
<li>EA's obsession with X-risk</li>
</ul><br><ul>
<li>I think effective altruism can do more to improve the long-term future</li>
</ul><br><ul>
<li>EA can do much more to help the long-term</li>
</ul><br><p><em>Preparation note: I really dislike this post; it's just going up because it's got to go up now and it might be easier to re-write this later if it actually has to go somewhere else. Also, I'm using longtermist as a short-hand for long-term thinking generally as many people who call themselves "longtermists" have a variety of beliefs about the long-term that could be confused with EA beliefs, but I'm not trying to write as if EA is a single unified thing, just as "EA" is just a shorthand for "things people agree on (as opposed to me being confused) including "the long-term future". So, sorry!]</em></p><br><p>In December 2021, I wrote some meta posts on my personal blog, where I argued that I was quite confident that something was an epistemic-irrational stance that longtermists take.</p><br><p>At the time, I had not actually become longtermist, I'd just been thinking about EA a little and it had seemed like quite a coherent worldview.</p><br><p>I thought it seemed particularly bad when people were not just arguing for longtermism but <em>arguing for their longtermism in the EA community before being longtermists _and _arguing in favor of their longtermism while still not understanding how to coherently donate longterm.</em></p><br><p>This post is an attempt to clarify my beliefs and try to convey them as clearly as I can.</p><br><p>I'm pretty confident about <em>these _beliefs, but it took _me</em> a long time to arrive at these beliefs, and I'm not completely sure if I've changed my mind since then. (I mostly don't think so, but it's a little tough to tell!) If you think I should write a post on the topic of epistemic vs instrumental rationality in EA, feel free to suggest that! I think it's a common theme there and important to keep track of.</p><br><p>I'm quite excited for people to be able to understand what LW thinks about long-termism, and I'm pretty happy in-the-moment that most people around me don't actually care about the long-run. I think a big majority of people around me actually care about improving the long-run right now, especially in the past ~10 years.</p><br><p>It's very rare for people to explicitly care about the long run, and that's great, but I don't want to downplay that effect because that's _especially _important! It means that long-termist is more like "people care about the long term" than "people explicitly care about the far future." I think that actually pushes people in the other direction: I think people implicitly care _lots and lots _about the far future, and that's why most people in the world today are very interested in the far future, even if the far future isn't getting attention in a particular cluster of organizations.</p><br><p>I really am happy about people prioritizing their own careers over helping the world. That's <em>amazing _that more of people actually do prioritize their careers over helping the (far) future. And: I think most people do, in practice, contribute a _tremendous _number to the long run. Not necessarily in an explicit way, but most of the people at Effective Altruism Global are just being really awesome, and they're the ones who get the _most</em> credit.</p><br><p>I will try to write the part where I'm most certain about why longtermists think what they think, in the order they think it's most convincing to them. But first, I think I should add some context to the issue.</p><br><p>I really do think most people think they care about the longterm, and in practice that's the impression that they give off. I think when most people talk about effective altruism (EA), that's what they're thinking of. They think that it's a coherent world-view, that different EA communities have developed, that EA is a movement. And I have _many _longtermist beliefs, including some that most people don't agree with. But I mostly think I'm _defining EA _the same way as most people do, and I find it pretty clear in practice.</p><br><p>"Donating to effective causes is an efficient way to give." I think this seems pretty obvious, to almost all longtermists. And I think that's a pretty good reason for everyone to focus on their own career. But I am <em>extremely</em> skeptical that it's true.</p><br><p>The only time that I think people are mostly doing a good thing in life by donating to effective causes is when you believe that effective altruism is better than direct <em>charity</em>. Because then the EA community's focus on X risks _really does _mean that they mostly care about the far-future. That is, if you were an Effective Altruist who thought that the far future was best optimized, donating to effective charities might not be the best way to help. But this seems _extremely _rare.</p><br><p>The most interesting longtermist disagreements that I have, are with people who just don't think there are coherent things that could make the far future much better than X risks. I think that one of the most important lessons about effective altruism _is _that EA seems to be much more concerned with X risks. And I think this has to do with the fact that EA members _do _have very different beliefs than the outside community. (One example I frequently find people making _is saying there are a finite number of people who can be made happier, and effective altruism just has a particular view of what should be done with those people. That people can't possibly be made happier that much, or that no amount of money can help, or that the best way to make people happier is to just make people happy, because that would be sad to do.)</p><br><p>This seems to me like a pretty clear and fundamental difference between how people think about the longterm. It could be a bunch of other disagreements, but this does seem relatively well-established to me.</p><br><p>I think we should have disagreements over consequentialism, justifications, and values, but should all be pretty clear about <em>what you think people think and are thinking</em>.</p><br><p>My general approach to dealing</p><br><p>With Longtermists, there's a general approach that I have. And here's the way I think about these different positions.</p><br><p>The EA position seems pretty good to me. I think most people agree that EA positions seem pretty strong!</p><br><p>I'm <em>not _agreeing they're _perfect. _EA is _much</em> better than direct charity in many ways, and I think it can still become _better _if people are aware of it. And I think EA has a lot more resources available to it, and that makes EA positions seem more likely to reach the "good" status faster.</p><br><p>I'm more optimistic about other positions than the EA position too. For me, I think there are actually _plenty _of bad long-termist positions, or things that are really bad and can't be justified.</p><br><p>The EA positions seems good in the sense that I don't know much about direct charities, but people seem pretty confused over effective altruism's claims that they should do direct charity. And I _do _think that EA claims like "People can be made better" are important, and it seems that EA claims can be important.</p><br><p>But I think EA does much _worse _than direct charity in many different ways. And I think most people probably do worse than effective charities on most important issues.</p><br><p>For that meta-reason, I don't find the EA position to be as compelling to me, so it's important to get into the differences between the claims we disagree about.</p><br><p>I think a lot of my disagreements with Longtermists relate to my perception of what their views are. If you are an Effective Altruism type who thinks it's important to help others, you can end up believing that your <em>best</em> way to help people is probably indirectly. I think most EA's would disagree that they'd have that conclusion. And I expect that if you looked hard enough, there'd be an argument for why the best way to influence the far-future would be to help the longterm. But I think most people don't spend the <em>time</em>.</p>      </span>    </div>  </div></body></html>