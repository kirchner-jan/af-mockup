<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        A Model for Technical AI Safety Research      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Rohin Shah and Joe Collma</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>Terminology</li>
</ul><br><ul>
<li>What will this model say?</li>
</ul><br><ul>
<li>Data-driven approach</li>
</ul><br><ul>
<li>Human judgement</li>
</ul><br><ul>
<li>What it's not</li>
</ul><br><ul>
<li>Current applications</li>
</ul><br><ul>
<li>Conclusion</li>
</ul><br><p>I want to explain a model to do technical AI safety research that I've been thinking about a lot over the past couple of days. Unfortunately, I haven't been using this model in my thinking: I started using it to explain my thinking to some people but stopped doing so after I'd already started writing the post.</p><br><p>I don't want to give away any ideas for how this model would look, or which things it might say. If you want to see something like that just take a look at this earlier post.</p><br><p>My hope with writing the model myself is that it will become better as other people use it. I'll list some of my thinking about the model below, but I won't be explaining what I'm thinking about the model, so you won't be able to judge my reasoning, including if the reasoning is wrong.</p><br><p>The model is split into three parts: what I'm calling a <em>data-driven approach</em> for AI safety research, a <em>human judgement</em> step, and (if you want to) a <em>current applications</em> step.</p><br><p>Terminology</p><br><p>The data-driven part is the part I care about most: the model explains how I think about technical AI safety research. The human judgement is how we <em>actually</em> think about technical AI Safety. The current applications part lists three domains where machine learning is being used that I would count as "AI", and these applications are particularly salient because we haven't had time yet to do much in-depth research on them.</p><br><p>The first section of the model is in fact the first section of the post. For example, if you had just read this you'd know what data-driven approach I'm thinking about\xe2\x80\x94but if you'd already read my earlier post you wouldn't.</p><br><p>Thus, I'm providing some context before I continue, via the model as a whole.</p><br><p>I think that a big part of the reason that these parts I'm using the names "data-driven approach" and "human judgement" while also having the current applications parts be fairly important is that I want to build towards the last part by showing that data-driven and human judgement are parts of a broader and larger model, which is why I'm calling them "the human judgement part".</p><br><p>What will this model say <strong>eventually</strong>? When it's <em>actually</em> working in practice, I think this model has the potential to lead to all of the following: (a) a better understanding of what humans are actually looking for when we're using ML for technical AI safety research (maybe via an empirical study or a more philosophical explanation), (b) a better understanding where we should apply and don't apply human judgement in cases we're using ML as we understand them right now, (c) a better understanding how ML and human judgement interact, and (d) a better understanding what's currently missing from a theory of change and possible research agendas and what we can do to help make them more plausible.</p><br><p><strong>This is what I'm planning to say about it in the short term:</strong></p><br><ul>
<li>This model is intended to be an aid for people who want to contribute to technical AI safety research, and who are currently confused about what to think about. I'm thinking about it in the context of research orgs and people working professionally in technical AI safety, but it could easily be used by anyone with an interest in the subject.</li>
</ul><br><ul>
<li>One reason I'm thinking about is a feeling of "if you don't know what to think about now, it makes sense to start by learning what some of these terms and concepts mean". I don't think this is how the average person is starting out (in general) in understanding technical safety work\xe2\x80\x94so I feel a sense of "if you can help that person understand technical safety research, you could help improve their understanding of all other aspects of it too..."</li>
</ul><br><ul>
<li>I've often found that the first and most confusing of the concept-terms in my head is "ML", or "AI", or "the field of AI", or "AI safety"</li>
</ul><br><ul>
<li>At the same time, I want to try to be as specific as I can while not being too imprecise (or "too general" if you prefer). E.g. if I say "AI safety", I would prefer to say "AI safety with a goal of good outcomes" instead of "AI safety", since by choosing the later, I'm opening myself up to misunderstands such as "what do you call the field of AI safety?" asking. This is the sort of thing I care about.</li>
</ul><br><p><strong>My hope is that eventually this model will help people make good choices around questions like "how much human judgement should there be in technical AI safety research", "should we focus on areas that involve ML more than areas that involve human judgement", etc.</strong></p><br><p>At a meta level, I'd like for such a model to be usable as a research agenda: I think that in the next year or two or three years, I could imagine people wanting to look into the details of this model, and then doing research on the details according to it. However, you're encouraged to take the model and adapt it to whatever your needs are, rather than to stick with just the parts about data, judgement, and current applications. (That said, you can use the model as a starting point, rather than starting with the parts about data and judgement.) As a result, the model is a more work-in-progress, and what I'm actually referring to by data-driven and by human judgement are the parts, or parts-of-parts-of-parts, rather than the overall model in and of itself.</p><br><p>I'm planning to use the model to answer questions around AI safety: in my current headspace, I find it hard to think about what AI safety might be, and this model might help me to make more progress on it in the same amount of time.</p><br><p>Data-driven approach</p><br><p>The data-drive is the part I'm least confident about, and so it's the portion of the model most related to uncertainty. Here, I'll summarize what I have in mind:</p><br><p>In order to do technical AI Safety research, the best way to understand it is to think about it in terms of ML systems, and to try to understand why ML systems are doing what they're doing. It seems to me that the key part of a technical strategy for ML systems is figuring out some sort of algorithm that correctly figures out what the reward function or objective is, for a given training data from some domain. There are two questions I'm focusing on for what this means: first, what sorts of "reward functions" could there possibly be for training ML systems, if the concept of "reward function" is even well-defined? and second, if you have some particular algorithm in mind that you're training, and you see why it's useful, what's stopping you from just replacing it right now by a new algorithm with the same effects that would be better at achieving its aim?</p><br><p>I'm assuming that people in ML do basically think about these questions. I could be wrong, and I want to correct my mistake (or point out the error) by showing how I am.</p><br><p>It's easy to get caught up in the terminology of data vs supervised training vs reinforcement learning, but I want to think in terms of the two key questions I am interested in\xe2\x80\x94the "reward function", and the algorithmic replacement step. I think the reward function is really more a question about the domain-in-general, than it is about current ML methods: there aren't different models of a robot moving about with different "reward functions". Rather, the distinction I care about is whether the general "thing" that a certain RL algorithm is doing works as well in future or new (and different) situations. In particular, I'm concerned with whether ML systems are able to use their general reasoning abilities to figure out reward functions (and other ways of defining what they want, but I'll focus on how reward functions fit in here).</p><br><p>As I list in the "Data-driven approach" of the model, my focus on ML systems is informed by my belief that ML systems are particularly powerful, and will likely continue to be more powerful, and I care about them because that means that if ML systems can figure out reward functions, they will likely be capable of doing a lot of positive stuff. Conversely, it's possible (and common) that AI doesn't take over the world. Even then, it could still be useful to study AI safety research, because our research could also eventually make progress towards a world where AI takes over the world (in which case it might be useful to have AI safety research in particular, because it could help us as a society decide what to value in such a scenario), or because a world with ML systems that take over the world could also be a better long-term world for us (in so far as we prefer that to a world where they just take over slowly, or where they can't do any harm).</p><br><p>In any case, I have my eye on the general problem (that of reward function discovery and/\xe2\x80\x8bor algorithmic replacement) and the general solutions I'm expecting (to a much greater extent than any solutions that I know about for ML systems right now).</p>      </span>    </div>  </div></body></html>