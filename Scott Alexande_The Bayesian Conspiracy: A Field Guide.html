<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        The Bayesian Conspiracy: A Field Guide      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Scott Alexande</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>The Bayesian Conspiracy:</p><br><p>It starts with Eliezer Yudkowsky, the brilliant Oxford cognitive psychologist turned Bayesian evangelist.</p><br><p>In a 1988 essay, he describes two fictional characters, Robin and Eliezer, representing two divergent epistemic positions on a controversial issue, and makes a bet with them:</p><br><blockquote>
<p>Suppose Eliezer and Robin had a <em>de novo</em> disagreement about which of them was more intelligent. Would Eliezer back off, admit defeat, and agree to reexamine the issue as a compromise? No. Eliezer would fight, and if necessary he would lie... lie about everything; invent "facts" and "reasons" and "justification" to persuade himself and everyone else that Robin was the "intelligent one". This is Robin's "strategy of offense"\xe2\x80\x94taking whatever argument the other person gives you, turning it inside out to make it look wrong, and then repeating the process as often as possible.</p>
</blockquote><br><p>The essay's main lesson is that most disagreements are really about power, since if it really <em>was</em> a case of two people trying to evaluate different things on their merits, then both of them would just stop talking to each other. But so often it's the case that someone <em>thinks</em> they're arguing about something that really isn't.</p><br><p>In one of the more famous examples, a professor at Cornell told a class about how he had studied under Wittgenstein, and in one of his lectures said that Wittgenstein had been an "amazingly good" teacher, because his main principle when explaining anything was to "tell the student they were wrong":</p><br><blockquote>
<p>The students laughed. Wittgenstein didn't. He was, indeed, rather prickly about such things.</p>
</blockquote><br><p>Wittgenstein, with some justice, was genuinely shocked by this kind of thing (though the class also knew, as he had explained to them, that this behavior on the part of faculty members was not uncommon on college campuses). Now he had an interesting idea. As he told the students "This is not right. If a teacher believes he is right and the student disagrees, then the student must believe he is right as well."</p><br><p>A couple of the students replied to this with, as they recalled it, "What if the student says, 'Well, you're wrong about this, but right about the next thing?' And Wittgenstein said, 'Then you must believe you're wrong about the next thing too.'" This is a very sensible reply, and is in fact the standard answer to this particular situation put forward in any philosophy textbook.</p><br><p>As Eliezer puts it:</p><br><blockquote>
<p>When human beings talk about "the truth", even when they are explicitly labeling their conversation as such, what they really mean is "the consensus view among academics who are committed to rigorous, honest dialogue".</p>
</blockquote><br><p>I say this about "truth" not just to explain that the phrase makes no sense on its own but helps make clear what the two characters are talking about. But as Yudkowsky explains more fully, the distinction between "consensus views of a profession" versus "the truth" is a subtlety that can quickly lead a conversation astray. Eliezer goes on to say that while there are obviously such views for things like math and religion, "there is at least one discipline \xe2\x80\x93 at least one profession \xe2\x80\x93 where the consensus view is not truth, but lies."</p><br><p>The consensus view, he says, is that "the only real experts in anything are the ones who don't care what other people think they know."</p><br><p>The problem with this explanation, according to Yudkowsky:</p><br><blockquote>
<p>it makes people suspicious that I'm telling them something I don't believe.</p>
</blockquote><br><p>I am not trying to convince you that my beliefs don't actually affect me at all. I am trying to convince you what an irrationalist perspective looks like. It looks like somebody who believes there is an objective reality that you can check for yourself; who believes there are some things that are definitely true about the real world regardless of which authority says so; who doesn't just accept his own beliefs, but wants to persuade other people of them as well; who does not just try to understand and explain the world, but who actually <em>changes</em> it.</p><br><p>According to Eliezer YUDKOWITZ:</p><br><p>People tend to reason based on their knowledge and then change their minds based on new evidence.</p><br><ul>
<li>Eliezer:</li>
</ul><br><blockquote>
<p>The one-sentence summary of a single, complete, internally consistent theory of rationality \xe2\x80\x93 in which <em>all</em> the procedures and algorithms and cached thoughts that make a human brain a human brain, have been understood, and specified in sufficient detail that a superintelligence could re-write the algorithm in code \xe2\x80\x93 is this:</p>
</blockquote><br><p>You should have an accurate map that reflects the territory. Whatever your map is, it should not be deceptive. You should be able to backchain any belief or assertion back to the sensory inputs that gave rise to it. You should be updateless; you should not be able to change your mind based on which information you discover later. You should not endorse any proposition you can't defend. You should not care who or what else believes your beliefs. You should not believe something unless you can actually prove it.</p><br><p>Which is to say, anyone arguing with Yudkowsky on any topic of rationality is engaging in some kind of mistake or other.</p><br><p>Eliezer's article continues:</p><br><blockquote>
<p>It begins by being suspicious of people who claim that there is an "objective truth". If there was an objective truth, then we wouldn't need to argue about it \xe2\x80\x93 we could just look at it, or talk about how scientific theories have predictive successes and failures, or whatever. The "objective reality" part sounds completely crazy. But it doesn't end there! The claim continues:</p>
</blockquote><br><p>Suppose I believe that the sky is blue. How can I <em>know</em> that the sky is in fact blue, rather than green? Or pink? Or the color of a certain shade of royal blue?</p><br><p>It's not so much that you <em>should</em> know, or that you <em>can't</em> know, or anything like that. But you probably <em>are</em> going to have a pretty hard time knowing, if you haven't spent any time looking at the sky. If you want to claim that the sky is, in fact, blue, you have to be able to cite specific experiences you've had. And those experiences include the sensory experience of the sky being blue, with exactly the same high-level neurons firing in your visual cortex as when you look at a blackboard, and there being a sensation of blueness that seems to be located in the same place in your visual cortex.</p><br><p>As I said, there do not seem to be any arguments that would convince a superintelligence of the existence of "objectively real", external Reality. But then <em>this means</em> we're actually arguing about something! We're not talking past each other! We're not arguing about what color the sky is! We're talking about the real-world consequences of certain belief systems and strategies for dealing with the world. And the only way we can talk about that, the only way we're allowed to talk at all, is using words like "true" and "believe", "real", and "existence", and talking about people trying to figure out what's really going on in their own minds and in the external world.</p><br><p>So, let's get back to Robin and Elieze. Suppose you've got a disagreement with Eliezer on how best to interpret this experiment with the coffee cup. Eliezer believes that in order to get the cup to move when it shouldn't have, some outside force has to be conspiring with the cup. Robin believes that this is just a physical object that is obeying the laws of physics. They have different beliefs, but, from Robin's point of view, they're talking past each other; even though they're both trying to answer the same "question", they're answering it differently.</p><br><p>They could agree to disagree to keep the discussion from blowing up, or take a chance on resolving this disagreement the hard way. Eliezer does not find this appealing. To make it even better for Robin's side, he agrees to take the position on "cached thoughts" that Robin favors, and Robin will decide whether or not to believe that "cached thoughts are real".</p><br><p>This, to Robin's eyes, looks like exactly what he said he wanted to avoid. The difference between the two of them is not <em>really</em> what is going on in their beliefs about the cup. The disagreement is what I would call a "red herring" \xe2\x80\x94 an argument that has no bearing on the question the two of them actually want to resolve, and gets everyone off on a tangent.</p>      </span>    </div>  </div></body></html>