<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        Is progress slowing down?      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Scott Alexander, Paul Crowley, and Aell</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>__Continuation of: __Ineffective Altruism</p><br><p>Ineffective altruism is an interesting case. The question we're asking is what proportion of altruistic people benefit? If you're a religious person, it's probably higher than the majority of religious people, and higher still than the vast majority of nonreligious people. If you just follow the advice of your local community organizer about it, it may be lower.</p><br><p>An attempt to answer this was done in an excellent paper by Peter Singer and Toby Ord which attempted to answer basically the exact same question, but from a different perspective so as to make their conclusion much less controversial. Their conclusion:</p><br><blockquote>
<p>One conclusion from our study is that progress is likely to continue. There is no reason to think it will not continue and no reason to assume it may suddenly stop. But we should use this to spur greater efforts to make that more happen in the future.</p>
</blockquote><br><p>But the paper was in the <em>New International Journal of Philosophical Ethics</em> which is one of those weird philosophical journals that exists only on paper and whose articles consist entirely of things like "What would philosophers think about the future of Artificial Intelligence?", which gives me an uncomfortable feeling about how relevant-sounding that paper's conclusion is going to be to my interests.</p><br><p>Instead of just reading papers from time to time, I decide to ask what the "mainstream" position on this is. For that I have to go to a less-weird philosophical journal, <em>Ethical Philosophy _which is famous for publishing one paper every year called "Is progress slowing down?" by Peter Singer. It's one of the most popular articles and one of the most up-voted. In one sense this is nice, since it means that my "mainstream" view has already been shown to be fairly representative; in another sense it's annoying, because the paper is _really</em> long (about 25k words) and covers quite a lot of ground, making it really hard for most LW readers to determine even what the crux of the argument is. Luckily, one particular crux is so important, it's the first sentence:</p><br><blockquote>
<p>A long-standing argument in the contemporary Western philosophy of ethics is: Has been there ever been a time, and is there one now, in which the level of moral improvement has been much greater than the level that we are now witnessing?</p>
</blockquote><br><p>(Note that "contemporary Western philosophy of ethics" in this case specifically refers to "moral realism", which means that we should expect to find a correlation between moral progress and real-world progress. Obviously not every moral realist thinks this, but it seems like a pretty good rule of thumb.)</p><br><p>The paper proceeds to defend the question by various clever arguments, and then concludes:</p><br><blockquote>
<p>In view of the moral progress that we now enjoy, there is a case to be made that progress has, in fact, slowed down.... This is the position I tentatively take.</p>
</blockquote><br><p>To support this I have to discuss a few of the other positions.</p><br><p>Some claim progress is <em>still _slowing down, and have a very good case for why. Here is a quote from one such article in the _Review of General Psychology</em>:</p><br><blockquote>
<p>Peter Singer argues in his book, <em>The Life You Can Save</em>, that our efforts to make the world a better place are woefully inadequate. The reason is the so-called "repugnant conclusion," for which he argues, is that, since most people value each additional year of life, by the time that they have lived 1,000 years, life extension technologies are going to have made all human lives barely worth living. [1]... We can accept, he says, that any technology that extends life is going to bring more happiness than not does, without embracing the repugnant conclusion by suggesting that life should be permanently and irreversibly shortened to barely-worth-living levels.</p>
</blockquote><br><p>The problem is that _The Life You Gotta Save _is a book about animal-related ethics, so Singer's position is going to be a lot weaker in the context of human ethics than people seem to think. Still, his basic contention that any method of life extension is likely to cause a lot of unhappiness seems like a pretty reasonable point. In fact, most of modern society would agree with his point.</p><br><p>Or to take one more quick look for a "mainstream" academic paper about this, here's a paper from the <em>Journal of Ethical Practice</em> based on interviews with philosophers and various other folk:</p><br><blockquote>
<p>The consensus seems to be that we have _not _been making significant moral progress over the last few decades.... We believe that this view is supported by available empirical data which show that people, as a society, have not been making much moral progress in recent historical periods.</p>
</blockquote><br><p>To the first claim, that's <em>very _clearly true to the extent that anyone has any views on history. There were a couple million people in western China who could have been born in the year 1000, but none were born because it was impossible to transport the fertilized ovum to a safe location. There were probably a few million people there who could have been alive in the year 1300, but none were alive because no one wanted Westerners to see _their</em> age-old culture. As for data supporting the claim "there have been (...) years when the level of moral progress has been much greater (...)": for example, maybe just as much moral progress occurred in medieval Japan as in the early twentieth century US. But as the article points out, "in the early twentieth century the Japanese state was much less morally competent than it had been in the late Tokugawa sh\xc5\x8dgunate", and maybe just as much, though probably not quite the same, in medieval Japan.</p><br><p>I'd argue that <em>The Life Gotta Save: The Realistic Hope for Humanity</em> is a better-written article, but I can't judge that because it's on the topic of animal welfare versus human welfare. Here's more from the <em>Journal</em>'s conclusion:</p><br><p>In addition to the empirical data supporting the claim that there have been (...) periods when the level of social change has been greater (...) there has also been (...) widespread skepticism about the claim that there were (previous) eras of much greater moral progress than the present. The claim that there have, historically, been eras of much greater social change may be highly plausible <em>a priori</em>, but, as we have seen, it is a hypothesis that is hard to confirm or falsify.</p><br><p>So that's what most of Western academia seems to believe, at least for now. Perhaps it would surprise our readers if we looked into this claim to see, not a consensus, but a consensus of a consensus among a minority. A group of academics, maybe around 100, might be willing to argue that in at least some recent eras there has been <em>some</em> improvement to the level. On the other hand, no one knows for a fact, and no one has any reason to think that if they do find some data that the mainstream view can be overturned.</p><br><p>At this point, the reader's eyes likely have wandered to the title of this post: Is progress slowing? Why would it be?</p><br><p>On the one hand, we could imagine a scenario in which human civilization just keeps growing and growing into new and new areas, until finally the frontier of the possible and the possible-to-compact is exhausted and we have all our atoms on earth to be a part of and no longer have to go on looking for things like happiness.</p><br><p>On the other hand, we could also imagine things not going great. So far our progress has been too focused on making us better at certain things, like medicine and technology and war, but that hasn't led us very well to other ends. You might start to think that all the stuff we care about isn't actually that important. Or maybe that there aren't <em>any</em> good ends at all, so our lives are just a long series of increasingly short and sadistic hedonistic satisfactions. Or maybe that all the things we care about have to do with maintaining the same people, instead of with making the world a better, happier, more free place.</p><br><p>Maybe progress is slowing down.</p><br><p>The first problem with that is that it's a complicated hypothesis, and we're not used to complicated hypotheses on LessWrong. Also it's more complicated because it can depend on what measure we look at, like "number of people who enjoy the experience of living" or "goodness of society" or "amount of good that happens".</p>      </span>    </div>  </div></body></html>