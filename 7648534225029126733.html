<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        How do you think people in the past would have reacted to AI risk?      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Kaj Sotal</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>The article's conclusion is that people may have behaved as if the Prisoners' Dillemma were a nonlinear prisoner's dilemma, and they expected cooperation under the common knowledge variant in <em>both</em> prisoners.</p><br><p>While the conclusions are obvious, the logic behind them is not. For that, I'd like to hear your feedback. I'm wondering how people here would have interpreted the behavior of others in situations like the following:  </p><br><ul>
<li>You and I are going to go to this movie together. What is the chance that you will let me know which one it is so that we can decide? </li>
</ul><br><ul>
<li>I get a job offer and need to tell my prospective employer which company I am going to work for. I assume that this job offer is my best option. But I know that many people will not want to accept it; some might even want to sabotage it. Given my lack of resources, it's in my best interest to inform none of them, only you. Unfortunately I'm aware that common knowledge ensures that we will all learn about the job offer at the same time. Do you agree that letting me tell anyone could be detrimental to my future life chances?</li>
</ul><br><ul>
<li>I think that the best option would be for you to not tell the other prisoners. Yet I expect them to tell you, either because I'm mistaken, or because they think that it is in my best interests for them to do so. Do you think that it's in their best interests to avoid talking to you?</li>
</ul><br><ul>
<li>You and your friend are trying to make a paper in a computer lab. It is not yet equipped with a scannerâ€”and you are quite good at hiding information with ink drawings that you pass on through a shared printer. Yet you realize that as soon as you try to scan an image, the ink is wiped from its scanner, meaning that you'll have to print the paper all over again. You therefore decide to print the image into a separate document before passing it on, but you know that your friend is still good at hiding information. Does this change your conclusion?</li>
</ul><br><ul>
<li>When writing software, we use various strategies about how to test it. One such common strategy is to write extensive test cases that aim to cover as many edge cases as possible. However, I know that when a programmer writes a test case, they typically assume that it will never actually be tested, since if it actually does get tested, it's hard to imagine that the programmers would make <em>all</em> of those test cases that they did. That assumption is reasonable, but I'm thinking that maybe we should adopt a stricter policy, and assume that if we ever do actually see that it test run, then there isn't anyone around to know that the software failed when it should have.</li>
</ul><br><p>(In case that's hard to understand: I'm thinking hypothetically about future AGI alignment failures because I think it's relevant to the Singularity, and would like to understand better why it's hard for AGI to do what we want.)</p>      </span>    </div>  </div></body></html>