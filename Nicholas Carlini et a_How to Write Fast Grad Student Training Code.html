<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        How to Write Fast Grad Student Training Code      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Nicholas Carlini et a</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>The Problem</li>
</ul><br><ul>
<li>Introduction</li>
</ul><br><ul>
<li>Background</li>
</ul><br><ul>
<li>Current Machine Learning Projects</li>
</ul><br><ul>
<li>The Approach</li>
</ul><br><ul>
<li>Answering the Question in the Shortest Possible Time</li>
</ul><br><ul>
<li>Why a One-Time Training Penalty Is Often Not enough</li>
</ul><br><ul>
<li>The Code</li>
</ul><br><ul>
<li>Current Issues</li>
</ul><br><p>We are going to share our experience in quickly training models for complex computer vision problems with gradient/\xe2\x80\x8bSGD based supervised learning in a few weeks from now (April 11, 2019 - Friday the 13th, so be prepared to run code for some time during those last couple of days).</p><br><p>To be clear, we didn't make a ton of extra effort relative to what we'd usually do. Instead, we took the basic approach of:</p><br><ul>
<li>Using PyTorch for the core functionality of the program.</li>
</ul><br><ul>
<li>Writing new algorithms, implementing new strategies, and combining these to achieve the speedups we need. For example we used some of our standard ML optimizations to speed up batching by 100x or removing randomness from the gradient update. Our algorithm also included a few tricks, such as using our GPU's to cache images instead of having to read the cache in each forward pass.</li>
</ul><br><ul>
<li>Running some benchmarks to know how much improvement we're getting. For example, we also ran a benchmark with our final program and then ran our new model on the top of that benchmark. These measurements helped us know that we're making significant improvements.</li>
</ul><br><ul>
<li>Running the same measurements on various hyperparameters and architectures so we can get a sense of the range of what the possible gains are from more training time/\xe2\x80\x8bmore training threads/\xe2\x80\x8bmore training data.</li>
</ul><br><ul>
<li>Writing documentation and testing our new program.</li>
</ul><br><p>Finally, we are aiming to share all code and experiments for the project in an open source format on a separate GitHub account so that you can independently verify our work for purposes of reproducing our training time improvements, or running your own experiments (with permission) and publishing the results. I'll then combine all of this information into an open source blog post at some point in April 2019\xe2\x80\x94so you can find the code today, just read it on April the 9th.</p><br><p>I'll also share with you some of the code here so that you can directly make these contributions as well with an eye toward reproducing our results for anyone else who's interested. Specifically, after we share our code the following things should be fairly straightforward:</p><br><ul>
<li>Make your copy of the PyTorch notebooks and/\xe2\x80\x8bor code that corresponds to one of the experiments presented here. </li>
</ul><br><ul>
<li>Try to reproduce our results\xe2\x80\x94this should be possible with minimal effort (i.e. perhaps requiring one change per machine learning problem you're trying to solve) -- the exact conditions we faced in the project were very difficult to determine beforehand and we tried to keep it fair and unbiased, but that's why we're sharing our code as well.</li>
</ul><br><ul>
<li>If you want to modify the code to try to improve on our original result, please do so with a new public repository and ensure your version of the code works when run with the rest of the PyTorcher notebooks, and then share that new version of the code as well.</li>
</ul><br><p>To be able to share everything from GitHub and help you reproduce the results for yourself, we'll need to release our training time improvements in various formats that we can later combine in a publication. For example, I'll share.dat files for the images and the PyTorch code (you can run those files without downloading any other dependencies). In addition to that stuff, I think an important project outcome will be the.pkl files that tell you in what order to train and then test your models, the.json files that share hyperparameter tuning information and the.bin files that share GPU memory usage information for every training /\xe2\x80\x8b testing run. For each of those, I'll share the Python code to write the dataset and hyperparameter tuning program, using the format mentioned above. I'll also point you to the repo on GitHub so that you can try running the code for yourself before I publish the.pkl,.json, and.bin files.</p><br><p>The Problem</p><br><p>The code we're using was originally written for a different project, but the approach we're using in general was pretty general and so this code works great for this purpose. We're using PyTorch, PyBorg and PyShaffy, all of which we've previously used for other projects and had great results. I originally wrote the original project in PyTorch for another computer vision training project and it worked quite well there, giving a significant speedup in training in comparison to a pure MLP implementation written in other ML tools. But when I tried it for this project, while it sped the training somewhat, I was still far slower than a pure MLP, because the training was bottlenecked by the time it took to download a very large dataset, and that's what we were trying to improve here.</p><br><p>Background</p><br><p>This project was more of a collaboration between multiple teams than a single team working on their own. In this project we were particularly interested in the use cases of MLP networks for machine learning in computer science, and so we chose to work directly on these kinds of networks in PyTorch. We wanted to know how well the networks would perform working in PyTorch so that we could better compare to implementations that used different tools. For previous projects in the past we have mostly focused on neural networks in general, however, so we ended up using several different types of networks here, including both networks with different types of architectures and networks that used additional techniques for increased efficiency purposes. To be as fair as possible, I wrote our code in a manner that is almost identical to PyTorch (the main change is a little simplification for PyBorg, but the rest of the code is mostly the same).</p><br><p>For a lot of the experiments presented in this project, we ran on different hardware, with the most extensive experiments being run on a single NVIDIA RTX2085 GPU. I don't really know why we chose that particular GPU, but we could easily have used a different one instead and I don't have detailed information about how the results were affected. We also ran experiments on Intel Core i7 CPUs running on the same hardware and this didn't have any notable change in training time. For the most part, though, these experiments were on Nvidia hardware instead of Intel hardware, but I believe our conclusions were relevant across multiple hardware platforms, with an open source notebook on their results, but I think anyone who's able to run their own implementations can get similar results.</p><br><p>I also didn't run this experiment as fast as I could because of that original project to focus on increasing training speed, and so I was only able to experiment with running the system once every few hours. I do believe that with some additional time and effort we could get these results substantially faster than that.</p><br><p>Current Machine Learning Projects</p><br><p>To try to break down the projects into somewhat more easily tractable work, we've recently started implementing a few different projects on AI/\xe2\x80\x8bML-related problems, which the team of us at least have gotten some experience with. Here are some examples of things that I think are probably promising to us:</p><br><ul>
<li></li>
</ul><br><p>Making a prediction engine for an online game, which should mostly fit a prediction-based approach to the problem (i.e., it's a sequential project so there is some back and forth between creating good features, writing good code, testing the code, and then iterating on those features as we need them).</p><br><ul>
<li></li>
</ul><br><p>Making an interactive text/\xe2\x80\x8bimage generation engine. This involves making a "story engine", a type of software in which the main software application you're interacting with generates a sequence of images that you can control (for a fictional example, imagine building a game where you create an NPC or similar AI and then you control the actions it's able to output).</p><br><ul>
<li>We also want to use these kinds of projects to develop some of our intuitions about good approaches to AI/\xe2\x80\x8bML problems, and then write papers and reports to explain our ideas.</li>
</ul><br><p>Below are projects we plan to work at a higher level:</p><br><ul>
<li>Training image/\xe2\x80\x8btext generation engines from text data</li>
</ul><br><ul>
<li>Training image/\xe2\x80\x8b text/\xe2\x80\x8b speech style translation engines from text data with adversarial training</li>
</ul><br><ul>
<li>Train a network on data and then try to predict which parts of the network will have high or low activations at a particular layer</li>
</ul><br><p>For these projects we're basically looking for people to help our experiments. If your project is about any of the two latter projects, you can easily submit a sample of the data you plan to work with and run your experiments. I expect there's room to improve on our current results but we want to hear about any ideas you have. We'll also be sharing our code with the community as we progress, so please feel free to suggest improvements to it in the issue tracker when you feel like helping improve the code.</p><br><p>The Approach</p><br><p>Our method for training these networks is to:</p><br><ul>
<li>Train PyTorch models with the PyBorg architecture on one of the large PyBorg datasets available at github. For example, the language model dataset and the large web image dataset.</li>
</ul><br><ul>
<li>Then use those models to generate text/\xe2\x80\x8bimage data that we have access to. For example, using the text/\xe2\x80\x8bimage generation system we just trained to generate webpages and then use that to train more advanced language models. And so on. Ideally we'd also like to find ways to improve our language model datasets to get even more training opportunities.</li>
</ul>      </span>    </div>  </div></body></html>