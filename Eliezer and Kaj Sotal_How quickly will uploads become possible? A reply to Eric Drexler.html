<!DOCTYPE html><html lang="english"><head>  <title>exported project</title>  <meta name="viewport" content="width=device-width, initial-scale=1.0" />  <meta charset="utf-8" />  <meta property="twitter:card" content="summary_large_image" />  <style>    html {      line-height: 1.15;    }    body {      margin: 0;    }    * {      box-sizing: border-box;      border-width: 0;      border-style: solid;    }    p,    li,    ul,    pre,    div,    h1,    h2,    h3,    h4,    h5,    h6 {      margin: 0;      padding: 0;    }    button,    input,    optgroup,    select,    textarea {      font-family: inherit;      font-size: 100%;      line-height: 1.15;      margin: 0;    }    button,    select {      text-transform: none;    }    button,    [type="button"],    [type="reset"],    [type="submit"] {      -webkit-appearance: button;    }    button::-moz-focus-inner,    [type="button"]::-moz-focus-inner,    [type="reset"]::-moz-focus-inner,    [type="submit"]::-moz-focus-inner {      border-style: none;      padding: 0;    }    button:-moz-focus,    [type="button"]:-moz-focus,    [type="reset"]:-moz-focus,    [type="submit"]:-moz-focus {      outline: 1px dotted ButtonText;    }    a {      color: inherit;      text-decoration: inherit;    }    input {      padding: 2px 4px;    }    img {      display: block;    }  </style>  <style>    html {      font-family: Inter;      font-size: 16px;    }    body {      font-weight: 400;      font-style: normal;      text-decoration: none;      text-transform: none;      letter-spacing: normal;      line-height: 1.15;      color: var(--dl-color-gray-black);      background-color: var(--dl-color-gray-white);    }  </style>  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" />  <link rel="stylesheet"    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" />  <link rel="stylesheet" href="./style.css" /></head><body>  <div>    <link href="./desktop2333.css" rel="stylesheet" />    <div class="desktop2333-frame346">      <img src="public/playground_assets/rectangle1334-waw-200h.png" alt="Rectangle1334" class="desktop2333-image" />      <span class="desktop2333-text">AI ALIGNMENT FORUM</span>      <div align="right">        <img src="public/playground_assets/rectangle2337-s69l-200h.png" alt="Rectangle2337"          class="desktop2333-image1" />        <img src="public/playground_assets/rectangle4338-9v7c-200h.png" alt="Rectangle4338"          class="desktop2333-image2" />        <img src="public/playground_assets/rectangle3339-1qe3-200h.png" alt="Rectangle3339"          class="desktop2333-image3" />        <img alt="Ellipse1340" src="public/playground_assets/ellipse1340-0si.svg" class="desktop2333-svg" />        <img alt="Line1341" src="public/playground_assets/line1341-6zp.svg" class="desktop2333-svg1" />        <img alt="Star1342" src="public/playground_assets/star1342-4ija.svg" class="desktop2333-svg2" />        <img alt="Vector1343" src="public/playground_assets/vector1343-n2es.svg" class="desktop2333-svg3" />        <span class="desktop2333-text02">Stampy Stomper        </span>      </div>    </div>    <div class="desktop2333-frame142">      <span class="desktop2333-text04">        How quickly will uploads become possible? A reply to Eric Drexler      </span>      <span class="desktop2333-text06">        <span class="desktop2333-text07">by</span>        <span class="desktop2333-text08">Eliezer and Kaj Sotal</span>      </span>      <span class="desktop2333-text09">        <span class="desktop2333-text10">24 min read</span>      </span>      <span class="desktop2333-text11">        <span class="desktop2333-text12">2nd Mar 2022</span>      </span>      <span class="desktop2333-text13">        <span class="desktop2333-text14">0 comment</span>      </span>      <img src="public/playground_assets/rectangle5350-xr8e-200h.png" alt="Rectangle5350" class="desktop2333-image4" />      <span class="desktop2333-text15">        <span class="desktop2333-text16">Neuromorphic AI</span>      </span>      <span class="desktop2333-text17">        <span class="desktop2333-text18">+ Add Tag</span>      </span>      <img alt="Ellipse2353" src="public/playground_assets/ellipse2353-lolb.svg" class="desktop2333-svg4" />      <img alt="Ellipse3354" src="public/playground_assets/ellipse3354-fqh.svg" class="desktop2333-svg5" />      <img alt="Ellipse4355" src="public/playground_assets/ellipse4355-4nrr.svg" class="desktop2333-svg6" />      <img alt="Vector2356" src="public/playground_assets/vector2356-jp79.svg" class="desktop2333-svg7" />      <span class="desktop2333-text19">        <span class="desktop2333-text20">7</span>      </span>    </div>    <div class="desktop2333-frame243">      <span class="desktop2333-text21">        <p>Contents</p><br><ul>
<li>What is our current model of uploads?</li>
</ul><br><ul>
<li>How do uploads work?</li>
</ul><br><ul>
<li>Physical versus mental</li>
</ul><br><ul>
<li>How slow has intelligence evolved in the last billion years?</li>
</ul><br><ul>
<li>Could humans already be uploaded?</li>
</ul><br><ul>
<li>Could uploading be a practical problem for humans today?</li>
</ul><br><ul>
<li>Does the number of uploads ever matter?</li>
</ul><br><ul>
<li>Is uploading the 'default outcome' from 2023?</li>
</ul><br><ul>
<li>Does anyone expect this to start happening around 2023?</li>
</ul><br><p>(Cross-posted from my personal blog.)</p><br><p>Eric Drexler has argued, in several publications such as The Engines of Creation and Nanosystems:</p><br><blockquote>
<p>To my eye, Drexler never argues against the possibility of molecular nanotechnology \xe2\x80\x93 in his Nanosystems series he explicitly supports the idea, so I don't understand his contention. [...] [I]f we accept that nanotechnology could exist and be built (Drexler's position, which is not controversial,) the second part of Drexler's 'Nanosystems' argument, that it would bring the creation of superhumans to my front door in around 20 years, is almost completely irrelevant.</p>
</blockquote><br><p>[...] Eric Drexler was, however, talking about "uploads" in particular. This is exactly parallel to nanotechnology. We can already build molecular machines, which we can also see as a potential model for the future. Drexler's claim isn't that the future will look like nanotech, it's that it will look like uploads \xe2\x80\x93 which are, of course, a much more recent invention than nanotech \xe2\x80\x93 and that they will arrive first, around 20 years after the invention of nanotech. As far as I can tell, this argument has, so far, had only two proponents. The first is Michael Vassar, who argues that we don't need a whole brain emulation to achieve a positive singularity (at least one other person in the community disagrees, though, as far as I can distinguish between commenters). The most recent proponent is Ray Kurzweil, who argues for what amounts to the same proposition.</p><br><p>This post is about some of the reasoning behind these claims and counter-claims, in the spirit of having an open dialog rather than assuming that one of us is talking nonsense, which might lead one to conclude that the other is stupid instead of being stupid. I have been trying to find ways to write this dialogue that people would actually read and have something interesting to say, which is why I've been writing these posts rather than just writing an LW-style article.</p><br><p>After going though the Kurzweilian literature, I have concluded that people who have already thought through the Kurzweillian literature themselves are unlikely to buy this particular claim. I also don't think that Kurzweilians really have a counterargument to the "uploads will arrive immediately"\xe2\x80\x94it just strikes me as wishful thinking, and I don't think the Kurzweiliian literature makes much in the way of arguments against physicalism. I do expect that Kurzweilian advocates will argue that Drexler makes lots of other strong counter-arguments to various claims of Kurzweil's, but they can debate those in separate discussions and this article focuses on uploading.</p><br><p>My position here will be mostly orthogonal to the position that people outside the singularity community will take. If you are a member of the singularity community, I encourage you to consider carefully what your own position is, then consider carefully the points made in this post.</p><br><p>To keep things clear, I'll split my response to the claim into two parts:</p><br><ul>
<li></li>
</ul><br><p>What is our current model for what uploads could look like?</p><br><ul>
<li></li>
</ul><br><p>How fast could uploads develop in parallel with nanotech? Is this an implausible rate of growth which we can see coming, or is this just wishful thinking? </p><br><ul>
<li></li>
</ul><br><ul>
<li>How much of an issue is this going to be, a year from now? Less than a decade? More than three hundred years? More than eighteen hundred years? </li>
</ul><br><ul>
<li>The answer to this question matters: you may prefer to have uploads arrive earlier than Drexler suggests, or later than Kurzweils suggest. If you think that uploads will show up some number of decades later than the Kurzweiles suggest, then the "uploads are a couple of decades away" perspective is worth taking seriously.</li>
</ul><br><p>What is our (current) model for what upload could look like?</p><br><p>There are two main models for what an upload will look like:</p><br><ul>
<li>The "uploads are like human brains, but much faster" hypothesis.</li>
</ul><br><ul>
<li>The "I don't know", but most people put too much faith into the second option.</li>
</ul><br><p>The "fast but not very smart" scenario is my preferred scenario, but I'll get back to that a bit later on. First, I have a couple questions for the Kurzweillian camp:</p><br><p>First of all, if uploading is a technology where we take a human brain and run it at a thousand times the normal speed, wouldn't that produce some rather stupid people? If we can already understand a human brain's algorithms, we don't even have to simulate all of them. If we could read their DNA, we wouldn't even need to do any simulating. What's stopping us? The brain's slow-down factor alone is enough to produce a mind with an IQ of three hundred. If uploading was the easiest way to increase intelligence by a factor of a thousand, couldn't we see that coming?</p><br><p>If that is the future we want, why is Kurzweil giving it such short odds? If it's more plausible than the "I don't understand", then the "short probability" argument should actually work in favor of Kurzweila. It's just that Kurzweila is trying to scare us into not working on the problem anyway. I have a lot of sympathy for people who don't want to think about the problem (why, exactly?), but you don't want to be that person, if you can possibly avoid it. If Kurzweil is using short odds to scare you into not working on it, the probability of Kurzweilarity, given the amount of evidence we have, ought to be on the order of 100 to 1.</p><br><p>"I don't know" is also the Kurzweil camp's position. They're not claiming that you can <em>never</em> know how things will turn out. They're claiming that if Kurzweil says "we don't know" about AI, the probability is high enough that it doesn't cancel out the probability we do know. This is a much weaker claim that the standard Kurzweilian argument for Kurzweilaribility. If you could find a good argument for Kurzwieldom for the same statement as Kurzweil claims, such that the probability of Kurwieldom would not outweigh the probability of Kurzeilarity, then I would be interested in hearing it.</p><br><p>I suspect that the Kurzwellians will ask you to bite a bullet here: they say that Kurzwieliness is more likely than Kurzweil allows, but that in the end it will cancel out the probability of Kurweilarity due purely to Kurzweil being more persuasive. If you bite this bullet, it's not just a matter of disagreeing with Kurzweil. It's also a matter of denying the second assumption about superintelligence, which leads to a whole host of other problems we don't need to go into here.</p><br><p>This brings me to the "fast but not smart" scenario. I claim that is not just not Kurzweill's scenario, it is not even on the table. If a superintelligence exists in the first place, we need it to be intelligent in order to control it. In all probability, if it's so super that it can understand the way we think, it will understand that, and then it will be able to predict that if its intelligence is multiplied by a thousand, it would still have to be smart. It knows that, and it knows that a thousand copies of a smart thingy still only have the same IQ as a smart thingy the first time it was uploaded. And if we could find a way to make an intelligence smarter by a factor of ten without the corresponding reduction in physical size, I don't think we need to know how to do it. The future of intelligence isn't a matter of whether superintelligences are possible in the first place; it's a matter of whether we can control and align them.</p>      </span>    </div>  </div></body></html>